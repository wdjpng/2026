@article{example2024calibration,
  title={Calibrated Uncertainty Estimation in Deep Learning},
  author={Anonymous},
  journal={arXiv preprint},
  year={2024},
  url={https://arxiv.org/abs/xxxx.xxxxx}
}

@inproceedings{example2023uncertainty,
  title={Understanding Model Uncertainty in Neural Networks},
  author={Anonymous},
  booktitle={International Conference on Learning Representations},
  year={2023}
}

@article{example2022reliability,
  title={Reliable Predictions with Confidence Intervals},
  author={Anonymous},
  journal={Machine Learning Journal},
  year={2022}
}


@article{Brier1950,
  author    = {Glenn W. Brier},
  title     = {Verification of Forecasts Expressed in Terms of Probability},
  journal   = {Monthly Weather Review},
  volume    = {78},
  number    = {1},
  pages     = {1--3},
  year      = {1950},
  publisher = {American Meteorological Society}
}

@article{MurphyWinkler1977,
  author    = {Allan H. Murphy and Robert L. Winkler},
  title     = {Reliability of Subjective Probability Forecasts of Precipitation and Temperature},
  journal   = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
  volume    = {26},
  number    = {1},
  pages     = {41--47},
  year      = {1977},
  publisher = {Wiley}
}

@article{Dawid1982,
  author    = {A. P. Dawid},
  title     = {The Well-Calibrated Bayesian},
  journal   = {Journal of the American Statistical Association},
  volume    = {77},
  number    = {379},
  pages     = {605--610},
  year      = {1982}
}

@incollection{Platt1999,
  author    = {John C. Platt},
  title     = {Probabilistic Outputs for Support Vector Machines and Comparisons to Regularized Likelihood Methods},
  booktitle = {Advances in Large Margin Classifiers},
  editor    = {Alexander J. Smola and Peter L. Bartlett and Bernhard Sch{\"o}lkopf and Dale Schuurmans},
  publisher = {MIT Press},
  address   = {Cambridge, MA},
  year      = {2000},
  pages     = {61--74}
}

@inproceedings{ZadroznyElkan2001,
  author    = {Bianca Zadrozny and Charles Elkan},
  title     = {Obtaining Calibrated Probability Estimates from Decision Trees and Na{\"\i}ve Bayesian Classifiers},
  booktitle = {Proceedings of the 18th International Conference on Machine Learning (ICML)},
  year      = {2001}
}

@inproceedings{ZadroznyElkan2002,
  author    = {Bianca Zadrozny and Charles Elkan},
  title     = {Transforming Classifier Scores into Accurate Multiclass Probability Estimates},
  booktitle = {Proceedings of the 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)},
  year      = {2002},
  doi       = {10.1145/775047.775151}
}

@inproceedings{NiculescuMizilCaruana2005,
  author    = {Alexandru Niculescu-Mizil and Rich Caruana},
  title     = {Predicting Good Probabilities with Supervised Learning},
  booktitle = {Proceedings of the 22nd International Conference on Machine Learning (ICML)},
  year      = {2005},
  doi       = {10.1145/1102351.1102430}
}

@inproceedings{Naeini2015BBQ,
  author    = {Mahdi Pakdaman Naeini and Gregory F. Cooper and Milos Hauskrecht},
  title     = {Obtaining Well Calibrated Probabilities Using Bayesian Binning},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  year      = {2015},
  pages     = {2901--2907},
  publisher = {AAAI Press}
}

@inproceedings{Guo2017Calibration,
  author    = {Chuan Guo and Geoff Pleiss and Yu Sun and Kilian Q. Weinberger},
  title     = {On Calibration of Modern Neural Networks},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning},
  series    = {Proceedings of Machine Learning Research},
  volume    = {70},
  year      = {2017},
  publisher = {PMLR},
  url       = {http://proceedings.mlr.press/v70/guo17a.html}
}

@inproceedings{Lakshminarayanan2017Ensembles,
  author    = {Balaji Lakshminarayanan and Alexander Pritzel and Charles Blundell},
  title     = {Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles},
  booktitle = {Advances in Neural Information Processing Systems 30 (NeurIPS 2017)},
  year      = {2017},
  url       = {https://papers.nips.cc/paper/2017/hash/9ef2ed4b7fd2c810847ffa5fa85bce38-Abstract.html}
}

@inproceedings{Kuleshov2018CalibratedRegression,
  author    = {Volodymyr Kuleshov and Nathan Fenner and Stefano Ermon},
  title     = {Accurate Uncertainties for Deep Learning Using Calibrated Regression},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning},
  series    = {Proceedings of Machine Learning Research},
  volume    = {80},
  year      = {2018},
  publisher = {PMLR},
  url       = {http://proceedings.mlr.press/v80/kuleshov18a.html}
}

@inproceedings{HebertJohnson2018Multicalibration,
  author    = {Samy Jelassi and Michael P. Kim and Rina Foygel Barber and Omer Reingold and Guy Rothblum and Jonathan Ullman},
  title     = {Multicalibration: Calibration for the (Computationally-Identifiable) Masses},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning},
  series    = {Proceedings of Machine Learning Research},
  volume    = {80},
  year      = {2018},
  publisher = {PMLR},
  url       = {http://proceedings.mlr.press/v80/hebert-johnson18a.html},
  note      = {Originally listed under author H{\'e}bert-Johnson et al.}
}

@inproceedings{Nixon2019CVPRW,
  author    = {Jeremy Nixon and Michael W. Dusenberry and Linchuan Zhang and Ghassen Jerfel and Dustin Tran},
  title     = {Measuring Calibration in Deep Learning},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
  year      = {2019},
  month     = {June}
}

@inproceedings{Kull2019Dirichlet,
  author    = {Meelis Kull and Miquel Perell{\'o}-Nieto and Markus K{\"a}ngsepp and Telmo Silva Filho and Hao Song and Peter Flach},
  title     = {Beyond Temperature Scaling: Obtaining Well-Calibrated Multiclass Probabilities with Dirichlet Calibration},
  booktitle = {Advances in Neural Information Processing Systems 32 (NeurIPS 2019)},
  year      = {2019},
  url       = {https://arxiv.org/abs/1910.12656}
}

@inproceedings{Kumar2019Verified,
  author    = {Aviral Kumar and Sunita Sarawagi and Yuanhong Tao and Tengyu Ma and Percy Liang},
  title     = {Verified Uncertainty Calibration},
  booktitle = {Advances in Neural Information Processing Systems 32 (NeurIPS 2019)},
  year      = {2019}
}

@inproceedings{Ovadia2019Shift,
  author    = {Yaniv Ovadia and Emily Fertig and Jie Ren and Zachary Nado and D. Sculley and Sebastian Nowozin and Joshua V. Dillon and Balaji Lakshminarayanan and Jasper Snoek},
  title     = {Can You Trust Your Model's Uncertainty? Evaluating Predictive Uncertainty under Dataset Shift},
  booktitle = {Advances in Neural Information Processing Systems 32 (NeurIPS 2019)},
  year      = {2019},
  url       = {https://proceedings.neurips.cc/paper/2019/hash/8558cb408c1d76621371888657d2eb1d-Abstract.html}
}

@inproceedings{Minderer2021Revisiting,
  author    = {Matthias Minderer and Josip Djolonga and Rob Romijnders and Frances Hubis and Xiaohua Zhai and Neil Houlsby and Dustin Tran and Mario Lucic},
  title     = {Revisiting the Calibration of Modern Neural Networks},
  booktitle = {Advances in Neural Information Processing Systems 34 (NeurIPS 2021)},
  year      = {2021}
}

@inproceedings{Wenger2020NonParametric,
  title     = {Non-Parametric Calibration for Classification},
  author    = {Wenger, Jonathan and Kjellstr{\"o}m, Hedvig and Triebel), Rudolph},
  booktitle = {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},
  pages     = {178--190},
  year      = {2020},
  editor    = {Chiappa, Silvia and Calandra, Roberto},
  volume    = {108},
  series    = {Proceedings of Machine Learning Research},
  month     = {26--28 Aug},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v108/wenger20a/wenger20a.pdf},
  url       = {https://proceedings.mlr.press/v108/wenger20a.html}
}

@inproceedings{PerezLebel2023GroupingLoss,
  author    = {Alexandre Perez-Lebel and Marine Le Morvan and Ga{\"e}l Varoquaux},
  title     = {Beyond Calibration: Estimating the Grouping Loss of Modern Neural Networks},
  booktitle = {The Eleventh International Conference on Learning Representations (ICLR)},
  year      = {2023},
  publisher = {OpenReview.net},
  url       = {https://openreview.net/forum?id=6w1k-IixnL8}
}

@inproceedings{Xiong2023ProCal,
  author    = {Miao Xiong and Ailin Deng and Pang Wei Koh and Jiaying Wu and Shen Li and Jianqing Xu and Bryan Hooi},
  title     = {Proximity-Informed Calibration for Deep Neural Networks},
  booktitle = {Advances in Neural Information Processing Systems 36 (NeurIPS 2023)},
  year      = {2023},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2023/hash/d826f5aadb26db488b8686097ceea2d1-Abstract-Conference.html}
}

@inproceedings{Brown2020GPT3,
  author    = {Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and et al.},
  title     = {Language Models are Few-Shot Learners},
  booktitle = {Advances in Neural Information Processing Systems 33 (NeurIPS 2020)},
  year      = {2020},
  url       = {https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf}
}

@article{OpenAI2023GPT4,
  author    = {{OpenAI}},
  title     = {{GPT-4} Technical Report},
  journal   = {arXiv preprint arXiv:2303.08774},
  year      = {2023},
  url       = {https://arxiv.org/abs/2303.08774}
}

@article{Rae2021Gopher,
  author    = {Jack W. Rae and Sebastian Borgeaud and Trevor Cai and Katie Millican and Jordan Hoffmann and Francis Song and John Aslanides and Sarah Henderson and Roman Ring and Susannah Young and Eliza Rutherford and Tom Hennigan and Jacob Menick and Albin Cassirer and Richard Powell and George van den Driessche and Lisa Anne Hendricks and Maribeth Rauh and Po-Sen Huang and Amelia Glaese and Johannes Welbl and Sumanth Dathathri and Saffron Huang and Jonathan Uesato and John Mellor and Irina Higgins and Antonia Creswell and Nat McAleese and Amy Wu and Erich Elsen and Siddhant Jayakumar and Elena Buchatskaya and David Budden and Esme Sutherland and Karen Simonyan and Michela Paganini and Laurent Sifre and Lena Martens and Xiang Lorraine Li and Adhiguna Kuncoro and Aida Nematzadeh and Elena Gribovskaya and Domenic Donato and Angeliki Lazaridou and Arthur Mensch and Jean-Baptiste Lespiau and Maria Tsimpoukelli and Nikolai Grigorev and Doug Fritz and Thibault Sottiaux and Mantas Pajarskas and Toby Pohlen and Zhitao Gong and Daniel Toyama and Cyprien de Masson d'Autume and Yujia Li and Tayfun Terzi and Vladimir Mikulik and Igor Babuschkin and Aidan Clark and Diego de Las Casas and Aurelia Guy and Chris Jones and James Bradbury and Matthew Johnson and Blake Hechtman and Laura Weidinger and Iason Gabriel and William Isaac and Ed Lockhart and Simon Osindero and Laura Rimell and Chris Dyer and Oriol Vinyals and Kareem Ayoub and Jeff Stanway and Lorrayne Bennett and Demis Hassabis and Koray Kavukcuoglu and Geoffrey Irving},
  title     = {Scaling Language Models: Methods, Analysis \& Insights from Training Gopher},
  journal   = {arXiv preprint arXiv:2112.11446},
  year      = {2021},
  url       = {https://arxiv.org/abs/2112.11446}
}

@article{Liang2022HELM,
title={Holistic Evaluation of Language Models},
author={Percy Liang and Rishi Bommasani and Tony Lee and Dimitris Tsipras and Dilara Soylu and Michihiro Yasunaga and Yian Zhang and Deepak Narayanan and Yuhuai Wu and Ananya Kumar and Benjamin Newman and Binhang Yuan and Bobby Yan and Ce Zhang and Christian Cosgrove and Christopher D Manning and Christopher Re and Diana Acosta-Navas and Drew A. Hudson and Eric Zelikman and Esin Durmus and Faisal Ladhak and Frieda Rong and Hongyu Ren and Huaxiu Yao and Jue WANG and Keshav Santhanam and Laurel Orr and Lucia Zheng and Mert Yuksekgonul and Mirac Suzgun and Nathan Kim and Neel Guha and Niladri S. Chatterji and Omar Khattab and Peter Henderson and Qian Huang and Ryan Andrew Chi and Sang Michael Xie and Shibani Santurkar and Surya Ganguli and Tatsunori Hashimoto and Thomas Icard and Tianyi Zhang and Vishrav Chaudhary and William Wang and Xuechen Li and Yifan Mai and Yuhui Zhang and Yuta Koreeda},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2023},
url={https://openreview.net/forum?id=iO4LZibEqW},
note={Featured Certification, Expert Certification, Outstanding Certification}
}

@article{Srivastava2022BIGBench,
title={Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models},
author={Aarohi Srivastava and Abhinav Rastogi and Abhishek Rao and Abu Awal Md Shoeb and Abubakar Abid and Adam Fisch and Adam R. Brown and Adam Santoro and Aditya Gupta and Adri{\`a} Garriga-Alonso and Agnieszka Kluska and Aitor Lewkowycz and Akshat Agarwal and Alethea Power and Alex Ray and Alex Warstadt and Alexander W. Kocurek and Ali Safaya and Ali Tazarv and Alice Xiang and Alicia Parrish and Allen Nie and Aman Hussain and Amanda Askell and Amanda Dsouza and Ambrose Slone and Ameet Rahane and Anantharaman S. Iyer and Anders Johan Andreassen and Andrea Madotto and Andrea Santilli and Andreas Stuhlm{\"u}ller and Andrew M. Dai and Andrew La and Andrew Kyle Lampinen and Andy Zou and Angela Jiang and Angelica Chen and Anh Vuong and Animesh Gupta and Anna Gottardi and Antonio Norelli and Anu Venkatesh and Arash Gholamidavoodi and Arfa Tabassum and Arul Menezes and Arun Kirubarajan and Asher Mullokandov and Ashish Sabharwal and Austin Herrick and Avia Efrat and Aykut Erdem and Ayla Karaka{\c{s}} and B. Ryan Roberts and Bao Sheng Loe and Barret Zoph and Bart{\l}omiej Bojanowski and Batuhan {\"O}zyurt and Behnam Hedayatnia and Behnam Neyshabur and Benjamin Inden and Benno Stein and Berk Ekmekci and Bill Yuchen Lin and Blake Howald and Bryan Orinion and Cameron Diao and Cameron Dour and Catherine Stinson and Cedrick Argueta and Cesar Ferri and Chandan Singh and Charles Rathkopf and Chenlin Meng and Chitta Baral and Chiyu Wu and Chris Callison-Burch and Christopher Waites and Christian Voigt and Christopher D Manning and Christopher Potts and Cindy Ramirez and Clara E. Rivera and Clemencia Siro and Colin Raffel and Courtney Ashcraft and Cristina Garbacea and Damien Sileo and Dan Garrette and Dan Hendrycks and Dan Kilman and Dan Roth and C. Daniel Freeman and Daniel Khashabi and Daniel Levy and Daniel Mosegu{\'\i} Gonz{\'a}lez and Danielle Perszyk and Danny Hernandez and Danqi Chen and Daphne Ippolito and Dar Gilboa and David Dohan and David Drakard and David Jurgens and Debajyoti Datta and Deep Ganguli and Denis Emelin and Denis Kleyko and Deniz Yuret and Derek Chen and Derek Tam and Dieuwke Hupkes and Diganta Misra and Dilyar Buzan and Dimitri Coelho Mollo and Diyi Yang and Dong-Ho Lee and Dylan Schrader and Ekaterina Shutova and Ekin Dogus Cubuk and Elad Segal and Eleanor Hagerman and Elizabeth Barnes and Elizabeth Donoway and Ellie Pavlick and Emanuele Rodol{\`a} and Emma Lam and Eric Chu and Eric Tang and Erkut Erdem and Ernie Chang and Ethan A Chi and Ethan Dyer and Ethan Jerzak and Ethan Kim and Eunice Engefu Manyasi and Evgenii Zheltonozhskii and Fanyue Xia and Fatemeh Siar and Fernando Mart{\'\i}nez-Plumed and Francesca Happ{\'e} and Francois Chollet and Frieda Rong and Gaurav Mishra and Genta Indra Winata and Gerard de Melo and Germ{\`a}n Kruszewski and Giambattista Parascandolo and Giorgio Mariani and Gloria Xinyue Wang and Gonzalo Jaimovitch-Lopez and Gregor Betz and Guy Gur-Ari and Hana Galijasevic and Hannah Kim and Hannah Rashkin and Hannaneh Hajishirzi and Harsh Mehta and Hayden Bogar and Henry Francis Anthony Shevlin and Hinrich Schuetze and Hiromu Yakura and Hongming Zhang and Hugh Mee Wong and Ian Ng and Isaac Noble and Jaap Jumelet and Jack Geissinger and Jackson Kernion and Jacob Hilton and Jaehoon Lee and Jaime Fern{\'a}ndez Fisac and James B Simon and James Koppel and James Zheng and James Zou and Jan Kocon and Jana Thompson and Janelle Wingfield and Jared Kaplan and Jarema Radom and Jascha Sohl-Dickstein and Jason Phang and Jason Wei and Jason Yosinski and Jekaterina Novikova and Jelle Bosscher and Jennifer Marsh and Jeremy Kim and Jeroen Taal and Jesse Engel and Jesujoba Alabi and Jiacheng Xu and Jiaming Song and Jillian Tang and Joan Waweru and John Burden and John Miller and John U. Balis and Jonathan Batchelder and Jonathan Berant and J{\"o}rg Frohberg and Jos Rozen and Jose Hernandez-Orallo and Joseph Boudeman and Joseph Guerr and Joseph Jones and Joshua B. Tenenbaum and Joshua S. Rule and Joyce Chua and Kamil Kanclerz and Karen Livescu and Karl Krauth and Karthik Gopalakrishnan and Katerina Ignatyeva and Katja Markert and Kaustubh Dhole and Kevin Gimpel and Kevin Omondi and Kory Wallace Mathewson and Kristen Chiafullo and Ksenia Shkaruta and Kumar Shridhar and Kyle McDonell and Kyle Richardson and Laria Reynolds and Leo Gao and Li Zhang and Liam Dugan and Lianhui Qin and Lidia Contreras-Ochando and Louis-Philippe Morency and Luca Moschella and Lucas Lam and Lucy Noble and Ludwig Schmidt and Luheng He and Luis Oliveros-Col{\'o}n and Luke Metz and L{\"u}tfi Kerem Senel and Maarten Bosma and Maarten Sap and Maartje Ter Hoeve and Maheen Farooqi and Manaal Faruqui and Mantas Mazeika and Marco Baturan and Marco Marelli and Marco Maru and Maria Jose Ramirez-Quintana and Marie Tolkiehn and Mario Giulianelli and Martha Lewis and Martin Potthast and Matthew L Leavitt and Matthias Hagen and M{\'a}ty{\'a}s Schubert and Medina Orduna Baitemirova and Melody Arnaud and Melvin McElrath and Michael Andrew Yee and Michael Cohen and Michael Gu and Michael Ivanitskiy and Michael Starritt and Michael Strube and Micha{\l} Sw{\k{e}}drowski and Michele Bevilacqua and Michihiro Yasunaga and Mihir Kale and Mike Cain and Mimee Xu and Mirac Suzgun and Mitch Walker and Mo Tiwari and Mohit Bansal and Moin Aminnaseri and Mor Geva and Mozhdeh Gheini and Mukund Varma T and Nanyun Peng and Nathan Andrew Chi and Nayeon Lee and Neta Gur-Ari Krakover and Nicholas Cameron and Nicholas Roberts and Nick Doiron and Nicole Martinez and Nikita Nangia and Niklas Deckers and Niklas Muennighoff and Nitish Shirish Keskar and Niveditha S. Iyer and Noah Constant and Noah Fiedel and Nuan Wen and Oliver Zhang and Omar Agha and Omar Elbaghdadi and Omer Levy and Owain Evans and Pablo Antonio Moreno Casares and Parth Doshi and Pascale Fung and Paul Pu Liang and Paul Vicol and Pegah Alipoormolabashi and Peiyuan Liao and Percy Liang and Peter W Chang and Peter Eckersley and Phu Mon Htut and Pinyu Hwang and Piotr Mi{\l}kowski and Piyush Patil and Pouya Pezeshkpour and Priti Oli and Qiaozhu Mei and Qing Lyu and Qinlang Chen and Rabin Banjade and Rachel Etta Rudolph and Raefer Gabriel and Rahel Habacker and Ramon Risco and Rapha{\"e}l Milli{\`e}re and Rhythm Garg and Richard Barnes and Rif A. Saurous and Riku Arakawa and Robbe Raymaekers and Robert Frank and Rohan Sikand and Roman Novak and Roman Sitelew and Ronan Le Bras and Rosanne Liu and Rowan Jacobs and Rui Zhang and Russ Salakhutdinov and Ryan Andrew Chi and Seungjae Ryan Lee and Ryan Stovall and Ryan Teehan and Rylan Yang and Sahib Singh and Saif M. Mohammad and Sajant Anand and Sam Dillavou and Sam Shleifer and Sam Wiseman and Samuel Gruetter and Samuel R. Bowman and Samuel Stern Schoenholz and Sanghyun Han and Sanjeev Kwatra and Sarah A. Rous and Sarik Ghazarian and Sayan Ghosh and Sean Casey and Sebastian Bischoff and Sebastian Gehrmann and Sebastian Schuster and Sepideh Sadeghi and Shadi Hamdan and Sharon Zhou and Shashank Srivastava and Sherry Shi and Shikhar Singh and Shima Asaadi and Shixiang Shane Gu and Shubh Pachchigar and Shubham Toshniwal and Shyam Upadhyay and Shyamolima Shammie Debnath and Siamak Shakeri and Simon Thormeyer and Simone Melzi and Siva Reddy and Sneha Priscilla Makini and Soo-Hwan Lee and Spencer Torene and Sriharsha Hatwar and Stanislas Dehaene and Stefan Divic and Stefano Ermon and Stella Biderman and Stephanie Lin and Stephen Prasad and Steven Piantadosi and Stuart Shieber and Summer Misherghi and Svetlana Kiritchenko and Swaroop Mishra and Tal Linzen and Tal Schuster and Tao Li and Tao Yu and Tariq Ali and Tatsunori Hashimoto and Te-Lin Wu and Th{\'e}o Desbordes and Theodore Rothschild and Thomas Phan and Tianle Wang and Tiberius Nkinyili and Timo Schick and Timofei Kornev and Titus Tunduny and Tobias Gerstenberg and Trenton Chang and Trishala Neeraj and Tushar Khot and Tyler Shultz and Uri Shaham and Vedant Misra and Vera Demberg and Victoria Nyamai and Vikas Raunak and Vinay Venkatesh Ramasesh and vinay uday prabhu and Vishakh Padmakumar and Vivek Srikumar and William Fedus and William Saunders and William Zhang and Wout Vossen and Xiang Ren and Xiaoyu Tong and Xinran Zhao and Xinyi Wu and Xudong Shen and Yadollah Yaghoobzadeh and Yair Lakretz and Yangqiu Song and Yasaman Bahri and Yejin Choi and Yichi Yang and Sophie Hao and Yifu Chen and Yonatan Belinkov and Yu Hou and Yufang Hou and Yuntao Bai and Zachary Seid and Zhuoye Zhao and Zijian Wang and Zijie J. Wang and Zirui Wang and Ziyi Wu},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2023},
url={https://openreview.net/forum?id=uyTL5Bvosj},
note={Featured Certification}
}

@misc{NeurIPS2020TutorialUncertainty,
  author    = {Dan Hendrycks and Shreyas Padhy and Jacob Steinhardt},
  title     = {Uncertainty and Robustness in Deep Learning (NeurIPS 2020 Tutorial Slides)},
  howpublished = {\url{https://neurips.cc/media/neurips-2020/Slides/16649.pdf}},
  year      = {2020},
  note      = {Tutorial slides}
}

@article{degroot1983comparison,
 ISSN = {00390526, 14679884},
 URL = {http://www.jstor.org/stable/2987588},
 abstract = {In this paper we present methods for comparing and evaluating forecasters whose predictions are presented as their subjective probability distributions of various random variables that will be observed in the future, e.g. weather forecasters who each day must specify their own probabilities that it will rain in a particular location. We begin by reviewing the concepts of calibration and refinement, and describing the relationship between this notion of refinement and the notion of sufficiency in the comparison of statistical experiments. We also consider the question of interrelationships among forecasters and discuss methods by which an observer should combine the predictions from two or more different forecasters. Then we turn our attention to the concept of a proper scoring rule for evaluating forecasters, relating it to the concepts of calibration and refinement. Finally, we discuss conditions under which one forecaster can exploit the predictions of another forecaster to obtain a better score.},
 author = {Morris H. DeGroot and Stephen E. Fienberg},
 journal = {Journal of the Royal Statistical Society. Series D (The Statistician)},
 number = {1},
 pages = {12--22},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {The Comparison and Evaluation of Forecasters},
 urldate = {2025-11-27},
 volume = {32},
 year = {1983}
}

@inproceedings{param_temp_scaling_eccv2022,
  author    = {Tomani, Christian and Cremers, Daniel and Buettner, Florian},
  title     = {Parameterized Temperature Scaling for Boosting the Expressive Power in Post-Hoc Uncertainty Calibration},
  booktitle = {Computer Vision -- ECCV 2022},
  editor    = {Avidan, Shai and Brostow, Gabriel and Ciss{\'e}, Moustapha and Farinella, Giovanni Maria and Hassner, Tal},
  series    = {Lecture Notes in Computer Science},
  volume    = {13673},
  pages     = {555--569},
  publisher = {Springer, Cham},
  year      = {2022},
  doi       = {10.1007/978-3-031-19778-9_32},
  url       = {https://link.springer.com/chapter/10.1007/978-3-031-19778-9_32}
}


@inproceedings{pavlovic2025understanding,
title={Understanding Model Calibration - A gentle introduction and visual exploration of calibration and the expected calibration error ({ECE})},
author={Maja Pavlovic},
booktitle={The Fourth Blogpost Track at ICLR 2025},
year={2025},
url={https://openreview.net/forum?id=BxBeCjQd2y}
}

@book{Bishop2006PatternRecognition,
  author    = {Christopher M. Bishop},
  title     = {Pattern Recognition and Machine Learning},
  year      = {2006},
  publisher = {Springer},
  address   = {New York},
  series    = {Information Science and Statistics},
  isbn      = {978-0-387-31073-2}
}

@article{Chow1970OptimumReject,
  author  = {C. K. Chow},
  title   = {On Optimum Recognition Error and Reject Tradeoff},
  journal = {IEEE Transactions on Information Theory},
  year    = {1970},
  volume  = {16},
  number  = {1},
  pages   = {41--46},
  doi     = {10.1109/TIT.1970.1054406}
}

@inproceedings{Geifman2017SelectiveClassification,
  author    = {Yonatan Geifman and Ran El{-}Yaniv},
  title     = {Selective Classification for Deep Neural Networks},
  booktitle = {Advances in Neural Information Processing Systems},
  volume    = {30},
  year      = {2017},
  pages     = {4885--4894},
  publisher = {Curran Associates, Inc.}
}

@inproceedings{Jaeger2023FailureDetection,
  author    = {Paul F. Jaeger and Carsten Tim L{\"u}th and Lukas Klein and Till J. Bungert},
  title     = {A Call to Reflect on Evaluation Practices for Failure Detection in Image Classification},
  booktitle = {International Conference on Learning Representations},
  year      = {2023},
  url       = {https://openreview.net/forum?id=YnkGMIh0gvX}
}

@article{Xia2024SelectiveOOD,
  author    = {Guoxuan Xia and Christos{-}Savvas Bouganis},
  title     = {Augmenting the Softmax with Additional Confidence Scores for Improved Selective Classification with Out-of-Distribution Data},
  journal   = {International Journal of Computer Vision},
  year      = {2024},
  volume    = {132},
  pages     = {3714--3752},
  doi       = {10.1007/s11263-024-02029-3}
}



@inproceedings{malinin2020ensemble,
  title     = {Ensemble Distribution Distillation},
  author    = {Malinin, Andrey and Mlodozeniec, Bruno and Gales, Mark J. F.},
  booktitle = {International Conference on Learning Representations},
  year      = {2020},
  url       = {https://openreview.net/forum?id=BygSP6Vtvr}
}


@article{CosmidesTooby1996IntuitiveStat,
  title     = {Are humans good intuitive statisticians after all? Rethinking some conclusions from the literature on judgment under uncertainty},
  author    = {Cosmides, Leda and Tooby, John},
  journal   = {Cognition},
  year      = {1996},
  volume    = {58},
  number    = {1},
  pages     = {1--73},
  doi       = {10.1016/0010-0277(95)00664-8},
  url       = {https://doi.org/10.1016/0010-0277(95)00664-8}
}


@inproceedings{LeCoz2024EfficientCalibration,
 author = {Le Coz, Adrien and Herbin, St\'{e}phane and Adjed, Faouzi},
 booktitle = {Advances in Neural Information Processing Systems},
 doi = {10.52202/079017-2469},
 editor = {A. Globerson and L. Mackey and D. Belgrave and A. Fan and U. Paquet and J. Tomczak and C. Zhang},
 pages = {77686--77725},
 publisher = {Curran Associates, Inc.},
 title = {Confidence Calibration of Classifiers with Many Classes},
 url = {https://proceedings.neurips.cc/paper_files/paper/2024/file/8df80d7115a55eb81010c967a247b1ae-Paper-Conference.pdf},
 volume = {37},
 year = {2024}
}
@InProceedings{Zhang2020MixnMatchCalibration,
  title     = {Mix-n-Match: Ensemble and Compositional Methods for Uncertainty Calibration in Deep Learning},
  author    = {Zhang, Jize and Kailkhura, Bhavya and Han, T. Yong-Jin},
  booktitle = {Proceedings of the 37th International Conference on Machine Learning},
  pages     = {11117--11128},
  year      = {2020},
  editor    = {Daumé III, Hal and Singh, Aarti},
  volume    = {119},
  series    = {Proceedings of Machine Learning Research},
  month     = {13--18 Jul},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v119/zhang20k/zhang20k.pdf},
  url       = {https://proceedings.mlr.press/v119/zhang20k.html}
}

@inproceedings{Chidambaram2025reassessing,
title={Reassessing How to Compare and Improve the Calibration of Machine Learning Models},
author={Muthu Chidambaram and Rong Ge},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=X0epAjg0hd}
}

@INPROCEEDINGS{Meronen2024fixoverconfidence,
  author={Meronen, Lassi and Trapp, Martin and Pilzer, Andrea and Yang, Le and Solin, Arno},
  booktitle={2024 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)}, 
  title={Fixing Overconfidence in Dynamic Neural Networks}, 
  year={2024},
  volume={},
  number={},
  pages={2668-2678},
  keywords={Deep learning;Adaptation models;Computer vision;Uncertainty;Computational modeling;Neural networks;Decision making;Algorithms;Machine learning architectures;formulations;and algorithms},
  doi={10.1109/WACV57701.2024.00266}}

@InProceedings{pmlr-v97-geifman19a,
  title = 	 {{S}elective{N}et: A Deep Neural Network with an Integrated Reject Option},
  author =       {Geifman, Yonatan and El-Yaniv, Ran},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {2151--2159},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/geifman19a/geifman19a.pdf},
  url = 	 {https://proceedings.mlr.press/v97/geifman19a.html},
  abstract = 	 {We consider the problem of selective prediction (also known as reject option) in deep neural networks, and introduce SelectiveNet, a deep neural architecture with an integrated reject option. Existing rejection mechanisms are based mostly on a threshold over the prediction confidence of a pre-trained network. In contrast, SelectiveNet is trained to optimize both classification (or regression) and rejection simultaneously, end-to-end. The result is a deep neural network that is optimized over the covered domain. In our experiments, we show a consistently improved risk-coverage trade-off over several well-known classification and regression datasets, thus reaching new state-of-the-art results for deep selective classification.}
}


@inproceedings{zhu2022rethinking,
author = {Zhu, Fei and Cheng, Zhen and Zhang, Xu-Yao and Liu, Cheng-Lin},
title = {Rethinking Confidence Calibration for Failure Prediction},
year = {2022},
isbn = {978-3-031-19805-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-19806-9_30},
doi = {10.1007/978-3-031-19806-9_30},
abstract = {Reliable confidence estimation for the predictions is important in many safety-critical applications. However, modern deep neural networks are often overconfident for their incorrect predictions. Recently, many calibration methods have been proposed to alleviate the overconfidence problem. With calibrated confidence, a primary and practical purpose is to detect misclassification errors by filtering out low-confidence predictions (known as failure prediction). In this paper, we find a general, widely-existed but actually-neglected phenomenon that most confidence calibration methods are useless or harmful for failure prediction. We investigate this problem and reveal that popular confidence calibration methods often lead to worse confidence separation between correct and incorrect samples, making it more difficult to decide whether to trust a prediction or not. Finally, inspired by the natural connection between flat minima and confidence separation, we propose a simple hypothesis: flat minima is beneficial for failure prediction. We verify this hypothesis via extensive experiments and further boost the performance by combining two different flat minima techniques. Our code is available at .},
booktitle = {Computer Vision – ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23–27, 2022, Proceedings, Part XXV},
pages = {518–536},
numpages = {19},
keywords = {Selective classification, Misclassification detection, Uncertainty, Flat minima, Confidence calibration, Failure prediction},
location = {Tel Aviv, Israel}
}

@inproceedings{geifman2018biasreduced,
title={Bias-Reduced Uncertainty Estimation for Deep Neural Classifiers},
author={Yonatan Geifman and Guy Uziel and Ran El-Yaniv},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=SJfb5jCqKm},
}