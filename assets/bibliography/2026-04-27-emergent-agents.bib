@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@article{ashery2025emergent,
  title={Emergent social conventions and collective bias in LLM populations},
  author={Ashery, Ariel Flint and Aiello, Luca Maria and Baronchelli, Andrea},
  journal={Science Advances},
  volume={11},
  number={20},
  pages={eadu9368},
  year={2025}
}
@misc{takata2025emergent,
  title        = {Emergent Social Dynamics of {LLM} Agents in the {El Farol Bar Problem}},
  author       = {Ryosuke Takata and Atsushi Masumori and Takashi Ikegami},
  year         = {2025},
  month        = sep,
  eprint       = {2509.04537},
  archivePrefix= {arXiv},
  primaryClass = {cs.MA},
  doi          = {10.48550/arXiv.2509.04537},
  url          = {https://arxiv.org/abs/2509.04537},
  note         = {v3, last revised 17 Sep 2025}
}


@book{russell2013aima,
  author    = {Stuart Russell and Peter Norvig},
  title     = {Artificial Intelligence: A Modern Approach},
  year      = {2013},
  publisher = {Pearson Education Limited},
  address   = {London}
}


@inproceedings{park2023,
author = {Park, Joon Sung and O'Brien, Joseph and Cai, Carrie Jun and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S.},
title = {Generative Agents: Interactive Simulacra of Human Behavior},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586183.3606763},
doi = {10.1145/3586183.3606763},
abstract = {Believable proxies of human behavior can empower interactive applications ranging from immersive environments to rehearsal spaces for interpersonal communication to prototyping tools. In this paper, we introduce generative agents: computational software agents that simulate believable human behavior. Generative agents wake up, cook breakfast, and head to work; artists paint, while authors write; they form opinions, notice each other, and initiate conversations; they remember and reflect on days past as they plan the next day. To enable generative agents, we describe an architecture that extends a large language model to store a complete record of the agent's experiences using natural language, synthesize those memories over time into higher-level reflections, and retrieve them dynamically to plan behavior. We instantiate generative agents to populate an interactive sandbox environment inspired by The Sims, where end users can interact with a small town of twenty-five agents using natural language. In an evaluation, these generative agents produce believable individual and emergent social behaviors. For example, starting with only a single user-specified notion that one agent wants to throw a Valentine's Day party, the agents autonomously spread invitations to the party over the next two days, make new acquaintances, ask each other out on dates to the party, and coordinate to show up for the party together at the right time. We demonstrate through ablation that the components of our agent architecture—observation, planning, and reflection—each contribute critically to the believability of agent behavior. By fusing large language models with computational interactive agents, this work introduces architectural and interaction patterns for enabling believable simulations of human behavior.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {2},
numpages = {22},
keywords = {Human-AI interaction, agents, generative AI, large language models},
location = {San Francisco, CA, USA},
series = {UIST '23}
}

@article{buscemi2025strategic,
  title={Strategic Communication and Language Bias in Multi-Agent LLM Coordination},
  author={Buscemi, Alessio and Proverbio, Daniele and Di Stefano, Alessandro and Han, The Anh and Castignani, German and Li{\`o}, Pietro},
  journal={arXiv preprint arXiv:2508.00032},
  year={2025},
  url={https://arxiv.org/abs/2508.00032}
}

@article{chen2025multi,
  title={Multi-Agent Consensus Seeking via Large Language Models},
  author={Chen, Huaben and Ji, Wenkang and Xu, Lufeng and Zhao, Shiyu},
  journal={arXiv preprint arXiv:2310.20151},
  year={2025},
  url={https://arxiv.org/abs/2310.20151}
}

@article{tran2025multi,
  title={Multi-agent collaboration mechanisms: A survey of LLMs},
  author={Tran, Khanh-Tung and Dao, Dung and Nguyen, Minh-Duong and Pham, Quoc-Viet and O'Sullivan, Barry and Nguyen, Hoang D},
  journal={arXiv preprint arXiv:2501.06322},
  year={2025}
}

@article{vallinder2024cultural,
  title={Cultural Evolution of Cooperation among LLM Agents},
  author={Vallinder, Aron and Hughes, Edward},
  journal={arXiv preprint arXiv:2412.10270},
  year={2024},
  url={https://arxiv.org/abs/2412.10270}
}

@article{wang2024survey,
  title={A survey on large language model based autonomous agents},
  author={Wang, Lei and Ma, Chen and Feng, Xueyang and Zhang, Zeyu and Yang, Hao and Zhang, Jingsen and Chen, Zhiyuan and Tang, Jiakai and Chen, Xu and Lin, Yankai and Zhao, Wayne Xin and Wei, Zhewei and Wen, Jirong},
  journal={Frontiers of Computer Science},
  volume={18},
  number={6},
  pages={186345},
  year={2024},
  month={March}
}

@article{brinkmann2023machine,
  title={Machine culture},
  author={Brinkmann, Levin and Baumann, Fabian and Bonnefon, Jean-Fran\c{c}ois and Derex, Maxime and Muller, Thomas F. and Nussberger, Anne-Marie and Czaplicka, Agnieszka and Acerbi, Alberto and Griffiths, Thomas L. and Henrich, Joseph and Leibo, Joel Z. and McElreath, Richard and Oudeyer, Pierre-Yves and Stray, Jonathan and Rahwan, Iyad},
  journal={Nature Human Behaviour},
  volume={7},
  number={11},
  pages={1855--1868},
  year={2023},
  month={November}
}

@misc{flint2025groupsizeeffectscollective,
      title={Group size effects and collective misalignment in LLM multi-agent systems},
      author={Ariel Flint and Luca Maria Aiello and Romualdo Pastor-Satorras and Andrea Baronchelli},
      year={2025},
      eprint={2510.22422},
      archivePrefix={arXiv},
      primaryClass={cs.MA},
      url={https://arxiv.org/abs/2510.22422},
}

@article{dafoe2020open,
  title={Open Problems in Cooperative AI},
  author={Dafoe, Allan and Hughes, Edward and Bachrach, Yoram and Collins, Tantum and McKee, Kevin R. and Leibo, Joel Z. and Larson, Kate and Graepel, Thore},
  year={2020},
  month={December},
  url={https://arxiv.org/abs/2012.08630}
}

@inproceedings{pan2023machiavelli,
  title={Do the rewards justify the means? Measuring trade-offs between rewards and ethical behavior in the Machiavelli benchmark},
  author={Pan, Alexander and Chan, Jun Shern and Zou, Andy and Li, Nathaniel and Basart, Steven and Woodside, Thomas and Zhang, Hanlin and Emmons, Scott and Hendrycks, Dan},
  booktitle={Proceedings of the 40th International Conference on Machine Learning},
  editor={Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  series={Proceedings of Machine Learning Research},
  volume={202},
  pages={26837--26867},
  year={2023},
  month={July},
  publisher={PMLR}
}

@article{anwar2024foundational,
  title={Foundational Challenges in Assuring Alignment and Safety of Large Language Models},
  author={Anwar, Usman and Saparov, Abulhair and Rando, Javier and Paleka, Daniel and Turpin, Miles and Hase, Peter and Lubana, Ekdeep Singh and Jenner, Erik and Casper, Stephen and Sourbut, Oliver and Edelman, Benjamin L. and Zhang, Zhaowei and Gunther, Mario and Korinek, Anton and Hernandez-Orallo, Jose and Hammond, Lewis and Bigelow, Eric and Pan, Alexander and Langosco, Lauro and Korbak, Tomasz and Zhang, Heidi and Zhong, Ruiqi and {\'O} h{\'E}igeartaigh, Sean and Recchia, Gabriel and Corsi, Giulio and Chan, Alan and Anderljung, Markus and Edwards, Lilian and Bengio, Yoshua and Chen, Danqi and Albanie, Samuel and Maharaj, Tegan and Foerster, Jakob and Tramer, Florian and He, He and Kasirzadeh, Atoosa and Choi, Yejin and Krueger, David},
  year={2024},
  month={April},
  url={https://arxiv.org/abs/2404.09992}
}

@misc{ferraro2024agentbasedmodellingmeetsgenerative,
      title={Agent-Based Modelling Meets Generative AI in Social Network Simulations},
      author={Antonino Ferraro and Antonio Galli and Valerio La Gatta and Marco Postiglione and Gian Marco Orlando and Diego Russo and Giuseppe Riccio and Antonio Romano and Vincenzo Moscato},
      year={2024},
      eprint={2411.16031},
      archivePrefix={arXiv},
      primaryClass={cs.SI},
      url={https://arxiv.org/abs/2411.16031},
}

@misc{orlando2025emergentcoordinatedbehaviorsnetworked,
      title={Emergent Coordinated Behaviors in Networked LLM Agents: Modeling the Strategic Dynamics of Information Operations},
      author={Gian Marco Orlando and Jinyi Ye and Valerio La Gatta and Mahdi Saeedi and Vincenzo Moscato and Emilio Ferrara and Luca Luceri},
      year={2025},
      eprint={2510.25003},
      archivePrefix={arXiv},
      primaryClass={cs.MA},
      url={https://arxiv.org/abs/2510.25003},
}

@misc{willis2025systemsllmagentscooperate,
      title={Will Systems of LLM Agents Cooperate: An Investigation into a Social Dilemma},
      author={Richard Willis and Yali Du and Joel Z Leibo and Michael Luck},
      year={2025},
      eprint={2501.16173},
      archivePrefix={arXiv},
      primaryClass={cs.MA},
      url={https://arxiv.org/abs/2501.16173},
}

@misc{ren2024emergencesocialnormsgenerative,
      title={Emergence of Social Norms in Generative Agent Societies: Principles and Architecture},
      author={Siyue Ren and Zhiyao Cui and Ruiqi Song and Zhen Wang and Shuyue Hu},
      year={2024},
      eprint={2403.08251},
      archivePrefix={arXiv},
      primaryClass={cs.MA},
      url={https://arxiv.org/abs/2403.08251},
}

@misc{schmidgall2025agentlaboratoryusingllm,
      title={Agent Laboratory: Using LLM Agents as Research Assistants},
      author={Samuel Schmidgall and Yusheng Su and Ze Wang and Ximeng Sun and Jialian Wu and Xiaodong Yu and Jiang Liu and Michael Moor and Zicheng Liu and Emad Barsoum},
      year={2025},
      eprint={2501.04227},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      url={https://arxiv.org/abs/2501.04227},
}

@misc{pan2023rewardsjustifymeansmeasuring,
      title={Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards and Ethical Behavior in the MACHIAVELLI Benchmark},
      author={Alexander Pan and Jun Shern Chan and Andy Zou and Nathaniel Li and Steven Basart and Thomas Woodside and Jonathan Ng and Hanlin Zhang and Scott Emmons and Dan Hendrycks},
      year={2023},
      eprint={2304.03279},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2304.03279},
}


@misc{sumers2024cognitivearchitectureslanguageagents,
      title={Cognitive Architectures for Language Agents},
      author={Theodore R. Sumers and Shunyu Yao and Karthik Narasimhan and Thomas L. Griffiths},
      year={2024},
      eprint={2309.02427},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2309.02427},
}

@article{DU2025105439,
title = {Emergent cooperative decision-making in triadic Prisoner's Dilemmas: Effects of incentives and information},
journal = {Acta Psychologica},
volume = {260},
pages = {105439},
year = {2025},
issn = {0001-6918},
doi = {https://doi.org/10.1016/j.actpsy.2025.105439},
url = {https://www.sciencedirect.com/science/article/pii/S0001691825007528},
author = {Yinuo Du and Kuldeep Singh and Palvi Aggarwal and Fei Fang and Cleotilde Gonzalez},
keywords = {Prisoner's Dilemma, Triads, Cooperation, Reciprocity, Strategy, Simulation},
abstract = {While pairwise cooperation has been extensively studied through the Prisoner's Dilemma (PD), our understanding of how cooperation emerges in small groups remains limited. We extend the classic dyadic PD framework to a triadic framework, examining two sets of PD games per individual and how individual strategies and relationships aggregate to group cooperation. Through two experiments (N=519), we investigate: (1) how structural incentives shape cooperation by varying the K-index (0.4/0.8), a theoretical value that predicts greater cooperation for higher K values, and (2) how different degrees of information about mutual interdependence affect group behavior. We find that, under minimal information conditions, a higher K-index promotes sustained cooperation in the triadic setting, in alignment with the theoretical definition of the K-index. However, while experiential information (observing others' actions/outcomes) enhances cooperation, descriptive information (complete payoff matrices) paradoxically reduces cooperation. Analysis of triadic interactions reveals that selective cooperation by a third player in the group can stabilize cooperative dyadic relationships and destabilize defective dyadic relationships. These findings provide insights for designing cooperative systems, particularly in contexts where organizations must balance information sharing benefits against strategic risks.}
}

@misc{williams2023epidemicmodelinggenerativeagents,
      title={Epidemic Modeling with Generative Agents},
      author={Ross Williams and Niyousha Hosseinichimeh and Aritra Majumdar and Navid Ghaffarzadegan},
      year={2023},
      eprint={2307.04986},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2307.04986},
}

@misc{li2025agenthospitalsimulacrumhospital,
      title={Agent Hospital: A Simulacrum of Hospital with Evolvable Medical Agents},
      author={Junkai Li and Yunghwei Lai and Weitao Li and Jingyi Ren and Meng Zhang and Xinhui Kang and Siyu Wang and Peng Li and Ya-Qin Zhang and Weizhi Ma and Yang Liu},
      year={2025},
      eprint={2405.02957},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2405.02957},
}

@book{helbing2012social,
  editor    = {Helbing, Dirk},
  title     = {Social Self-Organization: Agent-Based Simulations and Experiments to Study Emergent Social Behavior},
  series    = {Understanding Complex Systems},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  year      = {2012},
  doi       = {10.1007/978-3-642-24004-1}
}

@article{watts1998collective,
  title={Collective dynamics of 'small-world'networks},
  author={Watts, Duncan J and Strogatz, Steven H},
  journal={nature},
  volume={393},
  number={6684},
  pages={440--442},
  year={1998},
  publisher={Nature Publishing Group}
}

@article{rosas_pedro_emergence_2020,
    doi = {10.1371/journal.pcbi.1008289},
    author = {Rosas, Fernando E. AND Mediano, Pedro A. M. AND Jensen, Henrik J. AND Seth, Anil K. AND Barrett, Adam B. AND Carhart-Harris, Robin L. AND Bor, Daniel},
    journal = {PLOS Computational Biology},
    publisher = {Public Library of Science},
    title = {Reconciling emergences: An information-theoretic approach to identify causal emergence in multivariate data},
    year = {2020},
    month = {12},
    volume = {16},
    url = {https://doi.org/10.1371/journal.pcbi.1008289},
    pages = {1-22},
    abstract = {The broad concept of emergence is instrumental in various of the most challenging open scientific questions—yet, few quantitative theories of what constitutes emergent phenomena have been proposed. This article introduces a formal theory of causal emergence in multivariate systems, which studies the relationship between the dynamics of parts of a system and macroscopic features of interest. Our theory provides a quantitative definition of downward causation, and introduces a complementary modality of emergent behaviour—which we refer to as causal decoupling. Moreover, the theory allows practical criteria that can be efficiently calculated in large systems, making our framework applicable in a range of scenarios of practical interest. We illustrate our findings in a number of case studies, including Conway's Game of Life, Reynolds' flocking model, and neural activity as measured by electrocorticography.},
    number = {12},

}

@misc{carichon2025comingcrisismultiagentmisalignment,
      title={The Coming Crisis of Multi-Agent Misalignment: AI Alignment Must Be a Dynamic and Social Process},
      author={Florian Carichon and Aditi Khandelwal and Marylou Fauchard and Golnoosh Farnadi},
      year={2025},
      eprint={2506.01080},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2506.01080},
}

@article{rapoport1967note,
  title={A note on the" index of cooperation" for prisoner's dilemma},
  author={Rapoport, Anatol},
  journal={Journal of Conflict Resolution},
  volume={11},
  number={1},
  pages={100--103},
  year={1967},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}

@article{PhysRevE.67.026112,
  title = {Hierarchical organization in complex networks},
  author = {Ravasz, Erzs\'ebet and Barab\'asi, Albert-L\'aszl\'o},
  journal = {Phys. Rev. E},
  volume = {67},
  issue = {2},
  pages = {026112},
  numpages = {7},
  year = {2003},
  month = {Feb},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.67.026112},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.67.026112}
}

@article{LU2024283,
title = {LLMs and generative agent-based models for complex systems research},
journal = {Physics of Life Reviews},
volume = {51},
pages = {283-293},
year = {2024},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2024.10.013},
url = {https://www.sciencedirect.com/science/article/pii/S1571064524001386},
author = {Yikang Lu and Alberto Aleta and Chunpeng Du and Lei Shi and Yamir Moreno},
abstract = {The advent of Large Language Models (LLMs) offers to transform research across natural and social sciences, offering new paradigms for understanding complex systems. In particular, Generative Agent-Based Models (GABMs), which integrate LLMs to simulate human behavior, have attracted increasing public attention due to their potential to model complex interactions in a wide range of artificial environments. This paper briefly reviews the disruptive role LLMs are playing in fields such as network science, evolutionary game theory, social dynamics, and epidemic modeling. We assess recent advancements, including the use of LLMs for predicting social behavior, enhancing cooperation in game theory, and modeling disease propagation. The findings demonstrate that LLMs can reproduce human-like behaviors, such as fairness, cooperation, and social norm adherence, while also introducing unique advantages such as cost efficiency, scalability, and ethical simplification. However, the results reveal inconsistencies in their behavior tied to prompt sensitivity, hallucinations and even the model characteristics, pointing to challenges in controlling these AI-driven agents. Despite their potential, the effective integration of LLMs into decision-making processes —whether in government, societal, or individual contexts— requires addressing biases, prompt design challenges, and understanding the dynamics of human-machine interactions. Future research must refine these models, standardize methodologies, and explore the emergence of new cooperative behaviors as LLMs increasingly interact with humans and each other, potentially transforming how decisions are made across various systems.}
}
