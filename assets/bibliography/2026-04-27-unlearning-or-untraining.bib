@article{power2022grokking,
  title={Grokking: Generalization beyond overfitting on small algorithmic datasets},
  author={Power, Alethea and Burda, Yuri and Edwards, Harri and Babuschkin, Igor and Misra, Vedant},
  journal={arXiv preprint arXiv:2201.02177},
  year={2022}
}

@inproceedings{liu2023omnigrok,
  title={Omnigrok: Grokking Beyond Algorithmic Data},
  author={Ziming Liu and Eric J Michaud and Max Tegmark},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2023},
  url={https://openreview.net/forum?id=zDiHoIWa0q1}
}

@inproceedings{humayun2024grok,
  author = {Humayun, Ahmed Imtiaz and Balestriero, Randall and Baraniuk, Richard},
  title = {Deep networks always grok and here is why},
  year = {2024},
  booktitle = {Proceedings of the 41st International Conference on Machine Learning}
}

@inproceedings{foret2021sharpnessaware,
  title={Sharpness-aware Minimization for Efficiently Improving Generalization},
  author={Pierre Foret and Ariel Kleiner and Hossein Mobahi and Behnam Neyshabur},
  booktitle={International Conference on Learning Representations},
  year={2021},
  url={https://openreview.net/forum?id=6Tm1mposlrM}
}

@inproceedings{miyato2018spectral,
  title={Spectral Normalization for Generative Adversarial Networks},
  author={Takeru Miyato and Toshiki Kataoka and Masanori Koyama and Yuichi Yoshida},
  booktitle={International Conference on Learning Representations},
  year={2018},
  url={https://openreview.net/forum?id=B1QRgziT-}
}

@article{gouk2021regularisation,
  title={Regularisation of neural networks by enforcing lipschitz continuity},
  author={Gouk, Henry and Frank, Eibe and Pfahringer, Bernhard and Cree, Michael J},
  journal={Machine Learning},
  volume={110},
  number={2},
  pages={393--416},
  year={2021},
  publisher={Springer}
}

@article{zhang2017mixup,
  title={mixup: Beyond empirical risk minimization},
  author={Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N and Lopez-Paz, David},
  journal={arXiv preprint arXiv:1710.09412},
  year={2017}
}

@inproceedings{Izmailov2018AveragingWL,
  title={Averaging Weights Leads to Wider Optima and Better Generalization},
  author={Pavel Izmailov and Dmitrii Podoprikhin and T. Garipov and Dmitry P. Vetrov and Andrew Gordon Wilson},
  booktitle={Conference on Uncertainty in Artificial Intelligence},
  year={2018},
  url={https://api.semanticscholar.org/CorpusID:3833416}
}

@book{vapnik2013nature,
  title={The nature of statistical learning theory},
  author={Vapnik, Vladimir},
  year={2013},
  publisher={Springer science \& business media}
}

@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  year={2019}
}

@inproceedings{koh2017understanding,
  title={Understanding black-box predictions via influence functions},
  author={Koh, Pang Wei and Liang, Percy},
  booktitle={International conference on machine learning},
  pages={1885--1894},
  year={2017},
  organization={PMLR}
}

@article{paul2021deep,
  title={Deep learning on a data diet: Finding important examples early in training},
  author={Paul, Mansheej and Ganguli, Surya and Dziugaite, Gintare Karolina},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={20596--20607},
  year={2021}
}

@inproceedings{feldman2020does,
  title={Does learning require memorization? a short tale about a long tail},
  author={Feldman, Vitaly},
  booktitle={Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing},
  pages={954--959},
  year={2020}
}

@article{feldman2020neural,
  title={What neural networks memorize and why: Discovering the long tail via influence estimation},
  author={Feldman, Vitaly and Zhang, Chiyuan},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={2881--2891},
  year={2020}
}

@article{jiang2020characterizing,
  title={Characterizing structural regularities of labeled data in overparameterized models},
  author={Jiang, Ziheng and Zhang, Chiyuan and Talwar, Kunal and Mozer, Michael C},
  journal={arXiv preprint arXiv:2002.03206},
  year={2020}
}

@article{zhang2023counterfactual,
  title={Counterfactual memorization in neural language models},
  author={Zhang, Chiyuan and Ippolito, Daphne and Lee, Katherine and Jagielski, Matthew and Tram{\`e}r, Florian and Carlini, Nicholas},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={39321--39362},
  year={2023}
}

@article{bae2022if,
  title={If influence functions are the answer, then what is the question?},
  author={Bae, Juhan and Ng, Nathan and Lo, Alston and Ghassemi, Marzyeh and Grosse, Roger B},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={17953--17967},
  year={2022}
}

@inproceedings{barshan2020relatif,
  title={Relatif: Identifying explanatory training samples via relative influence},
  author={Barshan, Elnaz and Brunet, Marc-Etienne and Dziugaite, Gintare Karolina},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1899--1909},
  year={2020},
  organization={PMLR}
}

@article{triantafillou2024we,
  title={Are we making progress in unlearning? findings from the first neurips unlearning competition},
  author={Triantafillou, Eleni and Kairouz, Peter and Pedregosa, Fabian and Hayes, Jamie and Kurmanji, Meghdad and Zhao, Kairan and Dumoulin, Vincent and Junior, Julio Jacques and Mitliagkas, Ioannis and Wan, Jun and others},
  journal={arXiv preprint arXiv:2406.09073},
  year={2024}
}

@article{zhang2020casia,
  title={Casia-surf: A large-scale multi-modal benchmark for face anti-spoofing},
  author={Zhang, Shifeng and Liu, Ajian and Wan, Jun and Liang, Yanyan and Guo, Guodong and Escalera, Sergio and Escalante, Hugo Jair and Li, Stan Z},
  journal={IEEE Transactions on Biometrics, Behavior, and Identity Science},
  year={2020},
  publisher={IEEE}
}

@article{sekhari2021remember,
  title={Remember what you want to forget: Algorithms for machine unlearning},
  author={Sekhari, Ayush and Acharya, Jayadev and Kamath, Gautam and Suresh, Ananda Theertha},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={18075--18086},
  year={2021}
}

@inproceedings{kairouz2015composition,
  title={The composition theorem for differential privacy},
  author={Kairouz, Peter and Oh, Sewoong and Viswanath, Pramod},
  booktitle={International conference on machine learning},
  pages={1376--1385},
  year={2015},
  organization={PMLR}
}

@inproceedings{carlini2022membership,
  title={Membership inference attacks from first principles},
  author={Carlini, Nicholas and Chien, Steve and Nasr, Milad and Song, Shuang and Terzis, Andreas and Tramer, Florian},
  booktitle={2022 IEEE Symposium on Security and Privacy (SP)},
  pages={1897--1914},
  year={2022},
  organization={IEEE}
}

@inproceedings{shokri2017membership,
  title={Membership inference attacks against machine learning models},
  author={Shokri, Reza and Stronati, Marco and Song, Congzheng and Shmatikov, Vitaly},
  booktitle={2017 IEEE symposium on security and privacy (SP)},
  pages={3--18},
  year={2017},
  organization={IEEE}
}

@article{jagielski2020auditing,
  title={Auditing differentially private machine learning: How private is private sgd?},
  author={Jagielski, Matthew and Ullman, Jonathan and Oprea, Alina},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={22205--22216},
  year={2020}
}

@article{gupta2021adaptive,
  title={Adaptive machine unlearning},
  author={Gupta, Varun and Jung, Christopher and Neel, Seth and Roth, Aaron and Sharifi-Malvajerdi, Saeed and Waites, Chris},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={16319--16330},
  year={2021}
}

@inproceedings{neel2021descent,
  title={Descent-to-delete: Gradient-based methods for machine unlearning},
  author={Neel, Seth and Roth, Aaron and Sharifi-Malvajerdi, Saeed},
  booktitle={Algorithmic Learning Theory},
  pages={931--962},
  year={2021},
  organization={PMLR}
}

@article{nasr2023tight,
  title={Tight Auditing of Differentially Private Machine Learning},
  author={Nasr, Milad and Hayes, Jamie and Steinke, Thomas and Balle, Borja and Tram{\`e}r, Florian and Jagielski, Matthew and Carlini, Nicholas and Terzis, Andreas},
  journal={arXiv preprint arXiv:2302.07956},
  year={2023}
}

@inproceedings{nasr2021adversary,
  title={Adversary instantiation: Lower bounds for differentially private machine learning},
  author={Nasr, Milad and Songi, Shuang and Thakurta, Abhradeep and Papernot, Nicolas and Carlin, Nicholas},
  booktitle={2021 IEEE Symposium on security and privacy (SP)},
  pages={866--882},
  year={2021},
  organization={IEEE}
}

@article{steinke2023privacy,
  title={Privacy Auditing with One (1) Training Run},
  author={Steinke, Thomas and Nasr, Milad and Jagielski, Matthew},
  journal={arXiv preprint arXiv:2305.08846},
  year={2023}
}

@article{pillutla2023unleashing,
  title={Unleashing the Power of Randomization in Auditing Differentially Private ML},
  author={Pillutla, Krishna and Andrew, Galen and Kairouz, Peter and McMahan, H Brendan and Oprea, Alina and Oh, Sewoong},
  journal={arXiv preprint arXiv:2305.18447},
  year={2023}
}

@article{andrew2023one,
  title={One-shot Empirical Privacy Estimation for Federated Learning},
  author={Andrew, Galen and Kairouz, Peter and Oh, Sewoong and Oprea, Alina and McMahan, H Brendan and Suriyakumar, Vinith},
  journal={arXiv preprint arXiv:2302.03098},
  year={2023}
}

@inproceedings{golatkar2020eternal,
  title={Eternal sunshine of the spotless net: Selective forgetting in deep networks},
  author={Golatkar, Aditya and Achille, Alessandro and Soatto, Stefano},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9304--9312},
  year={2020}
}

@inproceedings{thudi2022unrolling,
  title={Unrolling sgd: Understanding factors influencing machine unlearning},
  author={Thudi, Anvith and Deza, Gabriel and Chandrasekaran, Varun and Papernot, Nicolas},
  booktitle={2022 IEEE 7th European Symposium on Security and Privacy (EuroS\&P)},
  pages={303--319},
  year={2022},
  organization={IEEE}
}

@inproceedings{wu2020deltagrad,
  title={Deltagrad: Rapid retraining of machine learning models},
  author={Wu, Yinjun and Dobriban, Edgar and Davidson, Susan},
  booktitle={International Conference on Machine Learning},
  pages={10355--10366},
  year={2020},
  organization={PMLR}
}

@article{goel2024corrective,
  title={Corrective Machine Unlearning},
  author={Goel, Shashwat and Prabhu, Ameya and Torr, Philip and Kumaraguru, Ponnurangam and Sanyal, Amartya},
  journal={arXiv preprint arXiv:2402.14015},
  year={2024}
}

@article{kurmanji2024towards,
  title={Towards unbounded machine unlearning},
  author={Kurmanji, Meghdad and Triantafillou, Peter and Hayes, Jamie and Triantafillou, Eleni},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{shah2023unlearning,
  title={Unlearning via Sparse Representations},
  author={Shah, Vedant and Tr{\"a}uble, Frederik and Malik, Ashish and Larochelle, Hugo and Mozer, Michael and Arora, Sanjeev and Bengio, Yoshua and Goyal, Anirudh},
  journal={arXiv preprint arXiv:2311.15268},
  year={2023}
}

@article{goel2022towards,
  title={Towards adversarial evaluations for inexact machine unlearning},
  author={Goel, Shashwat and Prabhu, Ameya and Sanyal, Amartya and Lim, Ser-Nam and Torr, Philip and Kumaraguru, Ponnurangam},
  journal={arXiv preprint arXiv:2201.06640},
  year={2022}
}

@article{fan2023salun,
  title={Salun: Empowering machine unlearning via gradient-based weight saliency in both image classification and generation},
  author={Fan, Chongyu and Liu, Jiancheng and Zhang, Yihua and Wei, Dennis and Wong, Eric and Liu, Sijia},
  journal={arXiv preprint arXiv:2310.12508},
  year={2023}
}

@inproceedings{golatkar2020forgetting,
  title={Forgetting outside the box: Scrubbing deep networks of information accessible from input-output observations},
  author={Golatkar, Aditya and Achille, Alessandro and Soatto, Stefano},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XXIX 16},
  pages={383--398},
  year={2020},
  organization={Springer}
}

@article{liu2024model,
  title={Model sparsity can simplify machine unlearning},
  author={Liu, Jiancheng and Ram, Parikshit and Yao, Yuguang and Liu, Gaowen and Liu, Yang and SHARMA, PRANAY and Liu, Sijia and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{kodge2023deep,
  title={Deep Unlearning: Fast and Efficient Training-free Approach to Controlled Forgetting},
  author={Kodge, Sangamesh and Saha, Gobinda and Roy, Kaushik},
  journal={arXiv preprint arXiv:2312.00761},
  year={2023}
}

@article{pawelczyk2023context,
  title={In-context unlearning: Language models as few shot unlearners},
  author={Pawelczyk, Martin and Neel, Seth and Lakkaraju, Himabindu},
  journal={arXiv preprint arXiv:2310.07579},
  year={2023}
}

@article{hayes2024inexact,
  title={Inexact Unlearning Needs More Careful Evaluations to Avoid a False Sense of Privacy},
  author={Hayes, Jamie and Shumailov, Ilia and Triantafillou, Eleni and Khalifa, Amr and Papernot, Nicolas},
  journal={arXiv preprint arXiv:2403.01218},
  year={2024}
}

@article{cotogni2023duck,
  title={DUCK: Distance-based Unlearning via Centroid Kinematics},
  author={Cotogni, Marco and Bonato, Jacopo and Sabetta, Luigi and Pelosin, Francesco and Nicolosi, Alessandro},
  journal={arXiv preprint arXiv:2312.02052},
  year={2023}
}


@inproceedings{dwork2006differential,
  title={Differential privacy},
  author={Dwork, Cynthia},
  booktitle={International colloquium on automata, languages, and programming},
  pages={1--12},
  year={2006},
  organization={Springer}
}

@article{caldas2018leaf,
  title={Leaf: A benchmark for federated settings},
  author={Caldas, Sebastian and Duddu, Sai Meher Karthik and Wu, Peter and Li, Tian and Kone{\v{c}}n{\`y}, Jakub and McMahan, H Brendan and Smith, Virginia and Talwalkar, Ameet},
  journal={arXiv preprint arXiv:1812.01097},
  year={2018}
}

@inproceedings{sablayrolles2019white,
  title={White-box vs black-box: Bayes optimal strategies for membership inference},
  author={Sablayrolles, Alexandre and Douze, Matthijs and Schmid, Cordelia and Ollivier, Yann and J{\'e}gou, Herv{\'e}},
  booktitle={International Conference on Machine Learning},
  pages={5558--5567},
  year={2019},
  organization={PMLR}
}

@article{fan2024challenging,
  title={Challenging forgets: Unveiling the worst-case forget sets in machine unlearning},
  author={Fan, Chongyu and Liu, Jiancheng and Hero, Alfred and Liu, Sijia},
  journal={arXiv preprint arXiv:2403.07362},
  year={2024}
}

@inproceedings{bourtoule2021machine,
  title={Machine unlearning},
  author={Bourtoule, Lucas and Chandrasekaran, Varun and Choquette-Choo, Christopher A and Jia, Hengrui and Travers, Adelin and Zhang, Baiwu and Lie, David and Papernot, Nicolas},
  booktitle={2021 IEEE symposium on security and privacy (SP)},
  pages={141--159},
  year={2021},
  organization={IEEE}
}

@inproceedings{cao2015towards,
  title={Towards making systems forget with machine unlearning},
  author={Cao, Yinzhi and Yang, Junfeng},
  booktitle={2015 IEEE symposium on security and privacy},
  pages={463--480},
  year={2015},
  organization={IEEE}
}

@article{lynch2024eight,
  title={Eight methods to evaluate robust unlearning in llms},
  author={Lynch, Aengus and Guo, Phillip and Ewart, Aidan and Casper, Stephen and Hadfield-Menell, Dylan},
  journal={arXiv preprint arXiv:2402.16835},
  year={2024}
}

@article{liu2024towards,
  title={Towards safer large language models through machine unlearning},
  author={Liu, Zheyuan and Dou, Guangyao and Tan, Zhaoxuan and Tian, Yijun and Jiang, Meng},
  journal={arXiv preprint arXiv:2402.10058},
  year={2024}
}

@article{yao2024large,
  title={Large language model unlearning},
  author={Yao, Yuanshun and Xu, Xiaojun and Liu, Yang},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={105425--105475},
  year={2024}
}

@article{li2024wmdp,
  title={The wmdp benchmark: Measuring and reducing malicious use with unlearning},
  author={Li, Nathaniel and Pan, Alexander and Gopal, Anjali and Yue, Summer and Berrios, Daniel and Gatti, Alice and Li, Justin D and Dombrowski, Ann-Kathrin and Goel, Shashwat and Phan, Long and others},
  journal={arXiv preprint arXiv:2403.03218},
  year={2024}
}

@inproceedings{zhang2024forget,
  title={Forget-me-not: Learning to forget in text-to-image diffusion models},
  author={Zhang, Gong and Wang, Kai and Xu, Xingqian and Wang, Zhangyang and Shi, Humphrey},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={1755--1764},
  year={2024}
}

@article{lucki2024adversarial,
  title={An adversarial perspective on machine unlearning for ai safety},
  author={{\L}ucki, Jakub and Wei, Boyi and Huang, Yangsibo and Henderson, Peter and Tram{\`e}r, Florian and Rando, Javier},
  journal={arXiv preprint arXiv:2409.18025},
  year={2024}
}

@article{barez2025open,
  title={Open problems in machine unlearning for ai safety},
  author={Barez, Fazl and Fu, Tingchen and Prabhu, Ameya and Casper, Stephen and Sanyal, Amartya and Bibi, Adel and O'Gara, Aidan and Kirk, Robert and Bucknall, Ben and Fist, Tim and others},
  journal={arXiv preprint arXiv:2501.04952},
  year={2025}
}

@article{zhao2024makes,
  title={What makes unlearning hard and what to do about it},
  author={Zhao, Kairan and Kurmanji, Meghdad and B{\u{a}}rbulescu, George-Octavian and Triantafillou, Eleni and Triantafillou, Peter},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={12293--12333},
  year={2024}
}

@book{jaeckel1972infinitesimal,
  title={The infinitesimal jackknife},
  author={Jaeckel, Louis A},
  year={1972},
  publisher={Bell Telephone Laboratories}
}

@article{pruthi2020estimating,
  title={Estimating training data influence by tracing gradient descent},
  author={Pruthi, Garima and Liu, Frederick and Kale, Satyen and Sundararajan, Mukund},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={19920--19930},
  year={2020}
}

@article{attias2024information,
  title={Information complexity of stochastic convex optimization: Applications to generalization and memorization},
  author={Attias, Idan and Dziugaite, Gintare Karolina and Haghifam, Mahdi and Livni, Roi and Roy, Daniel M},
  journal={arXiv preprint arXiv:2402.09327},
  year={2024}
}

@inproceedings{carlini2021extracting,
  title={Extracting training data from large language models},
  author={Carlini, Nicholas and Tramer, Florian and Wallace, Eric and Jagielski, Matthew and Herbert-Voss, Ariel and Lee, Katherine and Roberts, Adam and Brown, Tom and Song, Dawn and Erlingsson, Ulfar and others},
  booktitle={30th USENIX security symposium (USENIX Security 21)},
  pages={2633--2650},
  year={2021}
}

@inproceedings{liu2022backdoor,
  title={Backdoor defense with machine unlearning},
  author={Liu, Yang and Fan, Mingyuan and Chen, Cen and Liu, Ximeng and Ma, Zhuo and Wang, Li and Ma, Jianfeng},
  booktitle={IEEE INFOCOM 2022-IEEE conference on computer communications},
  pages={280--289},
  year={2022},
  organization={IEEE}
}

@article{schoepf2024potion,
  title={Potion: Towards poison unlearning},
  author={Schoepf, Stefan and Foster, Jack and Brintrup, Alexandra},
  journal={arXiv preprint arXiv:2406.09173},
  year={2024}
}

@article{schoepf2025redirection,
  title={Redirection for Erasing Memory (REM): Towards a universal unlearning method for corrupted data},
  author={Schoepf, Stefan and Mozer, Michael Curtis and Mitchell, Nicole Elyse and Brintrup, Alexandra and Kaissis, Georgios and Kairouz, Peter and Triantafillou, Eleni},
  journal={arXiv preprint arXiv:2505.17730},
  year={2025}
}

@article{eldan2023s,
  title={Whoâ€™s harry potter? approximate unlearning for LLMs},
  author={Eldan, Ronen and Russinovich, Mark},
  year={2023}
}

@inproceedings{yoon2024few,
  title={Few-shot Unlearning},
  author={Yoon, Youngsik and Nam, Jinhwan and Yun, Hyojeong and Lee, Jaeho and Kim, Dongwoo and Ok, Jungseul},
  booktitle={2024 IEEE Symposium on Security and Privacy (SP)},
  pages={3276--3292},
  year={2024},
  organization={IEEE}
}

@article{de2024unlearning,
  title={Unlearning personal data from a single image},
  author={De Min, Thomas and Mancini, Massimiliano and Lathuili{\`e}re, St{\'e}phane and Roy, Subhankar and Ricci, Elisa},
  journal={arXiv preprint arXiv:2407.12069},
  year={2024}
}


@article{pawelczyk2024machine,
  title={Machine unlearning fails to remove data poisoning attacks},
  author={Pawelczyk, Martin and Di, Jimmy Z and Lu, Yiwei and Sekhari, Ayush and Kamath, Gautam and Neel, Seth},
  journal={arXiv preprint arXiv:2406.17216},
  year={2024}
}

@article{cooper2024machine,
  title={Machine Unlearning Doesn't Do What You Think: Lessons for Generative AI Policy, Research, and Practice},
  author={Cooper, A Feder and Choquette-Choo, Christopher A and Bogen, Miranda and Jagielski, Matthew and Filippova, Katja and Liu, Ken Ziyu and Chouldechova, Alexandra and Hayes, Jamie and Huang, Yangsibo and Mireshghallah, Niloofar and others},
  journal={arXiv preprint arXiv:2412.06966},
  year={2024}
}

@article{shumailov2024ununlearning,
  title={Ununlearning: Unlearning is not sufficient for content regulation in advanced generative ai},
  author={Shumailov, Ilia and Hayes, Jamie and Triantafillou, Eleni and Ortiz-Jimenez, Guillermo and Papernot, Nicolas and Jagielski, Matthew and Yona, Itay and Howard, Heidi and Bagdasaryan, Eugene},
  journal={arXiv preprint arXiv:2407.00106},
  year={2024}
}

@article{shi2024muse,
  title={Muse: Machine unlearning six-way evaluation for language models},
  author={Shi, Weijia and Lee, Jaechan and Huang, Yangsibo and Malladi, Sadhika and Zhao, Jieyu and Holtzman, Ari and Liu, Daogao and Zettlemoyer, Luke and Smith, Noah A and Zhang, Chiyuan},
  journal={arXiv preprint arXiv:2407.06460},
  year={2024}
}


@article{siddiqui2025dormant,
  title={From Dormant to Deleted: Tamper-Resistant Unlearning Through Weight-Space Regularization},
  author={Siddiqui, Shoaib Ahmed and Weller, Adrian and Krueger, David and Dziugaite, Gintare Karolina and Mozer, Michael Curtis and Triantafillou, Eleni},
  journal={arXiv preprint arXiv:2505.22310},
  year={2025}
}

@article{hu2024unlearning,
  title={Unlearning or obfuscating? jogging the memory of unlearned llms via benign relearning},
  author={Hu, Shengyuan and Fu, Yiwei and Wu, Zhiwei Steven and Smith, Virginia},
  journal={arXiv preprint arXiv:2406.13356},
  year={2024}
}

@article{deeb2024unlearning,
  title={Do unlearning methods remove information from language model weights?},
  author={Deeb, Aghyad and Roger, Fabien},
  journal={arXiv preprint arXiv:2410.08827},
  year={2024}
}

@article{che2025model,
  title={Model tampering attacks enable more rigorous evaluations of llm capabilities},
  author={Che, Zora and Casper, Stephen and Kirk, Robert and Satheesh, Anirudh and Slocum, Stewart and McKinney, Lev E and Gandikota, Rohit and Ewart, Aidan and Rosati, Domenic and Wu, Zichu and others},
  journal={arXiv preprint arXiv:2502.05209},
  year={2025}
}

@article{zhang2024unlearncanvas,
  title={Unlearncanvas: A stylized image dataset to benchmark machine unlearning for diffusion models},
  author={Zhang, Yihua and Zhang, Yimeng and Yao, Yuguang and Jia, Jinghan and Liu, Jiancheng and Liu, Xiaoming and Liu, Sijia},
  journal={CoRR},
  year={2024}
}