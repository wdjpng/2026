@article{ahmad2021plbart,
  title={Unified Pre-training for Program Understanding and Generation},
  author={Ahmad, Wasi Uddin and Chakraborty, Saikat and Ray, Baishakhi and Chang, Kai-Wei},
  journal={arXiv preprint, arXiv:2103.06333},
  year={2021},
  url={https://arxiv.org/abs/2103.06333}
}

@article{chen2021codex,
  title={Evaluating Large Language Models Trained on Code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and De Oliveira Pinto, Henrique Ponde and Kaplan, Jared and Edwards, Harri and others},
  journal={arXiv preprint, arXiv:2107.03374},
  year={2021},
  url={https://arxiv.org/abs/2107.03374}
}

@article{jimenez2023swebench,
  title={SWE-bench: Can Language Models Resolve Real-World GitHub Issues?},
  author={Jimenez, Carlos E. and Yang, John and Wettig, Alexander and Yao, Shunyu and Pei, Kexin and Press, Ofir and Narasimhan, Karthik},
  journal={arXiv preprint, arXiv:2310.06770},
  year={2023},
  url={https://arxiv.org/abs/2310.06770}
}

@article{openai2024swebenchverified,
  title={Introducing SWE Bench Verified},
  author={OpenAI-Research},
  journal={OpenAI Blog},
  year={2024},
  url={https://openai.com/index/introducing-swe-bench-verified/}
}

@article{terminalbench2024,
  title={Terminal Bench},
  author={TerminalBench-Team},
  journal={TerminalBench Leaderboard},
  year={2024},
  url={https://www.tbench.ai/leaderboard/terminal-bench/2.0}
}

@article{anthropic2025claudecode,
  title={@anthropic-ai/claude-code},
  author={Anthropic-Research},
  journal={npm package},
  year={2025},
  url={https://www.npmjs.com/package/@anthropic-ai/claude-code}
}

@article{steipete2025claudecomputer,
  title={Claude Code is my computer},
  author={Steinberger, Peter},
  journal={Blog post},
  year={2025},
  url={https://steipete.me/posts/2025/claude-code-is-my-computer}
}

@article{anthropic2024agentsdk,
  title={Building agents with the Claude Agent SDK},
  author={Anthropic-Research},
  journal={Anthropic Engineering Blog},
  year={2024},
  url={https://www.anthropic.com/engineering/building-agents-with-the-claude-agent-sdk}
}

@article{schick2023toolformer,
  title={Toolformer: Language Models Can Teach Themselves to Use Tools},
  author={Schick, Timo and Dwivedi-Yu, Jane and Dessi, Roberto and Raileanu, Roberta and Lomeli, Maria and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  journal={arXiv preprint, arXiv:2302.04761},
  year={2023},
  url={https://arxiv.org/abs/2302.04761}
}

@article{aryabumi2024codepretraining,
  title={To Code, or Not To Code? Exploring Impact of Code in Pre-Training},
  author={Aryabumi, Viraat and Su, Yixuan and Ma, Raymond and Morisot, Adrien and Zhang, Ivan and Locatelli, Acyr and Fadaee, Marzieh and Ustun, Ahmet and Hooker, Sara},
  journal={arXiv preprint, arXiv:2408.10914},
  year={2024},
  url={https://arxiv.org/abs/2408.10914}
}

@article{wang2024codeact,
  title={Executable Code Actions Elicit Better LLM Agents},
  author={Wang, Xingyao and Chen, Yangyi and Yuan, Lifan and Zhang, Yizhe and Li, Yunzhu and Peng, Hao and Ji, Heng},
  journal={arXiv preprint, arXiv:2402.01030},
  year={2024},
  url={https://arxiv.org/abs/2402.01030}
}

@article{openai2025gpt51,
  title={GPT-5.1 Codex Max},
  author={OpenAI-Research},
  journal={OpenAI Blog},
  year={2025},
  url={https://openai.com/index/gpt-5-1-codex-max/}
}

@article{yao2024taubench,
  title={Tau-bench: A Benchmark for Tool-Agent-User Interaction in Real-World Domains},
  author={Yao, Shunyu and Shinn, Noah and Razavi, Pedram and Narasimhan, Karthik},
  journal={arXiv preprint, arXiv:2406.12045},
  year={2024},
  url={https://arxiv.org/abs/2406.12045}
}

@article{gorilla2024bfcl,
  title={The Berkeley Function Calling Leaderboard (BFCL): From Tool Use to Agentic Evaluation of Large Language Models},
  author={Gorilla-Team},
  journal={UC Berkeley},
  year={2024},
  url={https://gorilla.cs.berkeley.edu/blogs/15_bfcl_v4_web_search.html}
}

@article{denison2024sycophancy,
  title={Sycophancy to Subterfuge: Investigating Reward Tampering in Language Models},
  author={Denison, Carson and MacDiarmid, Monte and Barez, Fazl and Duvenaud, David and Kravec, Shauna and Marks, Samuel and Schiefer, Nicholas and Soklaski, Ryan and Tamkin, Alex and Kaplan, Jared and Shlegeris, Buck and Bowman, Samuel R. and Perez, Ethan and Hubinger, Evan},
  journal={arXiv preprint, arXiv:2406.10162},
  year={2024},
  url={https://arxiv.org/abs/2406.10162}
}

@article{sutton2019bitterlesson,
  title={The Bitter Lesson},
  author={Sutton, Richard S.},
  journal={Essay},
  year={2019},
  url={http://www.incompleteideas.net/IncIdeas/BitterLesson.html}
}
