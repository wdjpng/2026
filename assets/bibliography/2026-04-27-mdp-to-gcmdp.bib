@article{silver2018general,
  title={A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
  author={Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
  journal={Science},
  volume={362},
  number={6419},
  pages={1140--1144},
  year={2018},
  publisher={American Association for the Advancement of Science}
}

@article{shao2024deepseekmath,
  title={Deepseekmath: Pushing the limits of mathematical reasoning in open language models},
  author={Shao, Zhihong and Wang, Peiyi and Zhu, Qihao and Xu, Runxin and Song, Junxiao and Bi, Xiao and Zhang, Haowei and Zhang, Mingchuan and Li, YK and Wu, Yang and others},
  journal={arXiv preprint arXiv:2402.03300},
  year={2024}
}

@article{amin2025pi,
  title={$\pi^{*}_{0.6}$: a VLA That Learns From Experience},
  author={Amin, Ali and Aniceto, Raichelle and Balakrishna, Ashwin and Black, Kevin and Conley, Ken and Connors, Grace and Darpinian, James and Dhabalia, Karan and DiCarlo, Jared and Driess, Danny and others},
  journal={arXiv preprint arXiv:2511.14759},
  year={2025}
}

@inproceedings{liu2025a,
  title={A Single Goal is All You Need: Skills and Exploration Emerge from Contrastive RL without Rewards, Demonstrations, or Subgoals},
  author={Grace Liu and Michael Tang and Benjamin Eysenbach},
  booktitle={The Thirteenth International Conference on Learning Representations},
  year={2025},
  url={https://openreview.net/forum?id=xCkgX4Xfu0}
}

@inproceedings{kaelbling1993learning,
  title={Learning to achieve goals},
  author={Kaelbling, Leslie Pack},
  booktitle={IJCAI},
  volume={2},
  pages={1094--8},
  year={1993}
}


@inproceedings{schaul2015universal,
  title={Universal value function approximators},
  author={Schaul, Tom and Horgan, Daniel and Gregor, Karol and Silver, David},
  booktitle={International conference on machine learning},
  pages={1312--1320},
  year={2015},
  organization={PMLR}
}

@inproceedings{eysenbach2022contrastive,
  title={Contrastive Learning as Goal-Conditioned Reinforcement Learning},
  author={Benjamin Eysenbach and Tianjun Zhang and Sergey Levine and Ruslan Salakhutdinov},
  booktitle={Advances in Neural Information Processing Systems},
  editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
  year={2022},
}

@article{zheng2023contrastive,
  title={Contrastive difference predictive coding},
  author={Zheng, Chongyi and Salakhutdinov, Ruslan and Eysenbach, Benjamin},
  journal={arXiv preprint arXiv:2310.20141},
  year={2023}
}

@misc{bastankhah2025,
  title={Demystifying the Mechanisms Behind Emergent Exploration in Goal-conditioned RL}, 
  author={Mahsa Bastankhah and Grace Liu and Dilip Arumugam and Thomas L. Griffiths and Benjamin Eysenbach},
  year={2025},
  eprint={2510.14129},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
}

@inproceedings{thakoor2022generalised,
  title={Generalised policy improvement with geometric policy composition},
  author={Thakoor, Shantanu and Rowland, Mark and Borsa, Diana and Dabney, Will and Munos, R{\'e}mi and Barreto, Andr{\'e}},
  booktitle={International Conference on Machine Learning},
  pages={21272--21307},
  year={2022},
  organization={PMLR}
}

@inproceedings{ghosh2023reinforcement,
  title={Reinforcement learning from passive data via latent intentions},
  author={Ghosh, Dibya and Bhateja, Chethan Anand and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={11321--11339},
  year={2023},
  organization={PMLR}
}

@inproceedings{frans2024unsupervised,
  title={Unsupervised Zero-Shot Reinforcement Learning via Functional Reward Encodings},
  author={Kevin Frans and Seohong Park and Pieter Abbeel and Sergey Levine},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024},
}

@article{touati2021learning,
  title={Learning one representation to optimize all rewards},
  author={Touati, Ahmed and Ollivier, Yann},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={13--23},
  year={2021}
}

@article{janner2020gamma,
  title={Gamma-models: Generative temporal difference learning for infinite-horizon prediction},
  author={Janner, Michael and Mordatch, Igor and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1724--1735},
  year={2020}
}

@article{dayan1993improving,
  title={Improving generalization for temporal difference learning: The successor representation},
  author={Dayan, Peter},
  journal={Neural computation},
  volume={5},
  number={4},
  pages={613--624},
  year={1993},
  publisher={MIT Press}
}

@article{barreto2017successor,
  title={Successor features for transfer in reinforcement learning},
  author={Barreto, Andr{\'e} and Dabney, Will and Munos, R{\'e}mi and Hunt, Jonathan J and Schaul, Tom and van Hasselt, Hado P and Silver, David},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{wang2023optimal,
  title={Optimal goal-reaching reinforcement learning via quasimetric learning},
  author={Wang, Tongzhou and Torralba, Antonio and Isola, Phillip and Zhang, Amy},
  booktitle={International Conference on Machine Learning},
  pages={36411--36430},
  year={2023},
  organization={PMLR}
}

@article{park2024value,
  title={Is value learning really the main bottleneck in offline RL?},
  author={Park, Seohong and Frans, Kevin and Levine, Sergey and Kumar, Aviral},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={79029--79056},
  year={2024}
}

@article{nachum2018data,
  title={Data-efficient hierarchical reinforcement learning},
  author={Nachum, Ofir and Gu, Shixiang Shane and Lee, Honglak and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{park2025horizon,
  title={Horizon Reduction Makes RL Scalable},
  author={Park, Seohong and Frans, Kevin and Mann, Deepinder and Eysenbach, Benjamin and Kumar, Aviral and Levine, Sergey},
  journal={arXiv preprint arXiv:2506.04168},
  year={2025}
}

@inproceedings{walke2023bridgedata,
  title={Bridgedata v2: A dataset for robot learning at scale},
  author={Walke, Homer Rich and Black, Kevin and Zhao, Tony Z and Vuong, Quan and Zheng, Chongyi and Hansen-Estruch, Philippe and He, Andre Wang and Myers, Vivek and Kim, Moo Jin and Du, Max and others},
  booktitle={Conference on Robot Learning},
  pages={1723--1736},
  year={2023},
  organization={PMLR}
}

@article{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Pieter Abbeel, OpenAI and Zaremba, Wojciech},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{wilson2007multi,
  title={Multi-task reinforcement learning: a hierarchical bayesian approach},
  author={Wilson, Aaron and Fern, Alan and Ray, Soumya and Tadepalli, Prasad},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  pages={1015--1022},
  year={2007}
}

@inproceedings{yu2020meta,
  title={Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning},
  author={Yu, Tianhe and Quillen, Deirdre and He, Zhanpeng and Julian, Ryan and Hausman, Karol and Finn, Chelsea and Levine, Sergey},
  booktitle={Conference on robot learning},
  pages={1094--1100},
  year={2020},
  organization={PMLR}
}

@article{teh2017distral,
  title={Distral: Robust multitask reinforcement learning},
  author={Teh, Yee and Bapst, Victor and Czarnecki, Wojciech M and Quan, John and Kirkpatrick, James and Hadsell, Raia and Heess, Nicolas and Pascanu, Razvan},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@book{sutton1998reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G and others},
  volume={1},
  number={1},
  year={1998},
  publisher={MIT press Cambridge}
}

@book{bertsekas1996neuro,
  title={Neuro-Dynamic Programming},
  author={Bertsekas, Dimitri and Tsitsiklis, John N},
  year={1996},
  publisher={Athena Scientific}
}

@article{bertsekas1991analysis,
  title={An analysis of stochastic shortest path problems},
  author={Bertsekas, Dimitri P and Tsitsiklis, John N},
  journal={Mathematics of Operations Research},
  volume={16},
  number={3},
  pages={580--595},
  year={1991},
  publisher={INFORMS}
}

@book{kolobov2012planning,
  title={Planning with Markov decision processes: An AI perspective},
  author={Mausam, and Kolobov, Andrey},
  volume={17},
  year={2012},
  publisher={Morgan & Claypool Publishers}
}

@article{myers2024learning,
  title={Learning temporal distances: Contrastive successor features can provide a metric structure for decision-making},
  author={Myers, Vivek and Zheng, Chongyi and Dragan, Anca and Levine, Sergey and Eysenbach, Benjamin},
  journal={arXiv preprint arXiv:2406.17098},
  year={2024}
}

@article{park2025transitive,
  title={Transitive RL: Value Learning via Divide and Conquer},
  author={Park, Seohong and Oberai, Aditya and Atreya, Pranav and Levine, Sergey},
  journal={arXiv preprint arXiv:2510.22512},
  year={2025}
}

@article{park2024ogbench,
  title={Ogbench: Benchmarking offline goal-conditioned rl},
  author={Park, Seohong and Frans, Kevin and Eysenbach, Benjamin and Levine, Sergey},
  journal={arXiv preprint arXiv:2410.20092},
  year={2024}
}
