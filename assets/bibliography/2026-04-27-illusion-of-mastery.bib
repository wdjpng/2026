@article{liu2025rstar,
  title={rStar-Coder: Scaling Competitive Code Reasoning with a Large-Scale Verified Dataset},
  author={Liu, Yifei and Zhang, Li Lyna and Zhu, Yi and Dong, Bingcheng and Zhou, Xudong and Shang, Ning and Yang, Fan and Yang, Mao},
  journal={arXiv preprint arXiv:2505.21297},
  year={2025}
}


@article{shao2025deepseekmath,
  title={DeepSeekMath-V2: Towards Self-Verifiable Mathematical Reasoning},
  author={Shao, Zhihong and Luo, Yuxiang and Lu, Chengda and Ren, ZZ and Hu, Jiewen and Ye, Tian and Gou, Zhibin and Ma, Shirong and Zhang, Xiaokang},
  journal={arXiv preprint arXiv:2511.22570},
  year={2025}
}

@misc{musk,
  author = {Musk, Elon},
  title = {For self-driving, even if the road is painted completely wrong and a UFO lands in the middle of the road, the car still cannot crash and still needs to do the right thing},
  howpublished = {X (Twitter), personal statement},
  year = {2021},
  note = {Accessed via archived post 2021-02-11}
}


@article{waymo,
  title={Wod-e2e: Waymo open dataset for end-to-end driving in challenging long-tail scenarios},
  author={Xu, Runsheng and Lin, Hubert and Jeon, Wonseok and Feng, Hao and Zou, Yuliang and Sun, Liting and Gorman, John and Tolstaya, Kate and Tang, Sarah and White, Brandyn and others},
  journal={arXiv preprint arXiv:2510.26125},
  year={2025}
}

@article{corner,
  title={Corner Case Dataset for Autonomous Vehicle Testing Based on Naturalistic Driving Data},
  author={Zhao, Jian and Li, Wenxu and Zhu, Bing and Zhang, Peixing and Hu, Zhaozheng and Meng, Jie},
  journal={Smart Cities},
  volume={8},
  number={4},
  pages={129},
  year={2025},
  publisher={MDPI}
}

@article{cornersurvey,
  title={A survey on long-tailed visual recognition},
  author={Yang, Lu and Jiang, He and Song, Qing and Guo, Jun},
  journal={International Journal of Computer Vision},
  volume={130},
  number={7},
  pages={1837--1872},
  year={2022},
  publisher={Springer}
}


@article{Darg,
  title={Darg: Dynamic evaluation of large language models via adaptive reasoning graph},
  author={Zhang, Zhehao and Chen, Jiaao and Yang, Diyi},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={135904--135942},
  year={2024}
}


@article{time,
  title={Time travel in llms: Tracing data contamination in large language models},
  author={Golchin, Shahriar and Surdeanu, Mihai},
  journal={arXiv preprint arXiv:2308.08493},
  year={2023}
}

@article{llmjudge,
  title={Generative judge for evaluating alignment},
  author={Li, Junlong and Sun, Shichao and Yuan, Weizhe and Fan, Run-Ze and Zhao, Hai and Liu, Pengfei},
  journal={arXiv preprint arXiv:2310.05470},
  year={2023}
}


@article{llmjudge1,
  title={Llms-as-judges: a comprehensive survey on llm-based evaluation methods},
  author={Li, Haitao and Dong, Qian and Chen, Junjie and Su, Huixue and Zhou, Yujia and Ai, Qingyao and Ye, Ziyi and Liu, Yiqun},
  journal={arXiv preprint arXiv:2412.05579},
  year={2024}
}

@article{OMGEval,
  title={OMGEval: An Open Multilingual Generative Evaluation Benchmark for Large Language Models},
  author={Liu, Yang and Xu, Meng and Wang, Shuo and Yang, Liner and Wang, Haoyu and Liu, Zhenghao and Kong, Cunliang and Chen, Yun and Sun, Maosong and Yang, Erhong},
  journal={arXiv preprint arXiv:2402.13524},
  year={2024}
}





@inproceedings{bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={Proceedings of the 2019 conference of the North American chapter of the association for computational linguistics: human language technologies, volume 1 (long and short papers)},
  pages={4171--4186},
  year={2019}
}

@article{ALE,
  title={The arcade learning environment: An evaluation platform for general agents},
  author={Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  journal={Journal of artificial intelligence research},
  volume={47},
  pages={253--279},
  year={2013}
}

@misc{aime,
  title={American Invitational Mathematics Examination ({AIME}) 2025},
  author={{Mathematical Association of America}},
  year={2025},
  url={https://www.maa.org/math-competitions/aime}
}

@inproceedings{bigbench,
  title={Bigbench: Towards an industry standard benchmark for big data analytics},
  author={Ghazal, Ahmad and Rabl, Tilmann and Hu, Minqing and Raab, Francois and Poess, Meikel and Crolotte, Alain and Jacobsen, Hans-Arno},
  booktitle={Proceedings of the 2013 ACM SIGMOD international conference on Management of data},
  pages={1197--1208},
  year={2013}
}

@article{deepseek-r1,
  title={Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning},
  author={Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others},
  journal={arXiv preprint arXiv:2501.12948},
  year={2025}
}

@inproceedings{dynabench,
  title={Dynabench: Rethinking benchmarking in NLP},
  author={Kiela, Douwe and Bartolo, Max and Nie, Yixin and Kaushik, Divyansh and Geiger, Atticus and Wu, Zhengxuan and Vidgen, Bertie and Prasad, Grusha and Singh, Amanpreet and Ringshia, Pratik and others},
  booktitle={Proceedings of the 2021 conference of the North American chapter of the Association for Computational Linguistics: human language technologies},
  pages={4110--4124},
  year={2021}
}

@article{gsm8k,
  title={Training Verifiers to Solve Math Word Problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and Hesse, Christopher and Schulman, John},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@article{open,
  title={Open-ended learning leads to generally capable agents},
  author={Team, Open Ended Learning and Stooke, Adam and Mahajan, Anuj and Barros, Catarina and Deck, Charlie and Bauer, Jakob and Sygnowski, Jakub and Trebacz, Maja and Jaderberg, Max and Mathieu, Michael and others},
  journal={arXiv preprint arXiv:2107.12808},
  year={2021}
}

@article{llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{gpt4,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@misc{ilya,
  title={Ilya Sutskever: We're moving from the age of scaling to the age of research},
  author={Patel, Dwarkesh},
  howpublished={YouTube},
  url={https://www.youtube.com/watch?v=aR20FWCCjAs},
  year={2025},
  month={nov},
  day={26},
  note={Interview with Ilya Sutskever on the Dwarkesh Podcast}
}

@article{international-safety,
  title={International scientific report on the safety of advanced ai (interim report)},
  author={Bengio, Yoshua and Mindermann, S{\"o}ren and Privitera, Daniel and Besiroglu, Tamay and Bommasani, Rishi and Casper, Stephen and Choi, Yejin and Goldfarb, Danielle and Heidari, Hoda and Khalatbari, Leila and others},
  journal={arXiv preprint arXiv:2412.05282},
  year={2024}
}

@article{kumo,
  title={Generative evaluation of complex reasoning in large language models},
  author={Lin, Haowei and Wang, Xiangyu and Yan, Ruilin and Huang, Baizhou and Ye, Haotian and Zhu, Jianhua and Wang, Zihao and Zou, James and Ma, Jianzhu and Liang, Yitao},
  journal={arXiv preprint arXiv:2504.02810},
  year={2025}
}

@article{livecodebench,
  title={LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code},
  author={Jain, Naman and Han, King and Gu, Alex and Li, Wen-Ding and Yan, Fanjia and Zhang, Tianjun and Wang, Sida and Solar-Lezama, Armando and Sen, Koushik and Stoica, Ion},
  journal={CoRR},
  year={2024}
}

@inproceedings{mcu,
  title={MCU: An Evaluation Framework for Open-Ended Game Agents},
  author={Zheng, Xinyue and Lin, Haowei and He, Kaichen and Wang, Zihao and Fu, Qiang and Fu, Haobo and Zheng, Zilong and Liang, Yitao},
  booktitle={Forty-second International Conference on Machine Learning},
  year={2025}
}

@article{o1,
  title={Openai o1 system card},
  author={Jaech, Aaron and Kalai, Adam and Lerer, Adam and Richardson, Adam and El-Kishky, Ahmed and Low, Aiden and Helyar, Alec and Madry, Aleksander and Beutel, Alex and Carney, Alex and others},
  journal={arXiv preprint arXiv:2412.16720},
  year={2024}
}

@inproceedings{peeking,
  author = {Bansal*, Hritik and Maini*, Pratyush},
  title = {Peeking Behind Closed Doors: Risks of LLM Evaluation by Private Data Curators},
  abstract = {A critical examination of the risks and challenges posed by private evaluators (for example ScaleAI) in the LLM landscape, highlighting financial incentives, conflicts of interest, and prevalence of evaluation biases even when acting in good faith.},
  booktitle = {ICLR Blogposts 2025},
  year = {2025},
  date = {November 22, 2024},
  note = {https://iclr-blogposts.github.io/2025/blog/risks-private-evals/},
  url  = {https://iclr-blogposts.github.io/2025/blog/risks-private-evals/}
}

@article{swerebench,
  title={SWE-rebench: An Automated Pipeline for Task Collection and Decontaminated Evaluation of Software Engineering Agents},
  author={Badertdinov, Ibragim and Golubev, Alexander and Nekrashevich, Maksim and Shevtsov, Anton and Karasik, Simon and Andriushchenko, Andrei and Trofimova, Maria and Litvintseva, Daria and Yangel, Boris},
  journal={arXiv preprint arXiv:2505.20411},
  year={2025}
}

@article{swebenchlive,
  title={SWE-bench Goes Live!},
  author={Zhang, Linghao and He, Shilin and Zhang, Chaoyun and Kang, Yu and Li, Bowen and Xie, Chengxing and Wang, Junhao and Wang, Maoquan and Huang, Yufan and Fu, Shengyu and others},
  journal={arXiv preprint arXiv:2505.23419},
  year={2025}
}


@inproceedings{procegen,
  title={Leveraging procedural generation to benchmark reinforcement learning},
  author={Cobbe, Karl and Hesse, Chris and Hilton, Jacob and Schulman, John},
  booktitle={International conference on machine learning},
  pages={2048--2056},
  year={2020},
  organization={PMLR}
}

@article{rl-reasoning,
  title={Does reinforcement learning really incentivize reasoning capacity in llms beyond the base model?},
  author={Yue, Yang and Chen, Zhiqi and Lu, Rui and Zhao, Andrew and Wang, Zhaokai and Song, Shiji and Huang, Gao},
  journal={arXiv preprint arXiv:2504.13837},
  year={2025}
}

@article{swebench,
  title={Swe-bench: Can language models resolve real-world github issues?},
  author={Jimenez, Carlos E and Yang, John and Wettig, Alexander and Yao, Shunyu and Pei, Kexin and Press, Ofir and Narasimhan, Karthik},
  journal={arXiv preprint arXiv:2310.06770},
  year={2023}
}

@article{superglue,
  title={Superglue: A stickier benchmark for general-purpose language understanding systems},
  author={Wang, Alex and Pruksachatkun, Yada and Nangia, Nikita and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{unicode,
  title={UniCode: A Framework for Generating High Quality Competitive Coding Problems},
  author={Zheng, Xinyue and Lin, Haowei and Cai, Shaofei and Zheng, Zilong and Liang, Yitao},
  journal={arXiv preprint arXiv:2510.17868},
  year={2025}
}
