@article{jaech2024openai,
  title={Openai o1 system card},
  author={Jaech, Aaron and Kalai, Adam and Lerer, Adam and Richardson, Adam and El-Kishky, Ahmed and Low, Aiden and Helyar, Alec and Madry, Aleksander and Beutel, Alex and Carney, Alex and others},
  journal={arXiv preprint arXiv:2412.16720},
  year={2024}
}

@article{guo2025deepseek,
  title={Deepseek-r1 incentivizes reasoning in llms through reinforcement learning},
  author={Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Wang, Peiyi and Zhu, Qihao and Xu, Runxin and Zhang, Ruoyu and Ma, Shirong and Bi, Xiao and others},
  journal={Nature},
  volume={645},
  number={8081},
  pages={633--638},
  year={2025},
  publisher={Nature Publishing Group UK London}
}

@article{li2025questa,
  title={Questa: Expanding reasoning capacity in llms via question augmentation},
  author={Li, Jiazheng and Lin, Hongzhou and Lu, Hong and Wen, Kaiyue and Yang, Zaiwen and Gao, Jiaxuan and Wu, Yi and Zhang, Jingzhao},
  journal={arXiv preprint arXiv:2507.13266},
  year={2025}
}

@article{min2024imitate,
  title={Imitate, explore, and self-improve: A reproduction report on slow-thinking reasoning systems},
  author={Min, Yingqian and Chen, Zhipeng and Jiang, Jinhao and Chen, Jie and Deng, Jia and Hu, Yiwen and Tang, Yiru and Wang, Jiapeng and Cheng, Xiaoxue and Song, Huatong and others},
  journal={arXiv preprint arXiv:2412.09413},
  year={2024}
}

@misc{deepscaler2025,
  title={DeepScaleR: Surpassing O1-Preview with a 1.5B Model by Scaling RL},
  author={Michael Luo and Sijun Tan and Justin Wong and Xiaoxiang Shi and William Y. Tang and Manan Roongta and Colin Cai and Jeffrey Luo and Li Erran Li and Raluca Ada Popa and Ion Stoica},
  howpublished={\url{https://pretty-radio-b75.notion.site/DeepScaleR-Surpassing-O1-Preview-with-a-1-5B-Model-by-Scaling-RL-19681902c1468005bed8ca303013a4e2}},
  note={Notion Blog},
  year={2025}
}

@article{liu2025prorl,
  title={Prorl: Prolonged reinforcement learning expands reasoning boundaries in large language models},
  author={Liu, Mingjie and Diao, Shizhe and Lu, Ximing and Hu, Jian and Dong, Xin and Choi, Yejin and Kautz, Jan and Dong, Yi},
  journal={arXiv preprint arXiv:2505.24864},
  year={2025}
}

@misc{hu2025prorlv2,
  title        = {ProRL V2: Prolonged Training Validates RL Scaling Laws},
  author       = {Jian Hu and Mingjie Liu and Shizhe Diao and Ximing Lu and Xin Dong and Pavlo Molchanov and Yejin Choi and Jan Kautz and Yi Dong},
  year         = {2025},
  month        = {August},
  day          = {11},
  note         = {First published on Notion},
  url          = {https://hijkzzz.notion.site/prorl-v2}
}

@article{hu2025brorl,
  title={Brorl: Scaling reinforcement learning via broadened exploration},
  author={Hu, Jian and Liu, Mingjie and Lu, Ximing and Wu, Fang and Harchaoui, Zaid and Diao, Shizhe and Choi, Yejin and Molchanov, Pavlo and Yang, Jun and Kautz, Jan and others},
  journal={arXiv preprint arXiv:2510.01180},
  year={2025}
}

@article{liu2025part,
  title={Part i: Tricks or traps? a deep dive into rl for llm reasoning},
  author={Liu, Zihe and Liu, Jiashun and He, Yancheng and Wang, Weixun and Liu, Jiaheng and Pan, Ling and Hu, Xinyu and Xiong, Shaopan and Huang, Ju and Hu, Jian and others},
  journal={arXiv preprint arXiv:2508.08221},
  year={2025}
}

@article{song2025fastcurl,
  title={FastCuRL: Curriculum Reinforcement Learning with Stage-wise Context Scaling for Efficient Training R1-like Reasoning Models},
  author={Song, Mingyang and Zheng, Mao and Li, Zheng and Yang, Wenjie and Luo, Xuan and Pan, Yue and Zhang, Feng},
  journal={arXiv preprint arXiv:2503.17287},
  year={2025}
}

@article{setlur2025e3,
  title={e3: Learning to Explore Enables Extrapolation of Test-Time Compute for LLMs},
  author={Setlur, Amrith and Yang, Matthew YR and Snell, Charlie and Greer, Jeremy and Wu, Ian and Smith, Virginia and Simchowitz, Max and Kumar, Aviral},
  journal={arXiv preprint arXiv:2506.09026},
  year={2025}
}

@misc{Polaris2025,
    title = {POLARIS: A Post-Training Recipe for Scaling Reinforcement Learning on Advanced Reasoning Models},
    url = {https://hkunlp.github.io/blog/2025/Polaris},
    author = {An, Chenxin and Xie, Zhihui and Li, Xiaonan and Li, Lei and Zhang, Jun and Gong, Shansan and Zhong, Ming and Xu, Jingjing and Qiu, Xipeng and Wang, Mingxuan and Kong, Lingpeng},
    year = {2025}
}

@article{wang2025stabilizing,
  title={Stabilizing Knowledge, Promoting Reasoning: Dual-Token Constraints for RLVR},
  author={Wang, Jiakang and Liu, Runze and Zhang, Fuzheng and Li, Xiu and Zhou, Guorui},
  journal={arXiv preprint arXiv:2507.15778},
  year={2025}
}

@article{yu2025dapo,
  title={Dapo: An open-source llm reinforcement learning system at scale},
  author={Yu, Qiying and Zhang, Zheng and Zhu, Ruofei and Yuan, Yufeng and Zuo, Xiaochen and Yue, Yu and Dai, Weinan and Fan, Tiantian and Liu, Gaohong and Liu, Lingjun and others},
  journal={arXiv preprint arXiv:2503.14476},
  year={2025}
}

@article{CompassVerifier,
  title={CompassVerifier: A Unified and Robust Verifier for Large Language Models}, 
  author={Shudong Liu and Hongwei Liu and Junnan Liu and Linchen Xiao and Songyang Gao and Chengqi Lyu and Yuzhe Gu and Wenwei Zhang and Derek F. Wong and Songyang Zhang and Kai Chen},
  year={2025}
}

@article{liu2025dler,
  title={DLER: Doing Length pEnalty Right-Incentivizing More Intelligence per Token via Reinforcement Learning},
  author={Liu, Shih-Yang and Dong, Xin and Lu, Ximing and Diao, Shizhe and Liu, Mingjie and Chen, Min-Hung and Yin, Hongxu and Wang, Yu-Chiang Frank and Cheng, Kwang-Ting and Choi, Yejin and others},
  journal={arXiv preprint arXiv:2510.15110},
  year={2025}
}

