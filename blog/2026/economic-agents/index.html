<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> AI Fundamentals: Valuing AI Agents &amp; Data Assets | ICLR Blogposts 2026 </title> <meta name="author" content="ICLR Blog"> <meta name="description" content="Large Language Model (LLM) agents now read the world through managed-context pipelines, write to it via tool-calling APIs, and continuously re-wire themselves with fresh experience. Stakeholders therefore need a Generally Accepted Accounting Principles (GAAP) compatible method to price both (i) the agent's labour-like output and (ii) the data traces that fuel learning. We formalise a single unifying metric - agent Economic Value (AEV)- and demonstrate that these metrics are measurable today. We then extend the template to reinforcement-learning regimes in which grounded rewards equal cash flows. Lastly, we propose a financial settlement layer, which transforms the agent from a passive software user into an active economic participant."> <meta name="keywords" content="machine-learning, ml, deep-learning, reinforcement-learning, icl# add your own keywords or leave empty"> <link rel="stylesheet" href="/2026/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/2026/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/2026/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/2026/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/2026/assets/img/iclr_favicon.ico?0a8a3afdb0dbe139723b24dba3052a4f"> <link rel="stylesheet" href="/2026/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://iclr-blogposts.github.io/2026/blog/2026/economic-agents/"> <script src="/2026/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/2026/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <script src="/2026/assets/js/distillpub/template.v2.js"></script> <script src="/2026/assets/js/distillpub/transforms.v2.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "AI Fundamentals: Valuing AI Agents & Data Assets",
            "description": "Large Language Model (LLM) agents now read the world through managed-context pipelines, write to it via tool-calling APIs, and continuously re-wire themselves with fresh experience. Stakeholders therefore need a Generally Accepted Accounting Principles (GAAP) compatible method to price both (i) the agent's labour-like output and (ii) the data traces that fuel learning. We formalise a single unifying metric - agent Economic Value (AEV)- and demonstrate that these metrics are measurable today. We then extend the template to reinforcement-learning regimes in which grounded rewards equal cash flows. Lastly, we propose a financial settlement layer, which transforms the agent from a passive software user into an active economic participant.",
            "published": "April 27, 2026",
            "authors": [
              
              {
                "author": "Anonymous",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/2026/"> ICLR Blogposts 2026 </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/2026/">home </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/about/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/call/">call for blogposts </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/submitting/">submitting </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/reviewing/">reviewing </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">past iterations </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2026/"><strong>2026</strong></a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2025/">2025</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2024/">2024</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2023/">2023</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blog-track.github.io/home/" rel="external nofollow noopener" target="_blank">2022</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>AI Fundamentals: Valuing AI Agents &amp; Data Assets</h1> <p>Large Language Model (LLM) agents now read the world through managed-context pipelines, write to it via tool-calling APIs, and continuously re-wire themselves with fresh experience. Stakeholders therefore need a Generally Accepted Accounting Principles (GAAP) compatible method to price both (i) the agent's labour-like output and (ii) the data traces that fuel learning. We formalise a single unifying metric - agent Economic Value (AEV)- and demonstrate that these metrics are measurable today. We then extend the template to reinforcement-learning regimes in which grounded rewards equal cash flows. Lastly, we propose a financial settlement layer, which transforms the agent from a passive software user into an active economic participant.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#introduction">Introduction</a> </div> <div> <a href="#background">Background</a> </div> <ul> <li> <a href="#from-tasks-to-cash-flows">From Tasks to Cash Flows</a> </li> <li> <a href="#limitations-of-exposure-studies">Limitations of Exposure Studies</a> </li> </ul> <div> <a href="#framework">Framework</a> </div> <ul> <li> <a href="#technical-architecture-of-an-ai-agent">Technical Architecture of an AI Agent</a> </li> <li> <a href="#resource-taxonomy-and-marginal-valuation">Resource Taxonomy and Marginal Valuation</a> </li> <li> <a href="#metric-definitions">Metric Definitions</a> </li> <li> <a href="#efficiency-premium">Efficiency Premium</a> </li> </ul> <div> <a href="#measurement-methodology">Measurement Methodology</a> </div> <div> <a href="#empirical-benchmarks">Empirical Benchmarks</a> </div> <ul> <li> <a href="#anthropic-clio-national-task-adoption">Anthropic Clio: National Task Adoption</a> </li> <li> <a href="#swe-lancer-outcome-priced-coding">SWE-Lancer: Outcome-Priced Coding</a> </li> <li> <a href="#healthbench-safety-critical-triage">HealthBench: Safety-Critical Triage</a> </li> </ul> <div> <a href="#examples">Examples</a> </div> <ul> <li> <a href="#example-1-ai-powered-market-research-analysis-and-report-generation">Example 1: AI-Powered Market Research Analysis and Report Generation</a> </li> <li> <a href="#example-2-ai-enhanced-customer-support-automation">Example 2: AI-Enhanced Customer Support Automation</a> </li> <li> <a href="#example-3-ai-driven-deep-research-in-finance">Example 3: AI-Driven Deep Research in Finance</a> </li> </ul> <div> <a href="#the-reinforcement-learning-accelerator">The Reinforcement Learning Accelerator</a> </div> <div> <a href="#future-outlook-agentic-liquidity-and-the-mcp-wallet">Future Outlook: Agentic Liquidity and The MCP Wallet</a> </div> <ul> <li> <a href="#the-problem-closed-resource-loops">The Problem: Closed Resource Loops</a> </li> <li> <a href="#the-solution-the-settlement-layer">The Solution: The Settlement Layer</a> </li> </ul> <div> <a href="#conclusion">Conclusion</a> </div> </nav> </d-contents> <h2 id="introduction">Introduction</h2> <p><strong>Motivation.</strong> Large Language Model (LLM) based agents are rapidly evolving beyond simple chatbots into versatile autonomous assistants embedded in real workflows. These agents can <em>read</em> the world through managed context pipelines (ingesting documents, code, sensor data) and <em>write</em> to the world via APIs and tools, while continually improving themselves by incorporating new training data (experience) into their weights. As AI systems begin to perform economically valuable tasks across domains <d-cite key="erol2025cost,ide2024artificial,hadfield2025economy,handa2025economic"></d-cite>, from writing <d-cite key="choi-etal-2024-combining"></d-cite> and software development <d-cite key="chen2025textsuperscript,Miserendino2025"></d-cite> to customer service <d-cite key="liu2025evaluating,ackerman2025perceptions"></d-cite> and healthcare <d-cite key="Arora2025,gallifant2025beyond"></d-cite>, there is a pressing need to rigorously measure their performance, value, and risks in terms that organizations can understand and trust.</p> <p>Recent analyses of millions of AI usage instances show that AI is already touching a wide range of occupations, with particularly heavy use in software development and writing tasks (together nearly half of all usage) <d-cite key="Handa2025"></d-cite>. Notably, around 36% of occupations see at least a quarter of their tasks involving AI assistance <d-cite key="Handa2025"></d-cite> – but in most cases this is <em>augmentation</em> (AI helping a human) rather than full automation. Indeed, one study found 57% of AI usage suggests human-AI collaboration (learning or iterating on an output) vs. 43% where the AI essentially completes tasks autonomously <d-cite key="Handa2025"></d-cite>.</p> <p>Meanwhile, the capabilities of frontier models have been climbing rapidly. In high-stakes domains like medicine, open-ended physician-written evaluations (HealthBench) show model performance improving from 16% (GPT-3.5) to 32% (GPT-4) and up to 60% with the latest models <d-cite key="Arora2025"></d-cite> within two years – a nearly 4x improvement. In software engineering, new benchmarks of freelance programming tasks (SWE-Lancer) valued at \$1M found that state-of-the-art models can now complete a significant subset of real-world coding jobs (earning about \$400k of the \$1M total value) <d-cite key="Miserendino2025"></d-cite>, though they still fail on the majority of tasks. We are entering what Silver and Sutton term the <em>Era of Experience</em> <d-cite key="SilverSutton2025"></d-cite>, where AI agents learn continuously from real-world interactions rather than solely from static training data.</p> <p><strong>Contributions.</strong> We present an expanded <strong>AI Fundamentals</strong> framework that maps every technical aspect of an AI agent’s performance into the language of economics and public-company finance <d-cite key="bai2025review,garrido2024deep,erol2025cost"></d-cite>. Our goal is to define a single unifying metric – <strong>Agent Economic Value (AEV)</strong> – which collapses all performance aspects into one cash–flow based expression:</p> \[\begin{aligned} \text{AEV} &amp; = \text{Cost Saving} + \text{Efficiency Premium} - \text{Model Cost} \\ &amp;- \text{Data Cost} - \text{Human Intervention Cost}. \end{aligned}\] <ol> <li>We formalise AEV and map each cost or benefit term to GAAP <d-cite key="GAAP"></d-cite> line items, with empirical evidence showing the full expression is measurable today.</li> <li>We provide a measurement methodology validated on software, healthcare, and enterprise usage datasets.</li> <li>We extend the template to the “Era of Experience” where agents learn from grounded, real-world reward streams <d-cite key="SilverSutton2025"></d-cite>.</li> </ol> <p><strong>Data–Asset Valuation.</strong> Interaction logs generated during agent operation accrue as an <em>intangible data asset</em> <d-cite key=" moon-etal-2025-limacost,yanggmvaluator,zhang2025fairshare"></d-cite>. Under GAAP we expense collection and cleaning costs immediately, but we may capitalise the curated corpus once it demonstrably improves future cash flows (analogous to software development costs that pass technological feasibility). The same treatment applies under IFRS (IAS 38), where the asset is amortised over the useful life of the model. We therefore track a “Data R&amp;D” line item that migrates to the balance-sheet once the corpus clears the feasibility gate, providing an auditable bridge from token spend to book value.</p> <h2 id="background">Background</h2> <figure style="text-align: center; width: 100%;"> <img src="/2026/assets/img/2026-04-27-economic-agents/economic-value.png" style="width: 40%;"> <figcaption style="font-size: 1em;">Figure 1: Graphical breakdown of Agent Economic Value (AEV) into positive cash inflows (Cost Saving and Efficiency Premium) versus negative outflows (Model, Data, and Human Intervention Costs).</figcaption> </figure> <h3 id="from-tasks-to-cash-flows">From Tasks to Cash Flows</h3> <p>A <em>task</em> is the atomic unit defined by O<em>NET. Handa *et al.</em> build a differential-privacy pipeline (Clio) that maps raw conversations to such tasks at scale, recovering wages, skills, and job-zone attributes <d-cite key="Handa2025"></d-cite>. If each task’s historic market price is known (Upwork contracts, Medicare reimbursement, customer-service SLA penalty, …), the jump to GAAP becomes mechanical.</p> <h3 id="limitations-of-exposure-studies">Limitations of Exposure Studies</h3> <p>Forecasts based on patent text overlap <d-cite key="Handa2025"></d-cite> or embedding similarity predict potential, not realised impact. Our framework instead <em>measures</em> cash deltas per task, capturing both augmentation and automation effects.</p> <figure style="text-align: center; width: 100%;"> <img src="/2026/assets/img/2026-04-27-economic-agents/logistics-chain.png" style="width: 80%;"> <figcaption style="font-size: 1em;">Figure 2: End-to-end inference supply chain. Curated data and expert prompts are routed through the MCP to the model, where compute tokens refine them into machine-level skills that ultimately map to human-level economic output.</figcaption> </figure> <h2 id="framework">Framework</h2> <h3 id="technical-architecture-of-an-ai-agent">Technical Architecture of an AI Agent</h3> <p>A contemporary LLM-based agent is not an isolated text predictor but an <em>interactive system</em> that perceives and acts on the world in extended sequences. Figure 3 illustrates the components and data flows:</p> <figure style="text-align: center; width: 100%;"> <img src="/2026/assets/img/2026-04-27-economic-agents/picture-1-updated.png" style="width: 80%;"> <figcaption style="font-size: 1em;">Figure 3: Perception–Action–Self-Improvement pipeline. MCP servers provide read/write primitives; GPU clusters host training &amp; inference.</figcaption> </figure> <p>The architecture includes:</p> <ul> <li> <strong>Observer (Read) Paths:</strong> The agent ingests context through managed pipelines (MCP-Read). These could be <em>pull-based</em> queries or <em>push-based</em> streams of information.</li> <li> <strong>Actuator (Write) Paths:</strong> The agent produces outputs via actions (MCP-Write), generating text or calling tools/APIs to enact changes in the environment.</li> <li> <strong>Agent Core (LLM + Controller):</strong> The large model that processes inputs and decides on outputs, implementing a policy $\pi$ in an RL sense.</li> <li> <strong>Learning (Weight Updates):</strong> After tasks are completed, interaction data can be fed back into training pipelines (DL-TRAIN) to update model weights.</li> </ul> <p>Everything is orchestrated by a <strong>Managed Compute &amp; Prompt (MCP) service</strong>, which coordinates reads and writes and provides an interface to the agent.</p> <h3 id="resource-taxonomy-and-marginal-valuation">Resource Taxonomy and Marginal Valuation</h3> <p>Data are <em>non-fungible</em> assets whose worth is governed by their <em>quality</em> rather than sheer volume <d-cite key="moon-etal-2025-limacost,yanggmvaluator,zhang2025fairshare"></d-cite>. We track four economically distinct subclasses:</p> <ol> <li> <strong>Expert Time</strong> – manually crafted demonstrations, ratings, or critiques by domain specialists.</li> <li> <strong>Live-Environment Experience</strong> – interaction traces collected during real production usage.</li> <li> <strong>Inference Data Stream</strong> – prompts and completions logged on-the-fly at inference time.</li> <li> <strong>Training Dataset</strong> – the curated corpus used for pre-training or fine-tuning.</li> </ol> <p>The <strong>Model &amp; Compute</strong> layer is priced <em>per inference token</em>. Beyond raw compute, we include a <em>model premium</em>: the price gap between a proprietary frontier model and the best open-source alternative delivering similar quality.</p> <p><strong>Machine Skills</strong> achievable today include coding, deep financial research, and multi-modal artistic generation. Their marginal contribution is reflected in <em>Cost Saving</em> and <em>Efficiency Premium</em>. Conversely, <strong>Human Skills</strong> are either replaced or augmented, with any residual oversight captured by the <em>Human Intervention Cost</em> term.</p> <p>Putting these pieces together, the updated AI Fundamental identity is</p> \[\begin{aligned} \text{AEV} &amp;= \text{Cost Saving} + \text{Efficiency Premium} - \text{Model Cost} \\ &amp;- \text{Data Cost} - \text{Human Intervention Cost}, \end{aligned}\] <p>where Model Cost $=$ (inference compute token cost) $+$ model premium, and all terms are measured on a <em>marginal</em> per-task basis.</p> <h3 id="metric-definitions">Metric Definitions</h3> <p>The above Equation defines AEV with explicit cost fields.</p> \[\begin{aligned} \text{AEV} &amp;= \sum_{i \in T}\!\bigl(\text{CostSaving}_i + \text{EfficiencyPremium}_i\bigr) \\ &amp;- \text{ModelCost}_i - \text{DataCost}_i - \text{HumanInterventionCost}_i. \end{aligned}\] <p>We can also express Agent Economic Value with more detailed cost components:</p> \[\begin{aligned} \text{Agent Economic Value} &amp;= \text{Cost Saving} + \text{Efficiency Premium} \\ &amp;- (C_{\text{GPU}} + C_{\text{energy}} + C_{\text{MCP}} + C_{\text{human}} + C_{\text{data}}) \end{aligned}\] <p>Here, the cost components can be broken down further: $C_{\text{GPU}}$ encompasses expenses for GPUs and other accelerators; $C_{\text{energy}}$ includes power consumption and associated infrastructure like cooling systems; $C_{\text{data}}$ covers the often substantial lifecycle costs of data (acquisition, storage, processing, and ongoing curation), which forms the foundation for the agent’s learning and performance; $C_{\text{MCP}}$ pertains to the managed compute and prompt orchestration services, which can also factor in costs related to algorithmic complexity or specific software; and $C_{\text{human}}$ is the cost of necessary human oversight and intervention.</p> <p><strong>GAAP mapping.</strong></p> <ul> <li> <strong>Cost Saving</strong> $\to$ Operating expense reduction</li> <li> <strong>Efficiency Premium</strong> $\to$ Incremental revenue or throughput uplift</li> <li> <strong>Model, Data, Human Intervention Costs</strong> $\to$ Cost of goods sold / operating expenses</li> <li> <strong>AEV</strong> $\to$ Net Operating Profit After Tax (NOPAT)</li> </ul> <h3 id="efficiency-premium">Efficiency Premium</h3> <p>The Efficiency Premium captures the top-line growth or productivity gain from AI – not just doing the same work for cheaper, but doing <em>more</em> or <em>better</em> with AI than before. This metric recognizes that AI agents can operate at superhuman speed and scale when reliable, potentially generating additional revenue or throughput.</p> <p>Examples include:</p> <ul> <li>Customer support AI handling hundreds of chats concurrently compared to a human’s 5 chats</li> <li>Healthcare where AI can engage with patients who otherwise wouldn’t get attention</li> <li>Software development cycles becoming faster, allowing teams to tackle more ambitious projects</li> </ul> <p>The Efficiency Premium often remains latent until human-intervention costs are brought under control. Once the AI is reliable enough (failures are very rare), it can be scaled almost without limit and the premium can accumulate unabated. When intervention costs trend toward zero the negative terms vanish, allowing the Efficiency Premium to accumulate without bound.</p> <h2 id="measurement-methodology">Measurement Methodology</h2> <ol> <li> <strong>Task Extraction.</strong> For unstructured chat logs we apply Clio’s embedding+pattern pipeline (DP noise $\epsilon=0.5$) <d-cite key="Handa2025"></d-cite>.</li> <li> <strong>Dollar Valuation.</strong> <ul> <li> <em>Software</em>: Upwork median payout $\tilde{p}=$ \$500; full ticket pool \$1M <d-cite key="Miserendino2025"></d-cite>.</li> <li> <em>Healthcare</em>: average avoided readmission saves \$12,000 (CMS FY-24); multiply HealthBench rubric score by that coefficient <d-cite key="Arora2025"></d-cite>.</li> </ul> </li> <li> <strong>Human-Intervention Logging.</strong> Tag manual edits, escalations, or tool fallbacks. Frontier models still miss $\sim 60%$ of SWE-Lancer tasks <d-cite key="Miserendino2025,liang2025swe"></d-cite>.</li> <li> <strong>Experience Accounting.</strong> Tokens spent on self-play or simulation $\to$ <em>Exploration Opex</em>; indispensable for the experience-era view <d-cite key="SilverSutton2025"></d-cite>.</li> </ol> <p><strong>Data–Asset Valuation.</strong> Interaction logs generated during agent operation accrue as an <em>intangible data asset</em>. Under GAAP we expense collection and cleaning costs immediately, but we may capitalise the curated corpus once it demonstrably improves future cash flows (analogous to software development costs that pass technological feasibility). The same treatment applies under IFRS (IAS 38), where the asset is amortised over the useful life of the model. We therefore track a “Data R&amp;D” line item that migrates to the balance-sheet once the corpus clears the feasibility gate, providing an auditable bridge from token spend to book value.</p> <h2 id="empirical-benchmarks">Empirical Benchmarks</h2> <h3 id="anthropic-clio-national-task-adoption">Anthropic Clio: National Task Adoption</h3> <p><strong>Key findings</strong> <d-cite key="Handa2025"></d-cite>:</p> <ul> <li>46% of usage involves software and writing tasks; less than 0.5% involves physical manipulation.</li> <li>Only 4% of occupations use AI for at least 75% of their tasks, implying a high baseline human–intervention rate (HIR).</li> <li>Uptake peaks in <em>Job–Zone 4</em>, corresponding to bachelor-level pay-grade roles.</li> <li>57% of usage suggests human–AI collaboration, while 43% represents full automation.</li> </ul> <h3 id="swelancer-outcomepriced-coding">SWE–Lancer: Outcome–Priced Coding</h3> <p>The dataset comprises 1,488 Upwork tickets totalling \$1M in payouts. Claude 3.5 Sonnet earns \$403k, yielding a median cost–saving rate (CSR) of roughly \$300 and an HIR of about 74% <d-cite key="Miserendino2025"></d-cite>. Robust human–written tests mitigate grader gaming.</p> <h3 id="healthbench-safetycritical-triage">HealthBench: Safety–Critical Triage</h3> <p>GPT–4o scores 32%, whereas a later model (<em>o3</em>) scores 60% <d-cite key="Arora2025"></d-cite>. Using the \$12,000 valuation coefficient (Section 4), GPT–4o’s 32% rubric score translates to a CSR of approximately \$3,840 per triage (0.32 $\times$ \$12,000). The <em>o3</em> model, with a 60% score, yields an HIR of roughly 40%.</p> <h2 id="examples">Examples</h2> <p>To demonstrate the diagnostic utility of the <strong>AI Fundamentals</strong> framework, we apply it to three <strong>simulated</strong> business scenarios. While these case studies are hypothetical, the parameters are modeled on realistic operational baselines and current frontier model pricing <d-cite key="ackerman2025perceptions"></d-cite>. These simulations illustrate how the AEV equation decomposes complex agent deployments into clear economic drivers, highlighting the interplay between cost savings, efficiency gains, and the critical “tax” of human intervention.</p> <h3 id="example-1-ai-powered-market-research-analysis-and-report-generation">Example 1: AI-Powered Market Research Analysis and Report Generation</h3> <p>We model a hypothetical consulting firm, <em>InsightCorp</em>, that deploys an AI agent to streamline the production of market research.</p> <p><strong>Scenario and Baseline</strong></p> <ul> <li> <strong>Task</strong>: Analyze market trends and generate a client-ready 50-page report.</li> <li> <strong>Baseline (Human-Only)</strong>: 2 analysts, 10 days (160 hours), \$75/hour = \$12,000 per report.</li> <li> <strong>Output</strong>: Maximum 2 reports per month per team.</li> </ul> <p><strong>AI Fundamentals Metrics (Simulated)</strong></p> <p><em>Cost Saving</em></p> <ul> <li>AI processing: \$500</li> <li>Human review (reduced to 40 hours): \$3,000</li> <li>Total agent-assisted cost: \$3,500</li> <li> <strong>Cost Saving</strong> = \$12,000 - \$3,500 = **\$8,500 per report**</li> </ul> <p><em>Efficiency Premium</em></p> <ul> <li>Increased throughput (4 reports/month vs. 2): \$10,000 per report</li> <li>Enhanced quality/scope: \$1,000 per report</li> <li> <strong>Efficiency Premium</strong> = <strong>\$11,000 per report</strong> </li> </ul> <p><em>Human Intervention Cost</em></p> <ul> <li>In this model, 19 reports require only planned review.</li> <li>1 report needs significant rescue (vs. previous 2).</li> <li>Intervention incidents: 1 out of 20 reports required rescue (5%).</li> <li> <strong>Intervention penalty</strong>: We assign a simulated governance penalty of \$10 per basis point of intervention; hence 450 b.p. = 4.5% $\times$ 10 = \$4,500.</li> </ul> <p><em>Agent Economic Value (AEV)</em></p> <ul> <li>Additional costs (infrastructure, exploration): \$1,000</li> <li>Intervention penalty: \$10/b.p. $\times$ 450 b.p. = \$4,500 (reduced from \$9,500)</li> <li> <strong>AEV</strong> = \$8,500 + \$11,000 - (\$1,000 + \$4,500) = **\$14,000 per report**</li> </ul> <p><strong>Key Outcomes</strong> The simulation suggests that even with a 5% intervention rate, the system achieves:</p> <ul> <li>71% cost reduction (\$8,500 savings per report)</li> <li>100% increased throughput (4 vs. 2 reports monthly)</li> <li>117% ROI (\$14,000 profit/\$12,000 baseline cost)</li> </ul> <p>Further reducing intervention incidents to 2% in this model would add another \$3,000 to AEV (to \$17,000), highlighting how reliability directly impacts profitability.</p> <h3 id="example-2-ai-enhanced-customer-support-automation">Example 2: AI-Enhanced Customer Support Automation</h3> <p>Next, we simulate <em>ConnectSphere Inc.</em>, a hypothetical telecom company deploying an AI system to handle Tier-1 support.</p> <p><strong>Scenario and Baseline</strong></p> <ul> <li> <strong>Task Domain</strong>: Tier-1 customer support (password resets, billing inquiries, basic troubleshooting)</li> <li> <strong>Baseline</strong>: 100 agents handling 50,000 monthly interactions at \$10 per interaction (\$500,000 total)</li> <li> <strong>Service Quality</strong>: 15-minute average resolution time, 70% CSAT score</li> </ul> <p><strong>AI Fundamentals Metrics (Simulated)</strong></p> <p><em>Cost Saving</em></p> <ul> <li>AI fully resolves 20,000 interactions; humans handle 30,000 with AI assistance</li> <li>AI system cost: \$50,000</li> <li>Reduced human staffing: 50 agents at \$5,000 each = \$250,000</li> <li> <strong>Cost Saving</strong> = \$500,000 - \$300,000 = **\$200,000 per month**</li> </ul> <p><em>Efficiency Premium</em></p> <ul> <li>CSAT improvement (70% $\to$ 88%), reducing churn: \$120,000</li> <li>24/7 availability: \$20,000</li> <li> <strong>Efficiency Premium</strong> = **\$140,000 per month** (increased from previous \$120,000)</li> </ul> <p><em>Human Intervention Cost</em></p> <ul> <li>600 interactions (3% of AI-only attempts) require human rescue (reduced from 5%)</li> <li> <strong>Intervention penalty</strong>: We assign a governance penalty of \$50 per basis point of intervention; hence 200 b.p. = 2% $\times$ \$50 = \$10,000.</li> </ul> <p><em>Agent Economic Value (AEV)</em></p> <ul> <li>Intervention penalty: \$50/b.p. $\times$ 200 b.p. = \$10,000 (reduced from \$20,000)</li> <li> <strong>AEV</strong> = \$200,000 + \$140,000 - (\$0 + \$10,000) = **\$330,000 per month**</li> </ul> <p><strong>Key Outcomes</strong> In this scenario, the agent delivers a \$330,000 monthly profit (66% return). Key drivers in the model include:</p> <ul> <li>40% cost reduction (\$200,000 monthly savings)</li> <li>67% faster resolution (5 vs. 15 minutes for AI-handled queries)</li> <li>26% CSAT improvement (70% $\to$ 88%)</li> </ul> <h3 id="example-3-ai-driven-deep-research-in-finance">Example 3: AI-Driven Deep Research in Finance</h3> <p>Finally, we consider a simulated quantitative asset-management firm, <em>AlphaFunds</em>, deploying an LLM agent for forensic financial analysis.</p> <p><strong>Scenario and Baseline</strong></p> <ul> <li> <strong>Task:</strong> Produce a 20-page forensic analysis covering accounting quality, competitive moat, and scenario valuation for one ticker.</li> <li> <strong>Baseline (Human-Only):</strong> 1 senior analyst + 2 associates, 80 hours total at an average blended rate of \$180/h $\Rightarrow$ \$14,400 per report.</li> <li> <strong>Throughput:</strong> 10 tickers per quarter.</li> </ul> <p><strong>AI Fundamentals Metrics (Simulated)</strong></p> <p><em>Cost Saving</em></p> <ul> <li>LLM inference and retrieval cost: \$400.</li> <li>Human review (senior analyst 8 h): \$1,440.</li> <li>Total agent-assisted cost: \$1,840.</li> <li> <strong>Cost Saving</strong> = \$14,400 - \$1,840 = \$12,560 per report.</li> </ul> <p><em>Efficiency Premium</em></p> <ul> <li>Faster turn-around enables coverage of 25 tickers/quarter (2.5× baseline) generating incremental fee income of \$30,000.</li> <li>Richer alt-data synthesis improves hit-rate, adding expected alpha worth \$5,000 per report.</li> <li> <strong>Efficiency Premium</strong> = \$35,000 / 25 $\approx$ \$1,400 per report.</li> </ul> <p><em>Human Intervention Cost</em></p> <ul> <li>2 of 25 reports require significant rewrites $\Rightarrow$ <strong>Intervention penalty</strong>: We assign a governance penalty of \$15 per basis point of intervention; hence 700 b.p. = 7% $\times$ \$15 = \$10,500.</li> <li>Policy gate: 1% (100 b.p.) $\Rightarrow$ excess 700 b.p.</li> </ul> <p><em>Agent Economic Value (AEV)</em></p> <ul> <li>Model Cost (inference tokens + premium): \$400.</li> <li>Data Cost (alt-data subscription slices): \$150.</li> <li>Intervention penalty ($\lambda$ = 15 b.p.): \$10,500.</li> <li> <strong>AEV</strong> = \$12,560 + \$1,400 - (\$400 + \$150) - \$10,500 = \$2,910 per report.</li> </ul> <p><strong>Key Outcomes</strong> Even after a heavy intervention penalty, the simulated agent achieves a 20% profit margin. Reducing the intervention rate to 2% in the model would lift AEV above \$10,000.</p> <figure style="text-align: center;"> <img src="/2026/assets/img/2026-04-27-economic-agents/aev_returns_costs_v2.png" width="98%"> <figcaption style="font-size: 1em;">Figure 4: <strong>AEV Structural Analysis: Returns vs. Costs.</strong> The top row displays the composition of economic flows, highlighting the Net Margin (AEV / Total Returns) for each simulated domain. The bottom row contrasts absolute Returns (Cost Saving + Efficiency Premium) against Costs (Human Intervention + Model + Data). While <em>Support Automation</em> (center) benefits from massive scale and low intervention costs, the <em>Finance Deep Research</em> agent (right) illustrates the "reliability tax," where high human intervention costs significantly compress the net margin despite valid cost savings.</figcaption> </figure> <h2 id="the-reinforcement-learning-accelerator">The Reinforcement Learning Accelerator</h2> <p>The advent of advanced Reinforcement Learning (RL) <d-cite key="wang2025reinforcement,pippas2025evolution"></d-cite> techniques promises to significantly accelerate agent development and performance. As argued by Silver &amp; Sutton, the focus is shifting towards agents that learn from <em>experience</em> by optimizing for grounded rewards directly tied to economic outcomes like profit, or operational metrics like latency <d-cite key="lin2025stop"></d-cite>, rather than relying solely on static human feedback <d-cite key="SilverSutton2025"></d-cite>. The core idea is to define the agent’s objective function in terms of our framework’s value metrics. The total return $G_t$ at a given step $t$ is the sum of immediate economic contributions, $G_t = \text{CostSaving}_t + \text{EfficiencyPremium}_t$. The agent’s learning problem then becomes maximizing the expected cumulative discounted Agent Economic Value over an infinite horizon:</p> \[\begin{aligned} \max_\pi \mathbb{E}\Biggl[ &amp; \sum_{k=0}^{\infty} \gamma^k ( (\text{CostSaving}_{t+k} + \text{EfficiencyPremium}_{t+k}) - \\ &amp; \text{ModelCost}_{t+k} - \text{DataCost}_{t+k} - \text{HumanInterventionCost}_{t+k} ) \Biggr]. \end{aligned}\] <p>Here, the agent’s policy $\pi$ is learned to maximize this sum, where $\gamma$ is the discount factor; each term directly reflects measurable economic impact of the agent’s actions.</p> <p>A critical factor for successful RL-driven development is the creation of high-fidelity <em>simulation environments</em>. These environments must closely mirror the specific real-world scenarios in which the agent will operate, including the nuances of tasks, data distributions, and potential failure modes. By interacting with such well-crafted environments (effectively digital twins of operational realities), an agent can rapidly accumulate a vast amount of experience, far exceeding what is feasible with direct real-world interaction alone or from static datasets. For instance, AlphaProof achieved superhuman problem-solving by generating 100 million proofs through interaction with a dedicated proof environment, starting from an initial seed of 100k human proofs <d-cite key="SilverSutton2025"></d-cite>.</p> <p>This RL-driven, experience-based learning paradigm is central to achieving the long-run vision: an agent with consistently high Agent Economic Value. Such an agent continuously expands its capabilities—thereby raising Cost Saving and the Efficiency Premium—while actively learning to keep intervention costs negligible through ongoing adaptation and refinement within its operational or simulated domain. The key is not just the RL algorithms themselves, but the synergy between these algorithms and rich, representative environments that enable effective and accelerated learning.</p> <h2 id="future-outlook-agentic-liquidity-and-the-mcp-wallet">Future Outlook: Agentic Liquidity and The MCP Wallet</h2> <p>The current AEV equation assumes the agent works with fixed resources. However, as agents move toward full autonomy, we must extend the framework to include <strong>Agentic Liquidity</strong>. This is the ability of the agent to hold and spend capital—”MCP form money”—to complete tasks.</p> <h3 id="the-problem-closed-resource-loops">The Problem: Closed Resource Loops</h3> <p>Currently, if an agent lacks a specific tool or data source (e.g., a real-time Bloomberg terminal feed or a paid API for specialized protein folding), it fails or reports to a human. This spikes $C_{\text{human}}$ and lowers AEV.</p> <h3 id="the-solution-the-settlement-layer">The Solution: The Settlement Layer</h3> <p>We propose extending the MCP architecture to include a <strong>financial settlement layer</strong>. This transforms the agent from a passive software user into an active economic participant.</p> <p>In this model, the MCP is endowed with a wallet containing AI-native currency (stablecoins or equivalent). The agent can autonomously decide to incur a dynamic <strong>Transaction Cost</strong> ($C_{\text{txn}}$) to purchase:</p> <ol> <li> <strong>Private APIs &amp; Tools:</strong> Accessing paid SaaS tools or specialized computation (e.g., “renting” a physics engine for 5 minutes).</li> <li> <strong>Gated Data Sources:</strong> Paywall unlocking or purchasing high-fidelity datasets on the fly to improve inference quality.</li> <li> <strong>Inter-Agent Services:</strong> Hiring other specialized agents (e.g., a Generalist Agent hiring a specialized Legal Agent for contract review).</li> </ol> <h2 id="conclusion">Conclusion</h2> <p>Our framework collapses the valuation of AI agents into a single, auditable cash–flow metric—Agent Economic Value (AEV). AEV integrates</p> <ul> <li> <strong>Cost Saving</strong> (direct expense reduction),</li> <li> <strong>Efficiency Premium</strong> (new revenue or throughput), and</li> <li>the three marginal costs of <strong>Model</strong>, <strong>Data</strong>, and <strong>Human Intervention</strong>.</li> </ul> <p>This lens unifies technical performance and financial reporting into one number that investors and operators can track just like any other business KPI <d-cite key="ackerman2025perceptions"></d-cite>. Empirical studies across software <d-cite key="Miserendino2025"></d-cite>, healthcare <d-cite key="Arora2025"></d-cite>, and large-scale enterprise usage <d-cite key="Handa2025,erol2025cost"></d-cite> demonstrate that every term in the AEV equation can be measured today.</p> <p>As the Era of Experience unfolds and agents increasingly learn from and act in the real world <d-cite key="ide2024artificial,SilverSutton2025"></d-cite>, the AEV framework will be indispensable to ensure that technical progress translates into measurable economic value. By pushing Cost Saving and the Efficiency Premium up while driving the three cost terms down, organizations can continuously optimise agent deployments in a language the CFO understands.</p> <p>The future of AI valuation lies in this synthesis of technical capability and financial discipline <d-cite key="erol2025cost"></d-cite>. When Cost Saving and Efficiency Premium rise faster than Model, Data, and Human Intervention Costs, the resulting positive Agent Economic Value creates sustainable economic impact that can be measured, predicted, and optimised across diverse domains.</p> <p><em>Read pipes feed knowledge; write pipes mint dollars; training data re-wires the mint. Keep intervention costs low and the cash machine hums.</em></p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/2026/assets/bibliography/2026-04-27-economic-agents.bib"></d-bibliography> <d-article> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/wait-do-we-need-to-wait/">Wait, Do We Need to Wait? Revisiting Budget Forcing for Sequential Test-Time Scaling</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/tracing-principles-behind-modern-diffusion-models/">Tracing the Principles Behind Modern Diffusion Models</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/symbolic-connect/">From Dense Monoliths to Modular Minds: The Rise of Symbolic Routing in LLMs</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/speeding-up-rl/">Speeding up Training of Model-Free Reinforcement Learning :A Comparative Evaluation for Fast and Accurate Learning</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/sac-massive-sim/">Getting SAC to Work on a Massive Parallel Simulator: An RL Journey With Off-Policy Algorithms</a> </li> <br> <br> </d-article> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 ICLR Blog. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/2026/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script src="/2026/assets/js/distillpub/overrides.js"></script> <script defer src="https://cdn.jsdelivr.net/npm/mermaid@10.7.0/dist/mermaid.min.js" integrity="sha256-TtLOdUA8mstPoO6sGvHIGx2ceXrrX4KgIItO06XOn8A=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/d3@7.8.5/dist/d3.min.js" integrity="sha256-1rA678n2xEx7x4cTZ5x4wpUCj6kUMZEZ5cxLSVSFWxw=" crossorigin="anonymous"></script> <script defer src="/2026/assets/js/mermaid-setup.js?38ca0a0126f7328d2d9a46bad640931f" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/2026/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/2026/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/2026/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/2026/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/2026/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/2026/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/2026/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/2026/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/2026/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/2026/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/2026/assets/js/search-data.js"></script> <script src="/2026/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>