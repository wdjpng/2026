<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> How to Transition from ML to DL in Production - Lessons From the Trenches at Company | ICLR Blogposts 2026 </title> <meta name="author" content="ICLR Blog"> <meta name="description" content="A mature and entrenched boosting system has been powering Company’s risk systems for years. We outline our year long incremental migration strategy to a pure deep learning system which is highlighted by an intermediate heterogeneous ensembling phase used to reached parity and then outperforming our boosting model in production. We learned along the way that a simple MLPs can beat sophisticated tabular DL architectures at million-scale (1); ensembling is a practical bridge from ML to DL (2); and the biggest wins from DL are often beyond metrics (3)."> <meta name="keywords" content="machine-learning, ml, deep-learning, reinforcement-learning, icl# add your own keywords or leave empty"> <link rel="stylesheet" href="/2026/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/2026/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/2026/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/2026/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/2026/assets/img/iclr_favicon.ico?0a8a3afdb0dbe139723b24dba3052a4f"> <link rel="stylesheet" href="/2026/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://iclr-blogposts.github.io/2026/blog/2026/from-ml-to-dl/"> <script src="/2026/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/2026/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <script src="/2026/assets/js/distillpub/template.v2.js"></script> <script src="/2026/assets/js/distillpub/transforms.v2.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "How to Transition from ML to DL in Production - Lessons From the Trenches at Company",
            "description": "A mature and entrenched boosting system has been powering Company’s risk systems for years. We outline our year long incremental migration strategy to a pure deep learning system which is highlighted by an intermediate heterogeneous ensembling phase used to reached parity and then outperforming our boosting model in production. We learned along the way that a simple MLPs can beat sophisticated tabular DL architectures at million-scale (1); ensembling is a practical bridge from ML to DL (2); and the biggest wins from DL are often beyond metrics (3).",
            "published": "April 27, 2026",
            "authors": [
              
              {
                "author": "Anonymous",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/2026/"> ICLR Blogposts 2026 </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/2026/">home </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/about/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/call/">call for blogposts </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/submitting/">submitting </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/reviewing/">reviewing </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">past iterations </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2026/"><strong>2026</strong></a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2025/">2025</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2024/">2024</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2023/">2023</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blog-track.github.io/home/" rel="external nofollow noopener" target="_blank">2022</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>How to Transition from ML to DL in Production - Lessons From the Trenches at Company</h1> <p>A mature and entrenched boosting system has been powering Company’s risk systems for years. We outline our year long incremental migration strategy to a pure deep learning system which is highlighted by an intermediate heterogeneous ensembling phase used to reached parity and then outperforming our boosting model in production. We learned along the way that a simple MLPs can beat sophisticated tabular DL architectures at million-scale (1); ensembling is a practical bridge from ML to DL (2); and the biggest wins from DL are often beyond metrics (3).</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#background-fraud-detection-at-company">Background - Fraud Detection at Company</a> </div> </nav> </d-contents> <p>It is a widely held belief in the ML community that tree-based models are the most sensible choice for tabular data and that neural networks will invariably underperform. As a result, using neural networks in this domain is frequently met with skepticism—not only regarding their potential performance, but also their practicality (e.g., latency, GPU requirements, interpretability).</p> <p>These concerns are empirically motivated <d-cite key="grinsz"></d-cite>, but often misunderstood: for any fixed search budget, tree-based models consistently outperform non–tree-based alternatives. However, we argue that the perceived underperformance often stems from two factors: scale and uncertainty.</p> <p>First, many empirical comparisons rely on small-scale academic benchmarks that favor sample-efficient tree-based methods while underutilizing neural networks. Second, feasibility concerns often implicitly equate “deep learning” with large-language-model–style infrastructure—multi-billion-parameter architectures, expensive training pipelines, and complex deployment stacks—when in fact tabular neural networks need not resemble LLMs in either size or serving complexity.</p> <p>In this work, we describe the migration of our flagship risk system – scoring thousands of transactions per second – from a large, well-tuned tree-based model to a neural network. We also outline why we believe that, at scale, neural networks can not only match but surpass gradient-boosted trees on tabular data, while bringing substantial ancillary benefits.</p> <h2 id="background---risk-at-company">Background - Risk at Company</h2> <p>Company processes large volumes of payments for merchants worldwide. A key component of this process is our Fraud Detection Model (FDM), which estimates in real time the likelihood that a payment is fraudulent, allowing the system to approve, challenge, or block transactions accordingly.</p> <p>The cost of errors is high. Type I errors (blocking legitimate payments) degrade merchant authorization rates and harm shopper experience, while Type II errors (approving fraudulent transactions) lead to direct financial losses. Balancing these trade-offs while maintaining low latency and high throughput is central to the design of our risk models.</p> <p>Our system consumes a large and evolving feature set, including:</p> <ul> <li>basic payment-level features</li> <li>aggregate features (rolling statistics across merchant and shopper dimensions) computed by our feature platform</li> <li>shopper history signals served through our entity-linking system</li> <li>velocity features such as recent payment attempts across multiple dimensions</li> <li>structured and semi-structured string fields containing raw payment metadata</li> </ul> <pre><code class="language-mermaid">graph LR
    PR[Payment Request]

    subgraph "Feature Stores"
        FP[Feature Platform]
        SL[Shopper Linking]
        VDB[Velocity Database]
    end


    subgraph "Features"
        BF[Payment Information]
        SF[PII Fields]
        AF[Payment Aggregations]
        SHF[Shopper History]
        VF[Payment Velocity]
    end

    FDM[FDM]

    PR --&gt; BF
    PR --&gt; SF

    PR -.-&gt; FP
    PR -.-&gt; SL
    PR -.-&gt; VDB

    FP --&gt; AF
    SL --&gt; SHF
    VDB --&gt; VF

    BF --&gt; FDM
    SF --&gt; FDM
    AF --&gt; FDM
    SHF --&gt; FDM
    VF --&gt; FDM
</code></pre> <p>Historically, our risk stack was built around a large boosting model. It was easy to adopt, straightforward to scale, and strong on tabular data. As a result, raw model choice was not an immediate bottleneck: most improvements came from feature engineering, platform integration, and expanding model scope – making deep learning difficult to prioritize.</p> <p>Over time, however, signs emerged that a shift could unlock further gains. Many input signals are inherently sequential (timestamps, event streams) or textual. While engineered proxies helped — rolling-window aggregates, hashed or bucketed email features – these approaches approximate rather than directly learn from raw signal structure.</p> <p>Operational pressures also increased. Growing transaction volume (billion scale) and feature count strained out-of-core training and constant-memory inference. Meanwhile, Company’s long-term strategy emphasized deep learning: foundational payments models, model unification, and multi-task learning.</p> <p>We hypothesized that a well-designed neural network could provide both first-order performance uplift and second-order benefits: improved representation learning, reduced feature-engineering burden, better extensibility, and alignment with strategic goals.</p> <h2 id="why-deep-learning-on-tabular-data-might-work">Why Deep Learning on Tabular Data Might Work</h2> <p>To see why neural networks could eventually outperform tree-based models on tabular data, we must first understand <strong>why boosting works so well today.</strong></p> <h3 id="why-tree-based-models-excel-at-tabular-data">Why Tree-Based Models Excel at Tabular Data</h3> <p>Tree-based models remain the dominant choice for tabular tasks because their <strong>inductive bias matches the structure of the data.</strong> Tabular features are often categorical, sparse, piecewise, and highly non-smooth. Trees naturally capture this structure through axis-aligned splits and non-linear rule partitions. A single decision tree already encodes sharp discontinuities and local feature interactions that dense NNs typically struggle with <d-cite key="grinsz"></d-cite></p> <p>.</p> <p>Added to that and true power of boosting emerges from ensembling. Boosting constructs a large committee of weak learners, each correcting the residuals of the previous one, yielding a flexible and high-capacity model. This <em>homogeneous ensemble</em> scales extremely well with modest compute and is sample-efficient—crucial advantages for most tabular benchmarks.</p> <p>This connects to the <strong>No Free Lunch principle</strong>: no single model class is universally optimal, but <strong>an ensemble of diverse models often outperforms any single one.</strong></p> <p>Ensembling underlies:</p> <ul> <li><strong>bagging</strong></li> <li><strong>boosting (XGBoost, LightGBM)</strong></li> <li><strong>stacking — the backbone of most Kaggle-winning tabular systems</strong></li> </ul> <p>In short:</p> <blockquote> <p><strong>Boosting ≈ Trees (right inductive bias) + Ensembling (power multiplier).</strong><br> If we want the benefits of NNs without losing performance, we must replicate <em>both</em> components.</p> </blockquote> <p>Lets take homogeneous ensembling to it’s logical conclusion: heterogenous ensembling.</p> <h3 id="heterogeneous-ensembling-with-deep-models">Heterogeneous Ensembling with Deep Models</h3> <p>This observation suggests a natural migration path: <strong>extend boosting from a homogeneous ensemble of trees to a heterogeneous ensemble that mixes trees and neural models.</strong></p> <p>Rather than replacing the tree model outright, we can <strong>stack</strong> multiple learners—boosters, MLPs, attention models—and train a meta-learner over their predictions. This leverages complementary inductive biases while keeping the stable baseline in place.</p> <p>Heterogeneous ensembling has repeatedly proven effective in practice<d-cite key="tabarena, tabm"></d-cite>. And it makes sense, if boosting is an ensemble or trees, why would not compare NNs against it as an ensemble? Why leap directly from boosting to deep learning; instead, <strong>ensembling serves as a stable bridge</strong> while the neural model matures.</p> <pre><code class="language-mermaid">graph TD
  A[Input Features]

  subgraph "Base Learners"
      B[Neural Net]
      C[Alternative NN]
      D[Booster 1]
      E[Booster 2]
  end

  A --&gt; B
  A --&gt; C
  A --&gt; D
  A --&gt; E

  F(Meta-Learner)
  B --&gt; F
  C --&gt; F
  D --&gt; F
  E --&gt; F

  F --&gt; G[Final Prediction]
</code></pre> <p>Stacking allows:</p> <ul> <li>immediate incremental uplift from adding a small NN</li> <li>continuous improvement as NN architectures mature</li> <li>safe fallback to boosting during migration</li> </ul> <p>This leads to the final question: how do we tackle the inductive bias problem in NNs?</p> <p>##. How Do We Make Neural Networks Competitive on Tabular Data?</p> <p>Despite strong ensembles, neural networks still typically underperform trees on tabular tasks <d-cite key="tabm"></d-cite>. The gap is driven by differences in inductive bias <d-cite key="grisz"></d-cite>:</p> <ol> <li>Smoothness bias — MLPs favor smooth boundaries; tabular patterns are often sharp.</li> <li>Rotational invariance — NNs are rotation-invariant, while trees exploit axis alignment.</li> <li>Scale sensitivity — trees excel at small/medium datasets; NNs need regularization and data.</li> </ol> <blockquote> <p>Takeaway: You can’t just throw NNs at tabular data (w/ a meaningful budget).</p> </blockquote> <p>However, recent work <d-cite key="excelformer, realmlp, reg-is-all-you-need"></d-cite> shows these limitations can be overcome with thoughtful tuning:</p> <ul> <li>discretization and learned embeddings for continuous values <d-cite key="embeddings"></d-cite> </li> <li>attention architectures for tabular structure <d-cite key="excelformer"></d-cite> </li> <li>large-scale training + augmentation <d-cite key="excelformer"></d-cite> </li> <li>regularization <d-cite key="excelformer, realmlp, reg-is-all-you-need"></d-cite> </li> <li>activations <d-cite key="excelformer"></d-cite> </li> </ul> <p>Alongside industry reports where NNs eventually outperformed boosting <d-cite key="facebook, stripe, sharechat, swiggy"></d-cite>, these results suggest that:</p> <blockquote> <p>If we design the right inductive bias for NNs — and ensemble them during migration — they can match or surpass boosted trees at scale.</p> </blockquote> <p>In the next section, we describe how we operationalized and tested this hypothesis at Company.</p> <h2 id="operationalizing-the-migration-our-approach">Operationalizing the Migration: Our Approach</h2> <p>The complete transition of our fraud detection models from ML to DL ranged from October 2024 to September 2025. Given the uncertainties regarding the performance and deployability of neural networks and ensembling models, we avoided a large-scale monolithic migration and instead focused on shorter, iterative experiments.</p> <h3 id="offline-experiments">Offline Experiments</h3> <p>We ran an initial feasibility study to evaluate the performance of neural networks against our boosting model baseline. For simplicity and arguably lack of nuance, we used the existing boosting feature set unmodified. We built a lightweight experimentation loop focused on rapid iteration rather than production readiness. We initially experimented with simple MLP and ResNet<d-cite key="gorishniy2023revisitingdeeplearningmodels"></d-cite> architectures to novel solutions such as FT-Transformer (attention-based models for tabular data)<d-cite key="gorishniy2023revisitingdeeplearningmodels"></d-cite>, TabNet<d-cite key="arik2020tabnetattentiveinterpretabletabular"></d-cite>, and ExcelFormer <d-cite key="excelformer"></d-cite>.</p> <p>After running multiple training and tuning experiments, we observed that neural networks overall underperformed by 18% to 30% on our internal metrics versus our boosting baselines across a combination of architectures and encoding schemes:</p> <ul> <li> <p>On the architecture side, we surprisingly observed that performance metrics did not significantly differ across architectures: simple architectures such as MLP and ResNet were just as good (or, in this case, just as bad) as complex ones such as FT-Transformer or TabNet, although the latter were shown to bring significant performance uplift on smaller benchmarks <d-cite key="tabred"></d-cite>. Furthermore, model training time increased significantly with the complexity of the architectures on our then fairly immature GPU cluster, rendering the training of some architectures, like ExcelFormer, prohibitively time-consuming.</p> </li> <li> <p>On the encoding side, we found that an adequate encoding scheme for numerical and categorical features was essential for acceptable performance from neural networks. Here again, complex encoding schemes such as piecewise linear encoding or numerical embeddings <d-cite key="embeddings"></d-cite> did not bring uplift and sometimes significantly increased training time. A simple combination of standard scaling and masking missing values for numerical features, and learned embeddings for categorical features, gave the best results.</p> </li> </ul> <p>This first run of experiments allowed us to settle, quite surprisingly, on the simplest available architecture: a wide, shallow MLP of around 10M parameters. This architecture yielded superior performance among the architectures we could train (in a close tie with ResNet) and trained relatively fast, taking around 10 hours at the time to converge on our training sets.</p> <p>The surprising finding that a simple MLP was the most stable and scalable architecture for our problem shifted our strategy from finding the best architecture to making a simple architecture good at scale and matches recent findings in the literature <d-cite key="realmlp"></d-cite><d-cite key="facebook"></d-cite>.</p> <h3 id="ensembling-as-a-bridge">Ensembling as a Bridge</h3> <p>We then turned our efforts to the stacking ensemble strategy that would best complement the MLP architecture. We used a simple ridge classifier as our meta-learner and compared two popular forms of stacking:</p> <ul> <li>A <em>simple</em> stacking scheme in which the predictions of the MLP and the boosting model are fed as two inputs to the meta-learner. This is the most basic form of stacking, as the meta-learner receives only two input features with no extra information about the sample it is scoring.</li> <li>A <em>deep</em> stacking scheme in which the predictions of each individual tree from the booster and activations from the second-to-last layer of the MLP are fed to the meta-learner. This allows for a richer representation of the underlying sample being scored <d-cite key="facebook"></d-cite>.</li> </ul> <pre><code class="language-mermaid">graph TD
    A[Input Features]
    
    subgraph boosting [Boosting Model]
      B[Boosting Model]
      subgraph tree_outputs [Individual Trees]
        T1((T1))
        T2((T2))
        T3((...))
        TN((TN))
      end
    end
    
    subgraph neural [Neural Network]
      L1[First Layers]
      subgraph neuron_activations [Last Layer Neurons]
        N1((N1))
        N2((N2))
        N3((...))
        NM((NM))
      end
    end

    A --&gt; B
    B --&gt; T1
    B --&gt; T2
    B --&gt; T3
    B --&gt; TN

    A --&gt; L1
    L1 --&gt; N1
    L1 --&gt; N2
    L1 --&gt; N3
    L1 --&gt; NM
    
    ML[Meta-Learner]

    T1 --&gt; ML
    T2 --&gt; ML
    T3 --&gt; ML
    TN --&gt; ML

    N1 --&gt; ML
    N2 --&gt; ML
    N3 --&gt; ML
    NM --&gt; ML

    ML --&gt; FP[Prediction]
</code></pre> <p>While stacking models added complexity to the codebase, training them was extremely quick and straightforward. Both forms of stacking showed uplift compared to our standalone MLP trained in our first experimental round, which was somewhat expected. However, their individual performance was quite surprising. On the one hand, the simple two-input stacking scheme showed a 3.8% uplift against our flagship boosting model. On the other hand, the deep stacking scheme, although passing substantially more information to the meta-learner, underperformed by 10.8% against the same baseline.</p> <table> <thead> <tr> <th style="text-align: left">Model</th> <th style="text-align: left">Performance vs. Boosting</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">Standalone MLP</td> <td style="text-align: left">-18.0%</td> </tr> <tr> <td style="text-align: left">Stacking (Simple)</td> <td style="text-align: left">+3.8%</td> </tr> <tr> <td style="text-align: left">Stacking (Deep)</td> <td style="text-align: left">-10.8%</td> </tr> </tbody> </table> <p>These results were encouraging since stacking provided direct uplift compared to boosting. Furthermore, there were several unexplored approaches that could provide future performance gains on the neural network side: we had done no feature engineering, hyperparameter tuning was kept minimal, and the network architecture was extremely simple.</p> <p>Given these prospective improvements, we prioritized exploratory work on the transition of the model in production through stacking as it provided a great migration strategy: it gave immediate incremental gains without directly replacing the boosting models and offered a safety net while the neural network matured.</p> <p>However, we remained cautious due to the numerous unknowns regarding its deployability and latency in the live payment flow.</p> <h3 id="live-validation">Live Validation</h3> <p>The next essential step of the migration was validating whether the performance gains obtained through stacking offline could be achieved in production.</p> <p>More specifically, we wanted to ensure that our stacking model could correctly score transactions in production while respecting our strict latency requirements.</p> <p>The simple stacking scheme we settled on made it trivial to combine the boosting model and neural network to fulfill the two model interfaces that would be called in production: <code class="language-plaintext highlighter-rouge">score</code>, which requests a probability of fraud for a transaction, and <code class="language-plaintext highlighter-rouge">explain</code>, which generates merchant-facing signals explaining the model’s decision.</p> <pre><code class="language-mermaid">graph LR
  Score(Score)
  Explain(Explain)

  subgraph "Stacking Predictor"
      subgraph "Torch Predictor"
    NNS(Torch Neural Network)
    NNE(Captum Explanation Module)
  end
  subgraph "Boosting Predictor"
    BMS(LightGBM Booster)
    BME(LightGBM Explanation Module)
  end
    MMS(Ridge Classifier)
    MME(Combine Explanations)
  end

  Score --&gt; NNS
  Score --&gt; BMS
  Explain --&gt; NNE
  Explain --&gt; BME

  NNS --&gt; MMS
  BMS --&gt; MMS
  MMS --&gt; FS(Model Score)

  BME --&gt; MME
  NNE --&gt; MME
  MME --&gt; FE(Model Explanations)
</code></pre> <p>We initially deployed the stacking model on our datacenters in a <em>ghost</em> state, in which they scored duplicated versions of live payments without influencing their outcomes, allowing us to monitor model behavior with minimal risk. The average latency of the stacking model was around 12 ms (versus 5 ms for the boosting model), which was significantly under our latency requirements. These results showed that CPU are more than sufficient for real-time inference, which validate one of the core hypothesis of this work, that NNs/DL doesn’t need GPUs at serving-time.</p> <p>We then gradually rolled out the stacking model to influence payments, with a stacking setup still dominated by our boosting model.</p> <h3 id="scaling-and-transition">Scaling and Transition</h3> <p>With a strong stacking model online, we had time to invest in neural network-specific model improvements with the aim of matching or outperforming stacking to complete the migration. To gauge progress, we tracked the relative importance of boosting and the neural network within the ensemble over time.</p> <p>We ran a large number of parallel experiments to iteratively improve the model: feature encoding, feature engineering, loss function, and training stability were all revisited and meaningfully changed. These incremental changes increased the importance of the neural network within the stacking model, reducing its dependence on trees.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-from-ml-to-dl/figure1-480.webp 480w,/2026/assets/img/2026-04-27-from-ml-to-dl/figure1-800.webp 800w,/2026/assets/img/2026-04-27-from-ml-to-dl/figure1-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-from-ml-to-dl/figure1.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>Finally, we fully switched to the standalone neural network once we observed that it consistently matched or outperformed the stacking model. The stacking strategy we adopted made the entire transition seamless, as the model could just be deployed to production while a stacking fallback was still available.</p> <h2 id="learnings">Learnings</h2> <p>Our migration from a mature boosting model to a pure deep learning model yielded a number of lessons that we believe generalize beyond our specific domain.</p> <p><strong>Start with the simplest possible uplift</strong> The goal of the first experiments was not to “beat” boosting with a sophisticated neural network architecture but to obtain <strong>any credible uplift</strong> in a way that built trust for the rest of the migration. A very simple MLP, combined with a simple two-input stacking scheme, was enough to show measurable gains over the flagship boosting model. This uplift unlocked further investment and bought time for the subsequent transition phases.</p> <p><strong>Use ensembling as a bridge, not a destination</strong> Ensembling was invaluable as a <strong>migration tool</strong>. It allowed us to gradually and safely introduce deep learning into a critical production system while improving performance and maintaining a reliable fallback. At the same time, we treated stacking as a bridge rather than a permanent architecture. Once the neural network consistently dominated the ensemble, the additional complexity of stacking no longer justified itself.</p> <p><strong>Separate feasibility from full productionisation</strong> We deliberately separated the question “Can this model run in production at all?” from “Can it replace the existing model everywhere?”. The initial production deployment focused on <strong>feasibility</strong> by ensuring correctness and speed in the payment flow. Only once these constraints were verified did we invest in making the DL model a first-class citizen in the main training and deployment workflows.</p> <p><strong>Invest in tooling and speed early</strong> Many of the most impactful investments were not in model architecture but in <strong>tooling</strong> such as workflows with fast feedback, efficient data loaders and GPU-aware training pipelines. Shortening our experimentation loop made it easier to iterate on architectures and features. Without this tooling, it would have been tempting to over-index on one-off model tweaks rather than systematic improvement.</p> <p><strong>Do not underestimate simple architectures at scale</strong> On our million-scale tabular problem, a ResNet-style MLP ultimately outperformed more complex tabular DL architectures from the literature. These more complex models tended to be harder to train, slower, and offered little upside once we accounted for our data scale and operational constraints. This shows that at our scale a <strong>simple and robust</strong> architecture was a better fit than a complex and novel one.</p> <h2 id="future-work">Future Work</h2> <p>While the migration is a success in itself that already brought performance improvements in production, we still believe that most of the uplift that neural networks can bring in our domain is yet to be realized. Among these future avenues, we identify:</p> <ul> <li> <p><strong>Multi-task and multi-objective modelling.</strong> Now that the core risk model of Company is powered by a neural network, it becomes easier to consider integrating other domain-specific risk models (e.g. card testing or abusive refunds detection) in a multi-task risk model or using multi-objective losses that balance fraud, customer experience, and operational costs. This could leverage the specificities of these multiple models in a large unified network, and greatly reduce operational overhead.</p> </li> <li> <p><strong>Closer integration with foundation models.</strong> Company has ongoing work on foundation models for payments. A deep learning-based fraud model provides a natural anchor for integrating such models, whether through shared embeddings, pretraining on large-scale transaction data, or joint training for related tasks.</p> </li> <li> <p><strong>Better use of structured and semi-structured fields.</strong> We have only started to exploit the potential of structured fields like anonymised emails or sequence-based velocity features in FDM’s neural network. There is ample room for better architectures and regularisation schemes tailored to these modalities.</p> </li> <li> <p><strong>Benchmarks that reflect production constraints.</strong><br> Our experience suggests that small academic tabular benchmarks do not fully capture the realities of large-scale production systems where latency, explainability, and stability matter as much as raw performance metrics. Designing benchmarks that incorporate these dimensions could lead to architectures and training schemes that transfer more directly to real-world deployments.</p> </li> <li> <p><strong>Characterising when NNs should replace trees.</strong><br> Finally, we would like to better understand, in a more principled way, when deep learning is likely to dominate gradient-boosted trees in tabular settings. Factors such as data size, feature types, temporal structure, and available infrastructure all play a role. Formalising these trade-offs could help teams decide when to invest in a migration like the one described here.</p> </li> </ul> <p>We hope that this case study, and the concrete migration pattern we followed – from offline experiments, to stacking, to a full deep learning model – can serve as a practical blueprint for teams considering a migration path from ML to DL in production — not by replacing everything at once, but by moving <em>one reversible step at a time</em>.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/2026/assets/bibliography/2026-04-27-from-ml-to-dl.bib"></d-bibliography> <d-article> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/vis-llm-latent-geometry/">Visualizing LLM Latent Space Geometry Through Dimensionality Reduction</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/style-representations/">Artistic Style and the Play of Neural Style Representations</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/spatial-awareness/">Where's the Chicken? Unpacking Spatial Awareness in Vision-Language Models</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/sparsity/">Don't Look Up (Every Token): Escaping Quadratic Complexity via Geometric Patterns and Algorithms</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/scaling-rlvr/">Scaling Online RLVR Done Right with Decoupled Generation &amp; Optimization</a> </li> <br> <br> </d-article> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 ICLR Blog. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/2026/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script src="/2026/assets/js/distillpub/overrides.js"></script> <script defer src="https://cdn.jsdelivr.net/npm/mermaid@10.7.0/dist/mermaid.min.js" integrity="sha256-TtLOdUA8mstPoO6sGvHIGx2ceXrrX4KgIItO06XOn8A=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/d3@7.8.5/dist/d3.min.js" integrity="sha256-1rA678n2xEx7x4cTZ5x4wpUCj6kUMZEZ5cxLSVSFWxw=" crossorigin="anonymous"></script> <script defer src="/2026/assets/js/mermaid-setup.js?38ca0a0126f7328d2d9a46bad640931f" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/2026/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/2026/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/2026/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/2026/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/2026/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/2026/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/2026/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/2026/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/2026/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/2026/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/2026/assets/js/search-data.js"></script> <script src="/2026/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>