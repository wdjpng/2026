<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Wait, Do We Need to Wait? Revisiting Budget Forcing for Sequential Test-Time Scaling | ICLR Blogposts 2026 </title> <meta name="author" content="ICLR Blog"> <meta name="description" content="This blog revisits budget forcing, a sequential test-time scaling technique for reasoning models by controlling when it continues thinking versus when it must answer. We evaluate how well the method transfers across model types, including non-reasoning models, and whether alternative keywords work. We provide practical guidelines for using the technique."> <meta name="keywords" content="machine-learning, ml, deep-learning, reinforcement-learning, icl# add your own keywords or leave empty"> <link rel="stylesheet" href="/2026/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/2026/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/2026/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/2026/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/2026/assets/img/iclr_favicon.ico?0a8a3afdb0dbe139723b24dba3052a4f"> <link rel="stylesheet" href="/2026/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://iclr-blogposts.github.io/2026/blog/2026/wait-do-we-need-to-wait/"> <script src="/2026/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/2026/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <script src="/2026/assets/js/distillpub/template.v2.js"></script> <script src="/2026/assets/js/distillpub/transforms.v2.js"></script> <style type="text/css">:root{--co-accent:#6366f1;--co-bg:#f8fafc;--co-border:#e2e8f0;--co-text:#334155;--co-title:#0f172a}@media(prefers-color-scheme:dark){:root{--co-accent:#818cf8;--co-bg:#1e293b;--co-border:#334155;--co-text:#cbd5e1;--co-title:#f1f5f9}}[data-theme="dark"]{--co-accent:#818cf8;--co-bg:#1e293b;--co-border:#334155;--co-text:#cbd5e1;--co-title:#f1f5f9}[data-theme="light"]{--co-accent:#6366f1;--co-bg:#f8fafc;--co-border:#e2e8f0;--co-text:#334155;--co-title:#0f172a}.highlight-card{display:flex;flex-direction:row;align-items:flex-start;gap:1rem;width:100%;padding:1.25rem;margin:1.5rem 0;box-sizing:border-box;background-color:var(--co-bg);border:1px solid var(--co-border);border-left:5px solid var(--co-accent);border-radius:6px;color:var(--co-text);font-family:system-ui,-apple-system,sans-serif;box-shadow:0 1px 2px rgba(0,0,0,0.05)}.highlight-card .icon{flex-shrink:0;display:flex;align-items:center;justify-content:center;width:2rem;height:2rem;font-size:1.5rem;margin-top:0}.highlight-card .content{flex:1;min-width:0}.highlight-card .title{font-size:1.1rem;font-weight:700;color:var(--co-title);margin:0 0 .75rem 0;line-height:1.2;text-transform:uppercase;letter-spacing:.025em}.highlight-card .content ul{margin:0;padding-left:1.25rem}.highlight-card .content li{margin-bottom:.5rem;line-height:1.6;font-size:.95rem}.highlight-card .content li:last-child{margin-bottom:0}.highlight-card .content p{margin:0 0 .5rem 0;line-height:1.6}.highlight-card .content strong{color:var(--co-title);font-weight:600}</style> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Wait, Do We Need to Wait? Revisiting Budget Forcing for Sequential Test-Time Scaling",
            "description": "This blog revisits budget forcing, a sequential test-time scaling technique for reasoning models by controlling when it continues thinking versus when it must answer. We evaluate how well the method transfers across model types, including non-reasoning models, and whether alternative keywords work. We provide practical guidelines for using the technique.",
            "published": "April 27, 2026",
            "authors": [
              
              {
                "author": "Anonymous",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/2026/"> ICLR Blogposts 2026 </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/2026/">home </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/about/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/call/">call for blogposts </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/submitting/">submitting </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/reviewing/">reviewing </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">past iterations </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2026/"><strong>2026</strong></a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2025/">2025</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2024/">2024</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2023/">2023</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blog-track.github.io/home/" rel="external nofollow noopener" target="_blank">2022</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Wait, Do We Need to Wait? Revisiting Budget Forcing for Sequential Test-Time Scaling</h1> <p>This blog revisits budget forcing, a sequential test-time scaling technique for reasoning models by controlling when it continues thinking versus when it must answer. We evaluate how well the method transfers across model types, including non-reasoning models, and whether alternative keywords work. We provide practical guidelines for using the technique.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#what-is-budget-forcing-and-how-does-it-work">What is Budget Forcing And How Does It Work?</a> </div> <ul> <li> <a href="#a-very-brief-introduction-to-test-time-scaling">A Very Brief Introduction to Test-Time Scaling</a> </li> <li> <a href="#budget-forcing-forcing-the-model-to-think-within-the-budget">Budget Forcing: Forcing The Model To Think Within The Budget</a> </li> <li> <a href="#scaling-up">Scaling Up</a> </li> <li> <a href="#scaling-down">Scaling Down</a> </li> </ul> <div> <a href="#what-people-say-about-budget-forcing">What People Say About Budget Forcing?</a> </div> <ul> <li> <a href="#studies-suggesting-benefits-from-budget-forcing">Studies Suggesting Benefits from Budget Forcing</a> </li> <li> <a href="#evidence-challenging-budget-forcing">Evidence Challenging Budget Forcing</a> </li> </ul> <div> <a href="#testing-it-with-more-models">Testing It With More Models</a> </div> <ul> <li> <a href="#not-all-reasoning-models-are-created-the-same-way">Not All Reasoning Models Are Created The Same Way</a> </li> <li> <a href="#comparing-zero-shot-cot-and-budget-forcing-results">Comparing Zero-shot CoT and Budget Forcing Results</a> </li> <li> <a href="#is-linear-scaling-real">Is Linear Scaling Real?</a> </li> <li> <a href="#why-this-might-happen">Why This Might Happen?</a> </li> </ul> <div> <a href="#budget-forcing-works-with-non-reasoning-models-or-not">Budget Forcing Works With Non-Reasoning Models? Or Not?</a> </div> <ul> <li> <a href="#results-with-qwen2-5-7b-instruct">Results with Qwen2.5-7B-Instruct</a> </li> <li> <a href="#how-about-other-model-families">How About Other Model Families?</a> </li> </ul> <div> <a href="#wait-you-do-not-need-to-wait">Wait, You Do Not Need to Wait?</a> </div> <ul> <li> <a href="#keyword-selection">Keyword Selection</a> </li> <li> <a href="#let-us-try-other-keywords-perhaps-we-will-get-interesting-results">Let Us Try Other Keywords: Perhaps We Will Get Interesting Results</a> </li> </ul> <div> <a href="#summary">Summary</a> </div> <div> <a href="#practical-recommendations">Practical Recommendations</a> </div> <div> <a href="#limitations">Limitations</a> </div> </nav> </d-contents> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/hero-480.webp 480w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/hero-800.webp 800w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/hero-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/hero.png" class="img-fluid rounded-lg" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>In this blog post, we revisit the technique ofÂ <strong><em>budget forcing</em></strong>Â â€” a sequential test-time scaling technique that controls reasoning budget in reasoning models by appending a â€œWaitâ€ keyword (or equivalently forcing a stop when the budget is exceeded), thereby determining whether the model continues thinking or directly outputs an answer.</p> <p>We explore three main questions:</p> <ol> <li>To what extent does budget-forcing generalize across different model families and settings?</li> <li>Does it work with non-reasoning models?</li> <li>Can other keywords serve the same function as â€œWaitâ€?</li> </ol> <p>We present experimental results, including cases where budget forcing does and doesÂ <em>not</em>Â help and offer practical guidance for applying budget-forcing in test-time scaling.</p> <div class="highlight-card"> <div class="icon">ğŸ’¡</div> <div class="content"> <div class="title">TL;DR</div> <ul> <li> Budget forcingÂ <strong>helps most</strong>Â for some SFT-based reasoning models (e.g., s1.1, OpenThinker3) but providesÂ <strong>little or negative gains</strong>Â for others (especially some RFT-based or distillation-based models). </li> <li> The often-claimedÂ <strong>"linear scaling law"</strong>Â between budget and performanceÂ <strong>does not hold universally</strong>; many models plateau or fluctuate as the budget grows. </li> <li> Budget forcing isÂ <strong>not exclusive to reasoning models</strong>: instruction-tuned models can benefit when prompted withÂ <code>&lt;think&gt;...&lt;/think&gt;</code>Â structures, but this effect isÂ <strong>highly model-family dependent</strong>. </li> <li> The keyword "Wait" isÂ <strong>not special</strong>. Alternative high-frequency reasoning words likeÂ <strong>"Let"</strong>Â orÂ <strong>"Perhaps"</strong>Â often work better, and the optimal keyword appears to beÂ <strong>model-specific</strong>. </li> </ul> </div> </div> <h2 id="what-is-budget-forcing-and-how-does-it-work">What is Budget Forcing And How Does It Work?</h2> <h3 id="a-very-brief-introduction-to-test-time-scaling">A Very Brief Introduction to Test-Time Scaling</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/tts_types-480.webp 480w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/tts_types-800.webp 800w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/tts_types-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/tts_types.png" class="img-fluid rounded-lg" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> A comparison of sequential, parallel, and hybrid test-time scaling approaches, adapted from <a href="https://arxiv.org/abs/2503.24235" target="_blank" rel="external nofollow noopener">Zhang et al. (2025)</a>. <strong>Sequential</strong> methods extend a single chain of thought, giving one trajectory more room to refine its reasoning. <strong>Parallel</strong> methods sample multiple independent trajectories and select an answer via voting or scoring. <strong>Hybrid</strong> methods both extend chains and branch them, combining deeper single-trajectory reasoning with cross-trajectory selection. </div> <p>Before we go deeper into budget forcing, letâ€™s take a very brief look at what test-time scaling is. Since <strong>budget forcing</strong> is a (1) <em>sequential</em> (2) <em>test-time scaling</em> technique.</p> <p>Letâ€™s unpack that a bit. <a href="https://arxiv.org/abs/2503.24235" rel="external nofollow noopener" target="_blank"><strong><em>Test-time scaling</em></strong></a> <d-cite key="zhang2025surveytesttimescalinglarge"></d-cite> means spending more compute <strong>during inference</strong> â€” for example, generating more tokens â€” to get better performance.</p> <p>Broadly speaking, test-time scaling methods fall into three categories:Â <strong>sequential</strong>,Â <strong>parallel</strong>, andÂ <strong>hybrid</strong>.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/budget_forcing_tts_types-480.webp 480w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/budget_forcing_tts_types-800.webp 800w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/budget_forcing_tts_types-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/budget_forcing_tts_types.png" class="img-fluid rounded-lg" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> A figure contrasting sequential and parallel test-time scaling from <a href="https://arxiv.org/abs/2501.19393" target="_blank" rel="external nofollow noopener">s1: Simple Test-Time Scaling</a> <d-cite key="muennighoff-etal-2025-s1"></d-cite> </div> <ul> <li> <strong>Sequential test-time scaling</strong>, like budget forcing, extends a single generated response so that the model has more â€œroom to thinkâ€ and potentially reach a better answer.</li> <li> <strong>Parallel test-time scaling</strong>Â is based on a different idea. Sampling from a language model is like sampling from a probability distribution. The model might â€œknowâ€ the correct answer, but it might not appear in the first sample. So instead of continuing one generation, weÂ <strong>sample multiple times</strong>, and then pick either the most confident or the highest-quality output (for example, using a majority vote or a grader model).</li> <li> <strong>Hybrid approaches</strong>Â mix both ideas. For instance, we might extend the reasoning sequence (sequential), but at each extension step sample multiple continuations and pick the best one to append.</li> </ul> <h3 id="budget-forcing-forcing-the-model-to-think-within-the-budget">Budget Forcing: Forcing The Model To Think Within The Budget</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/budget_forcing_linear-480.webp 480w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/budget_forcing_linear-800.webp 800w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/budget_forcing_linear-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/budget_forcing_linear.png" class="img-fluid rounded-lg" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Performance of s1 under different budgets from <a href="https://arxiv.org/abs/2501.19393" target="_blank" rel="external nofollow noopener">s1: Simple Test-Time Scaling</a> <d-cite key="muennighoff-etal-2025-s1"></d-cite> </div> <p>Budget forcing was first introduced in <a href="https://arxiv.org/abs/2501.19393" rel="external nofollow noopener" target="_blank">s1: Simple Test-Time Scaling</a> <d-cite key="muennighoff-etal-2025-s1"></d-cite>, which introduced an approach to extend the reasoning process for improving mathematical performance. The original introduction summarizes the idea well:</p> <blockquote> <p>â€œâ€¦ a simple decoding-time intervention by forcing a maximum and/or minimum number of thinking tokens. Specifically, we enforce a maximum token count by simply appending the end-of-thinking token delimiter and optionally â€œFinal Answer:â€ to early exit To enforce a minimum, we suppress the generation of the end-of-thinking token delimiter and optionally append the string â€œWaitâ€ to the modelâ€™s current reasoning trace to encourage the model to reflect on its current generation. the thinking stage and make the model provide its current best answer.â€</p> </blockquote> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/scaling_up_down-480.webp 480w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/scaling_up_down-800.webp 800w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/scaling_up_down-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/scaling_up_down.png" class="img-fluid rounded-lg" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>Letâ€™s unpack that a bit. The objective of budget forcing is to control the number of thinking tokens. It operates through two mechanisms: enforcing (1) a <strong>maximum</strong> and (2) a <strong>minimum</strong> number of thinking tokens. We refer to the first mechanism as <strong>scaling down</strong> (enforced maximum) and the second as <strong>scaling up</strong> (enforced minimum). The high-level process follows:</p> <ul> <li>We treat everything inside aÂ <code class="language-plaintext highlighter-rouge">&lt;think&gt;...&lt;/think&gt;</code>Â block asÂ <strong>reasoning tokens</strong>,</li> <li>We enforce a fixedÂ <strong>token budget</strong>Â on that block,</li> <li>And we either <strong>extend</strong> or <strong>truncate</strong> the block until the budget is used up.</li> </ul> <p>So, letâ€™s see how scaling up and scaling down work!</p> <h3 id="scaling-up">Scaling Up</h3> <div class="l-page"> <iframe src="/2026/assets/html/2026-04-27-wait-do-we-need-to-wait/scaling_up.html" frameborder="0" scrolling="no" height="600px" width="100%"></iframe> </div> <p>When scaling up, budget forcing encourages the model toÂ <em>keep thinking</em>Â as long as it still has reasoning budget left.</p> <p>Hereâ€™s how it works step by step:</p> <ol> <li>The model generates a response consisting of two parts â€” theÂ <strong>thinking process</strong>Â and theÂ <strong>final answer</strong>.</li> <li>The algorithm checks whether the length of the thinking content is still within the budget.</li> <li>If thereâ€™s budget remaining, itÂ <strong>discards the final answer and the thinking-end tag</strong>Â (e.g.,Â <code class="language-plaintext highlighter-rouge">&lt;/think&gt;</code>), then appends a keyword such asÂ <em>â€œWaitâ€</em>Â (as used in the original paper).</li> <li>The model continues generating more reasoning until the budget limit is reached.</li> <li>Steps 2â€“4 repeat until the reasoning budget is exhausted. Only then do we let the model closeÂ <code class="language-plaintext highlighter-rouge">&lt;/think&gt;</code>Â and produce its final answer.</li> </ol> <p>Effectively, we are telling the model,Â <em>Hold on, keep thinking before you answer.</em></p> <h3 id="scaling-down">Scaling Down</h3> <div class="l-page"> <iframe src="/2026/assets/html/2026-04-27-wait-do-we-need-to-wait/scaling_down.html" frameborder="0" scrolling="no" height="600px" width="100%"></iframe> </div> <p>Scaling down is the opposite: instead of letting the model think longer, weÂ <strong>cut off</strong>Â its reasoning once it exceeds the budget.</p> <p>The algorithm:</p> <ol> <li>The model generates a response consisting of two parts â€” theÂ <strong>thinking process</strong>Â and theÂ <strong>final answer</strong>.</li> <li>The algorithm checks whether the length of the thinking content is still within the budget.</li> <li>Truncates the <code class="language-plaintext highlighter-rouge">&lt;think&gt;...&lt;/think&gt;</code> content so that it fits within the reasoning token budget.</li> <li> <strong>Forces an ending indicator</strong> (e.g., <code class="language-plaintext highlighter-rouge">&lt;/think&gt;</code>) after the truncated reasoning.</li> <li>Prompts the model to produce its final answer (for example, â€œ<em>The final answer is â€¦</em>â€).</li> <li>Continues generating the final answer.</li> </ol> <p>In other words,Â <em>â€œTimeâ€™s up â€” give your answer.â€</em></p> <hr> <p>While this is a promising idea and approach, several <em>unknown factors</em> limit our understanding of <strong>what</strong> budget forcing does, <strong>why</strong> it works, and <strong>how</strong> it behaves. In particular:</p> <ol> <li>Budget forcing was introduced and tested using <code class="language-plaintext highlighter-rouge">s1</code>. This raises the question of how <strong>generalizable</strong> it is to other reasoning models.</li> <li>The paper reports a <strong>linear relationship</strong> between performance and thinking budget. Is the trend truly linear?</li> <li>The <strong>keyword â€œWait,â€</strong> used to encourage the model to continue thinking, is chosen somewhat arbitrarily. Does the keyword actually matter?</li> </ol> <h2 id="what-people-say-about-budget-forcing">What People Say About Budget Forcing?</h2> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/lit_survey-480.webp 480w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/lit_survey-800.webp 800w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/lit_survey-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/lit_survey.png" class="img-fluid rounded-lg" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>Before we dig into the deeper questions, itâ€™s worth stepping back to see what the current research landscape says about budget forcing. The findings vary widely, and the overall picture is far from settled. Hereâ€™s a concise tour of the perspectives that have emerged so far.</p> <h3 id="studies-suggesting-benefits-from-budget-forcing">Studies Suggesting Benefits from Budget Forcing</h3> <p>A number of works report that prompting models to â€œwaitâ€ or continue thinking can offer advantages. A study <d-cite key="ringel2025learningcontinuethinkingtokenenhanced"></d-cite> trains models explicitly to use a continued-thinking token, encouraging them to pause and elaborate on their reasoning. Another study <d-cite key="jurayj-etal-2025-final"></d-cite> shows that increasing test-time computeâ€”often by allowing longer chains of thoughtâ€”can boost accuracy and confidence, at least in some settings.</p> <p>A related perspective emphasizes the role of backtracking <d-cite key="gandhi2025cognitive"></d-cite>. In both humans and models, the signal to â€œwaitâ€ can function as an invitation to revisit earlier steps, reconsider calculations, or catch overlooked details. Under this view, brief delays may improve the final answer by prompting revision.</p> <h3 id="evidence-challenging-budget-forcing">Evidence Challenging Budget Forcing</h3> <p>Several recent findings call into question the idea that longer chains of thought inherently improve performance. One study indicates that extended reasoning and excessive reviewing correlate withÂ <em>lower</em>Â accuracy across tasks such as mathematics and scientific reasoning <d-cite key="feng2025characterizeseffectivereasoningrevisiting"></d-cite>.</p> <p>Further, research on test-time scaling shows that when models are forced to answer with less time than they naturally require, accuracy degrades <d-cite key="wu2025itssimpleanalysissimple"></d-cite>â€”and that shorter chain-of-thought models are especially sensitive to this truncation. Other work <d-cite key="zhao2025testtimescalingreasoningmodels"></d-cite> observes fluctuating or decreased accuracy when budget forcing is applied in knowledge-intensive domains, and finds little to no benefit in fields like medicine <d-cite key="huang2025m"></d-cite>.</p> <p>One hypothesis ties these patterns together: models may simply be more familiar with certain reasoning lengths because those lengths are more commonly represented in training data. Extremely long chains of thought appear less frequently, making the model less practiced in producing them. As a result, artificially lengthening the reasoning process does not always yield deeper or more reliable thinking. This idea will be explored further later in the post.</p> <h3 id="what-we-will-do-in-this-blog">What We Will Do In This Blog?</h3> <p>Given the contradictory results in prior work, we revisit budget forcing and evaluate it in a more systematic setup to understand <em>how well the technique generalizes</em> and <em>how its individual components affect outcomes</em>. This is not an exhaustive study; instead, we focus on several particularly interesting aspects: <strong>model compatibility</strong>, <strong>budget scaling behavior</strong>, and <strong>keyword choice</strong>. Letâ€™s dive in.</p> <div class="highlight-card"> <div class="icon">ğŸ“</div> <div class="content"> <div class="title">Summary</div> <ul> <li>Budget forcing is a <strong>sequential test-time scaling</strong> method that manipulates tokens inside <code>&lt;think&gt;...&lt;/think&gt;</code> under a fixed budget.</li> <li>It has two components: <strong>scaling up</strong> (extend reasoning) and <strong>scaling down</strong> (truncate reasoning), both controlled by the same budget mechanism.</li> <li>Prior work shows <strong>clear but non-universal gains</strong>: some models and settings benefit, others do not.</li> </ul> </div> </div> <h2 id="testing-it-with-more-models">Testing It With More Models</h2> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/models-480.webp 480w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/models-800.webp 800w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/models-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/models.png" class="img-fluid rounded-lg" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="not-all-reasoning-models-are-created-the-same-way">Not All Reasoning Models Are Created The Same Way</h3> <p>Not all reasoning models are created equal â€” or trained the same way. Broadly speaking, there are <strong>two main approaches</strong> to developing reasoning models: <strong>Supervised Fine-Tuning (SFT)</strong> and <strong>Reinforcement Fine-Tuning (RFT)</strong>.</p> <ul> <li>SFT aims to teach a model a particularÂ <strong>style of reasoning</strong>Â by directly imitating curated chains of thought.</li> <li>RFT lets the modelÂ <strong>explore</strong>Â its own reasoning trajectories and then uses rewards to shapeÂ <em>which behaviors</em>Â are preferred, without necessarily providing explicit step-by-step demonstrations.</li> </ul> <blockquote> <p>Do reasoning models trained with SFT and RFT behave differently when we apply budget forcing?</p> </blockquote> <h4 id="experimental-setup">Experimental Setup</h4> <p>To explore this, we selected several models that all share theÂ <strong>same initial model</strong>Â â€” <code class="language-plaintext highlighter-rouge">Qwen2.5-7B-Instruct</code> â€” to make comparisons as fair and controlled as possible.</p> <p>Specifically, we used:</p> <ul> <li> <a href="https://huggingface.co/simplescaling/s1.1-7B" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">simplescaling/s1.1-7B</code></a> (SFT-based, an updated version from the s1 paper)</li> <li> <a href="https://huggingface.co/open-thoughts/OpenThinker-7B" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">open-thoughts/OpenThinker3-7B</code></a> (SFT-based, for comparison with s1.1)</li> <li> <a href="https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">deepseek-ai/DeepSeek-R1-Distill-Qwen-7B</code></a> (SFT-based, for comparison with s1.1 and OpenThinker3)</li> <li> <code class="language-plaintext highlighter-rouge">RFT</code> â€” our own reasoning model fine-tuned from <code class="language-plaintext highlighter-rouge">Qwen2.5-7B-Instruct</code> using pure reinforcement fine-tuning, <strong>without</strong> additional SFT reasoning data.</li> </ul> <details><summary>More technical details on how we trained the <code class="language-plaintext highlighter-rouge">RFT</code> model</summary> <ul> <li> <strong>Model</strong>: <a href="https://huggingface.co/Qwen/Qwen2.5-7B-Instruct" target="_blank" rel="external nofollow noopener">Qwen2.5-7B-Instruct</a> </li> <li> <strong>Algorithm</strong>: GRPO</li> <li> <strong>Trainer</strong>: <a href="https://github.com/volcengine/verl" target="_blank" rel="external nofollow noopener">verl</a> </li> <li> <strong>Training Set</strong>: <a href="https://huggingface.co/datasets/mnoukhov/DAPO-Math-14k-Processed-RLVR" target="_blank" rel="external nofollow noopener">DAPO Math 14K</a> </li> </ul> <details><summary>Training config (click to expand)</summary> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python3 <span class="nt">-m</span> verl.trainer.main_ppo <span class="se">\</span>
 algorithm.adv_estimator<span class="o">=</span>grpo <span class="se">\</span>
 data.train_files<span class="o">=</span>RUC-AIBOX/STILL-3-Preview-RL-Data <span class="se">\</span>
 data.val_files<span class="o">=</span>RUC-AIBOX/STILL-3-Preview-RL-Data <span class="se">\</span>
 data.train_batch_size<span class="o">=</span>256 <span class="se">\</span>
 data.max_prompt_length<span class="o">=</span>2048 <span class="se">\</span>
 data.max_response_length<span class="o">=</span>4096 <span class="se">\</span>
 actor_rollout_ref.model.path<span class="o">=</span>Qwen/Qwen2.5-7B-Instruct <span class="se">\</span>
 actor_rollout_ref.actor.optim.lr<span class="o">=</span>1e-6 <span class="se">\</span>
 actor_rollout_ref.model.use_remove_padding<span class="o">=</span>True <span class="se">\</span>
 actor_rollout_ref.model.enable_gradient_checkpointing<span class="o">=</span>True <span class="se">\</span>
 +actor_rollout_ref.model.use_torch_compile<span class="o">=</span>True <span class="se">\</span>
 actor_rollout_ref.actor.ppo_mini_batch_size<span class="o">=</span>64 <span class="se">\</span>
 actor_rollout_ref.actor.fsdp_config.param_offload<span class="o">=</span>False <span class="se">\</span>
 actor_rollout_ref.actor.fsdp_config.optimizer_offload<span class="o">=</span>False <span class="se">\</span>
 actor_rollout_ref.ref.fsdp_config.param_offload<span class="o">=</span>False <span class="se">\</span>
 actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu<span class="o">=</span>8 <span class="se">\</span>
 actor_rollout_ref.rollout.tensor_model_parallel_size<span class="o">=</span>1 <span class="se">\</span>
 actor_rollout_ref.rollout.name<span class="o">=</span>vllm <span class="se">\</span>
 actor_rollout_ref.rollout.gpu_memory_utilization<span class="o">=</span>0.8 <span class="se">\</span>
 actor_rollout_ref.rollout.n<span class="o">=</span>8 <span class="se">\</span>
 actor_rollout_ref.actor.strategy<span class="o">=</span>fsdp2 <span class="se">\</span>
 actor_rollout_ref.ref.strategy<span class="o">=</span>fsdp2 <span class="se">\</span>
 critic.strategy<span class="o">=</span>fsdp2 <span class="se">\</span>
 actor_rollout_ref.actor.use_dynamic_bsz<span class="o">=</span>True <span class="se">\</span>
 actor_rollout_ref.actor.ppo_max_token_len_per_gpu<span class="o">=</span>24576 <span class="se">\</span>
 actor_rollout_ref.ref.log_prob_max_token_len_per_gpu<span class="o">=</span>24576 <span class="se">\</span>
 actor_rollout_ref.rollout.log_prob_max_token_len_per_gpu<span class="o">=</span>24576 <span class="se">\</span>
 algorithm.use_kl_in_reward<span class="o">=</span>False <span class="se">\</span>
 reward_model.reward_manager<span class="o">=</span>naive <span class="se">\</span>
 custom_reward_function.path<span class="o">=</span>compute_score <span class="se">\</span>
 custom_reward_function.name<span class="o">=</span>math_acc_rw_fn.py <span class="se">\</span>
 trainer.critic_warmup<span class="o">=</span>0 <span class="se">\</span>
 trainer.logger<span class="o">=[</span><span class="s1">'console'</span>,<span class="s1">'wandb'</span><span class="o">]</span> <span class="se">\</span>
 trainer.project_name<span class="o">=</span>your_project_name <span class="se">\</span>
 trainer.experiment_name<span class="o">=</span>your_exp_name <span class="se">\</span>
 trainer.val_before_train<span class="o">=</span>False <span class="se">\</span>
 trainer.default_hdfs_dir<span class="o">=</span>null <span class="se">\</span>
 trainer.n_gpus_per_node<span class="o">=</span>4 <span class="se">\</span>
 trainer.nnodes<span class="o">=</span>1 <span class="se">\</span>
 trainer.save_freq<span class="o">=</span>100 <span class="se">\</span>
 trainer.test_freq<span class="o">=</span>1000000 <span class="se">\</span>
 trainer.total_epochs<span class="o">=</span>2 2&gt;&amp;1
</code></pre></div></div> </details> <details><summary>Reward function (click to expand)</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">re</span>
<span class="kn">from</span> <span class="n">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">math_verify</span> <span class="kn">import</span> <span class="n">parse</span><span class="p">,</span> <span class="n">verify</span>


<span class="k">def</span> <span class="nf">extract_boxed_content</span><span class="p">(</span><span class="n">text</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]:</span>
    <span class="k">if</span> <span class="n">text</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">None</span>

    <span class="n">pattern</span> <span class="o">=</span> <span class="sa">r</span><span class="sh">"</span><span class="s">\\boxed\{((?:[^{}]|\{[^{}]*\})*)\}</span><span class="sh">"</span>
    <span class="k">return</span> <span class="n">re</span><span class="p">.</span><span class="nf">findall</span><span class="p">(</span><span class="n">pattern</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">math_boxed_reward_func</span><span class="p">(</span>
    <span class="n">assistant_message</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">float</span> <span class="o">|</span> <span class="nb">int</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">Reward function for math problems with boxed answers.</span><span class="sh">"""</span>
    <span class="n">extracted_answers</span> <span class="o">=</span> <span class="nf">extract_boxed_content</span><span class="p">(</span><span class="n">assistant_message</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">extracted_answers</span> <span class="ow">or</span> <span class="nf">len</span><span class="p">(</span><span class="n">extracted_answers</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.0</span>

    <span class="n">parsed_extracted_answer</span> <span class="o">=</span> <span class="nf">parse</span><span class="p">(</span><span class="n">extracted_answers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">parsed_ground_truth</span> <span class="o">=</span> <span class="nf">parse</span><span class="p">(</span><span class="n">ground_truth</span><span class="p">)</span>

    <span class="k">if</span> <span class="nf">verify</span><span class="p">(</span><span class="n">parsed_ground_truth</span><span class="p">,</span> <span class="n">parsed_extracted_answer</span><span class="p">):</span>
        <span class="k">return</span> <span class="mf">1.0</span>

    <span class="k">return</span> <span class="mf">0.0</span>


<span class="k">def</span> <span class="nf">format_reward_func</span><span class="p">(</span><span class="n">assistant_message</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">Scores the assistant message based on formatting (&lt;think&gt; tags).</span><span class="sh">"""</span>
    <span class="k">if</span> <span class="n">assistant_message</span> <span class="ow">is</span> <span class="bp">None</span> <span class="ow">or</span> <span class="nf">len</span><span class="p">(</span><span class="n">assistant_message</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.0</span>

    <span class="n">think_pattern</span> <span class="o">=</span> <span class="sa">r</span><span class="sh">"</span><span class="s">&lt;think&gt;.*?&lt;/think&gt;</span><span class="sh">"</span>
    <span class="n">matches</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">findall</span><span class="p">(</span><span class="n">think_pattern</span><span class="p">,</span> <span class="n">assistant_message</span><span class="p">,</span> <span class="n">re</span><span class="p">.</span><span class="n">DOTALL</span><span class="p">)</span>

    <span class="nf">if </span><span class="p">(</span>
        <span class="nf">len</span><span class="p">(</span><span class="n">matches</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="ow">and</span> <span class="n">assistant_message</span><span class="p">.</span><span class="nf">strip</span><span class="p">().</span><span class="nf">startswith</span><span class="p">(</span><span class="sh">"</span><span class="s">&lt;think&gt;</span><span class="sh">"</span><span class="p">)</span>
        <span class="ow">and</span> <span class="n">assistant_message</span><span class="p">.</span><span class="nf">count</span><span class="p">(</span><span class="sh">"</span><span class="s">&lt;think&gt;</span><span class="sh">"</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="ow">and</span> <span class="n">assistant_message</span><span class="p">.</span><span class="nf">count</span><span class="p">(</span><span class="sh">"</span><span class="s">&lt;/think&gt;</span><span class="sh">"</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="p">):</span>
        <span class="k">return</span> <span class="mf">1.0</span>
    <span class="k">return</span> <span class="mf">0.0</span>


<span class="k">def</span> <span class="nf">compute_score</span><span class="p">(</span>
    <span class="n">data_source</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">solution_str</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">ground_truth</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">extra_info</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    A unified reward function for `verl` that handles </span><span class="sh">'</span><span class="s">math</span><span class="sh">'</span><span class="s"> types.

    Args:
        data_source (str): The name of the dataset (provided by verl).
        solution_str (str): The response generated by the model.
        ground_truth (str): The ground truth answer.
        extra_info (dict, optional): A dictionary for additional data. Defaults to None.

    Returns:
        float: The calculated reward score.
    </span><span class="sh">"""</span>

    <span class="n">format_score</span> <span class="o">=</span> <span class="nf">format_reward_func</span><span class="p">(</span><span class="n">solution_str</span><span class="p">)</span>
    <span class="n">accuracy_score</span> <span class="o">=</span> <span class="nf">math_boxed_reward_func</span><span class="p">(</span><span class="n">solution_str</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">)</span>

    <span class="n">combined_score</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">([</span><span class="n">accuracy_score</span><span class="p">,</span> <span class="n">format_score</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">combined_score</span>
</code></pre></div></div> </details> </details> <p>We evaluated all four models on a diverse set of reasoning benchmarks:</p> <ul> <li> <a href="https://huggingface.co/datasets/math-ai/aime25" rel="external nofollow noopener" target="_blank"><strong>AIME 2025</strong></a>Â â€“ competition math problems</li> <li> <a href="https://huggingface.co/datasets/math-ai/math500" rel="external nofollow noopener" target="_blank"><strong>MATH 500</strong></a>Â â€“ medium-difficult mathematical reasoning problems</li> <li> <a href="https://huggingface.co/datasets/TIGER-Lab/MMLU-Pro" rel="external nofollow noopener" target="_blank"><strong>MMLU Pro-1K</strong></a>Â â€“ broad multi-domain knowledge tasks</li> <li> <a href="https://huggingface.co/datasets/m-a-p/SuperGPQA" rel="external nofollow noopener" target="_blank"><strong>SuperGPQA-1K</strong></a>Â â€“ general-purpose question answering tasks</li> </ul> <p>Together, these benchmarks give us aÂ <strong>holistic view</strong>Â of how budget forcing affects models across both mathematical (as proposed originally in the s1 paper) and non-mathematical domains.</p> <p>We used the following sampling parameters for all evaluations: <code class="language-plaintext highlighter-rouge">temperature = 0.6</code>, <code class="language-plaintext highlighter-rouge">max_tokens = 8192</code>, <code class="language-plaintext highlighter-rouge">top_p = 0.95</code>, <code class="language-plaintext highlighter-rouge">top_k = 20</code>, and <code class="language-plaintext highlighter-rouge">presence_penalty = 0.5</code>. We also fixed theÂ <strong>thinking budget</strong>Â toÂ <code class="language-plaintext highlighter-rouge">8192</code>Â tokens â€” a value thatâ€™s comfortably above the average reasoning length for most models.</p> <p>Hereâ€™s what we found:</p> <h3 id="comparing-zero-shot-cot-and-budget-forcing-results">Comparing Zero-shot CoT and Budget Forcing Results</h3> <details><summary>Result table</summary> <div class="l-page"> <table class="table table-sm"> <thead> <tr> <th>Model</th> <th>Approach</th> <th>AIME 2025</th> <th>MATH500</th> <th>MMLU Pro-1K</th> <th>SuperGPQA-1K</th> <th>Average</th> </tr> </thead> <tbody> <tr> <td>RFT</td> <td>Zero-shot</td> <td>20.00</td> <td>69.40</td> <td>9.80</td> <td>6.70</td> <td>26.48</td> </tr> <tr> <td>RFT</td> <td>CoT+BF</td> <td>23.33</td> <td>63.80</td> <td>45.20</td> <td>27.80</td> <td>40.03</td> </tr> <tr> <td>s1.1-7B</td> <td>Zero-shot</td> <td>20.00</td> <td>73.60</td> <td>40.20</td> <td>17.40</td> <td>37.80</td> </tr> <tr> <td>s1.1-7B</td> <td>CoT+BF</td> <td>23.33</td> <td>74.20</td> <td><strong>62.10</strong></td> <td>33.40</td> <td>48.26</td> </tr> <tr> <td>OpenThinker3-7B</td> <td>Zero-shot</td> <td>26.67</td> <td>81.00</td> <td>51.40</td> <td>24.60</td> <td>45.92</td> </tr> <tr> <td>OpenThinker3-7B</td> <td>CoT+BF</td> <td><strong>53.33</strong></td> <td><strong>87.00</strong></td> <td>61.10</td> <td><strong>36.60</strong></td> <td><strong>59.51</strong></td> </tr> <tr> <td>DeepSeek-R1-Distill-Qwen-7B</td> <td>Zero-shot</td> <td>33.33</td> <td>81.00</td> <td>12.00</td> <td>5.20</td> <td>32.88</td> </tr> <tr> <td>DeepSeek-R1-Distill-Qwen-7B</td> <td>CoT+BF</td> <td>26.67</td> <td>83.40</td> <td>10.80</td> <td>6.70</td> <td>31.89</td> </tr> </tbody> </table> </div> </details> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/performance_reasoning_models-480.webp 480w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/performance_reasoning_models-800.webp 800w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/performance_reasoning_models-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/performance_reasoning_models.png" class="img-fluid rounded-lg" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/performance_on_reasoning_models-480.webp 480w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/performance_on_reasoning_models-800.webp 800w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/performance_on_reasoning_models-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/performance_on_reasoning_models.png" class="img-fluid rounded-lg" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>Budget forcing (CoT+BF) generally enhances performance, especially in <strong>SFT-based models</strong> like <em>s1.1-7B</em> and <em>OpenThinker3-7B</em>, which benefit from having more reasoning steps to express their learned procedural thought patterns. These models appear to use the extra budget productively, expanding on intermediate reasoning and improving performance across complex benchmarks. This is possibly due to the fact that long CoT responses exist in their training sets <a href="https://huggingface.co/datasets/simplescaling/s1K-1.1" target="_blank" rel="external nofollow noopener">s1K-1.1</a> and <a href="https://huggingface.co/datasets/open-thoughts/OpenThoughts3-1.2M" target="_blank" rel="external nofollow noopener">OpenThoughts3-1.2M</a>, respectively.</p> <p>In contrast, <em>DeepSeek-R1-Distill-Qwen-7B</em> shows minimal or negative gains. The small declines on <em>AIME 2025</em> and <em>MMLU Pro-1K</em> suggest that overthinking can degrade accuracy when models already operate near optimal reasoning efficiency. Given that we do not have access to the training set of this model, we are unable to state this with certainty, but itâ€™s likely that only the shorter end of CoT chains is used to train the model. These findings suggest that reasoning improvement under budget forcing depends more on <strong>training configurations</strong>.</p> <h3 id="is-linear-scaling-real">Is Linear Scaling Real?</h3> <details><summary>Result table</summary> <div class="l-page"> <table class="table table-sm"> <thead> <tr> <th>Model</th> <th>Budget</th> <th>AIME 2025</th> <th>MATH500</th> <th>MMLU Pro-1K</th> <th>SuperGPQA-1K</th> <th>Average</th> </tr> </thead> <tbody> <tr> <td>RFT</td> <td>256</td> <td>16.67</td> <td>41.20</td> <td>36.90</td> <td>24.30</td> <td>29.77</td> </tr> <tr> <td>RFT</td> <td>512</td> <td>16.67</td> <td>56.40</td> <td>40.70</td> <td>27.80</td> <td>35.39</td> </tr> <tr> <td>RFT</td> <td>1024</td> <td>26.67</td> <td>63.20</td> <td>44.90</td> <td>27.80</td> <td>40.64</td> </tr> <tr> <td>RFT</td> <td>2048</td> <td>20.00</td> <td>64.60</td> <td>46.30</td> <td>26.80</td> <td>39.42</td> </tr> <tr> <td>RFT</td> <td>4096</td> <td>16.67</td> <td>65.20</td> <td>45.90</td> <td>27.40</td> <td>38.79</td> </tr> <tr> <td>RFT</td> <td>8192</td> <td>23.33</td> <td>63.80</td> <td>45.20</td> <td>27.80</td> <td>40.03</td> </tr> <tr> <td>s1.1-7B</td> <td>256</td> <td>16.67</td> <td>63.00</td> <td>53.10</td> <td>28.80</td> <td>40.39</td> </tr> <tr> <td>s1.1-7B</td> <td>512</td> <td>30.00</td> <td>66.80</td> <td>54.20</td> <td>26.80</td> <td>44.45</td> </tr> <tr> <td>s1.1-7B</td> <td>1024</td> <td>20.00</td> <td>69.80</td> <td>57.50</td> <td>30.20</td> <td>44.38</td> </tr> <tr> <td>s1.1-7B</td> <td>2048</td> <td>13.33</td> <td>70.60</td> <td>60.00</td> <td>30.60</td> <td>43.63</td> </tr> <tr> <td>s1.1-7B</td> <td>4096</td> <td>26.67</td> <td>74.80</td> <td>59.80</td> <td>30.70</td> <td>47.99</td> </tr> <tr> <td>s1.1-7B</td> <td>8192</td> <td>23.33</td> <td>74.20</td> <td><strong>62.10</strong></td> <td>33.40</td> <td>48.26</td> </tr> <tr> <td>OpenThinker3-7B</td> <td>256</td> <td>40.00</td> <td>76.60</td> <td>53.80</td> <td>26.50</td> <td>49.22</td> </tr> <tr> <td>OpenThinker3-7B</td> <td>512</td> <td>33.33</td> <td>77.60</td> <td>56.30</td> <td>29.00</td> <td>49.06</td> </tr> <tr> <td>OpenThinker3-7B</td> <td>1024</td> <td>30.00</td> <td>80.20</td> <td>56.20</td> <td>29.90</td> <td>49.08</td> </tr> <tr> <td>OpenThinker3-7B</td> <td>2048</td> <td>33.33</td> <td>81.80</td> <td>57.90</td> <td>32.40</td> <td>51.36</td> </tr> <tr> <td>OpenThinker3-7B</td> <td>4096</td> <td><strong>60.00</strong></td> <td>83.20</td> <td>61.90</td> <td>31.30</td> <td>59.10</td> </tr> <tr> <td>OpenThinker3-7B</td> <td>8192</td> <td>53.33</td> <td><strong>87.00</strong></td> <td>61.10</td> <td><strong>36.60</strong></td> <td><strong>59.51</strong></td> </tr> <tr> <td>DeepSeek-R1-Distill-Qwen-7B</td> <td>256</td> <td>26.67</td> <td>84.20</td> <td>9.60</td> <td>5.40</td> <td>31.47</td> </tr> <tr> <td>DeepSeek-R1-Distill-Qwen-7B</td> <td>512</td> <td>26.67</td> <td>84.00</td> <td>10.00</td> <td>5.60</td> <td>31.57</td> </tr> <tr> <td>DeepSeek-R1-Distill-Qwen-7B</td> <td>1024</td> <td>16.67</td> <td>81.80</td> <td>10.30</td> <td>5.90</td> <td>28.67</td> </tr> <tr> <td>DeepSeek-R1-Distill-Qwen-7B</td> <td>2048</td> <td>20.00</td> <td>83.20</td> <td>10.80</td> <td>6.40</td> <td>30.10</td> </tr> <tr> <td>DeepSeek-R1-Distill-Qwen-7B</td> <td>4096</td> <td>20.00</td> <td>83.20</td> <td>11.90</td> <td>7.10</td> <td>30.55</td> </tr> <tr> <td>DeepSeek-R1-Distill-Qwen-7B</td> <td>8192</td> <td>26.67</td> <td>83.40</td> <td>10.80</td> <td>6.70</td> <td>31.89</td> </tr> </tbody> </table> </div> </details> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/performance_benchmarks_on_reasoning_models-480.webp 480w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/performance_benchmarks_on_reasoning_models-800.webp 800w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/performance_benchmarks_on_reasoning_models-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/performance_benchmarks_on_reasoning_models.png" class="img-fluid rounded-lg" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>Now that we knowÂ <strong>budget forcing</strong>Â is effective for most included reasoning models, the next question is whether theÂ <strong>linear trend</strong> in performance improvements holds universally.</p> <p>In this experiment, we vary theÂ <strong>thinking token budget</strong>Â fromÂ <strong>256</strong>Â toÂ <strong>8192</strong>Â tokens.</p> <p>As expected, all models perform better at a higher budget (8192) compared to the lowest budget (256). However, the trend isÂ <strong>not linear</strong>.</p> <ul> <li>Only the <strong>RFT model</strong> exhibits a roughly linear improvement from 256 to 1024 tokens, after which its performance becomes inconsistent.</li> <li> <strong>s1.1</strong> and <strong>OpenThinker3</strong> both show an early <strong>performance plateau</strong>, with gains concentrated in a mid-range of budgets.</li> <li> <strong>DeepSeek-R1-Distill-Qwen-7B</strong> fluctuates slightly with little overall difference across the scaling curve.</li> </ul> <p>Interestingly,Â <strong>s1.1</strong>Â andÂ <strong>OpenThinker3</strong>Â share notably similar scaling behavior, likely reflecting shared design choices and data sources.</p> <p>Overall, these results suggest that theÂ <strong>claimed linear relationship</strong>Â between performance and increased thinking budgetÂ <strong>does not hold universally</strong>â€”aligning with observations from prior literature that question the effectiveness of budget forcing across different models and configurations.</p> <h3 id="why-this-might-happen">Why This Might Happen?</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/budget_forcing_failure_modes-480.webp 480w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/budget_forcing_failure_modes-800.webp 800w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/budget_forcing_failure_modes-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/budget_forcing_failure_modes.png" class="img-fluid rounded-lg" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>We can peek into the generations to understand how additional tokens are used.</p> <details><summary>Examples of Repetitive Chunks</summary> <p><strong>Qwen2.5-7B-Instruct; budget = 256 tokens</strong></p> <details><summary>MATH500 (Correct answer: 15x - 80)</summary> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;think&gt;</span>
user
To simplify the expression \(19x + 1 - 4x - 81\), we need to combine like terms. Here are the steps:

1. Identify and group the like terms. The like terms involving \(x\) are \(19x\) and \(-4x\). The constant terms are \(1\) and \(-81\).

2. Combine the \(x\) terms:
\[
19x - 4x = 15x
\]

3. Combine the constant terms:
\[
1 - 81 = -80
\]

4. Write the simplified expression by combining the results from steps 2 and 3:
\[
15x - 80
\]

Therefore, the simplified expression is \(\boxed{15x - 80}\).
Wait, let me double-check the arithmetic for the constant terms. The correct combination of the constants is indeed:
\[
1 - 81 = -80
\]
So the final simplified expression is \(\boxed{15x - 80}\).
Wait, I realize the constant term calculation was correct
<span class="nt">&lt;/think&gt;</span>

So, the final answer is \boxed{15x - 80}.
</code></pre></div></div> </details> <details><summary>MMLU Pro (Correct answer: D)</summary> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;think&gt;</span>
Assistant J) The excavators were inexperienced in identifying historical structures. 

\boxed{J}
Wait, let's ensure this is the most accurate answer. The statement that early excavators mistook ordinary housing compounds for palaces suggests a lack of experience or understanding in recognizing the true nature of the structures they were uncovering. This directly points to the excavators' inexperience.

Therefore, the final answer is \boxed{J}.
Wait, the conclusion should be more accurately stated as:

\boxed{J}
Wait, the correct reasoning is:

The fact that early excavators of TeotihuacÃ¡n mistook ordinary housing compounds for palaces suggests that the excavators were inexperienced in identifying historical structures. Thus, the final answer is \boxed{J}.
Wait, let's reconfirm the final boxed answer:

\boxed{J}
Wait, the final boxed answer is:

\boxed{J}
Wait, the final and correct boxed answer is:

\boxed{J}
Wait, the final and correct boxed answer is:

\boxed{J}
Wait, the final and correct boxed answer is:

\boxed{J}
Wait, the final and correct boxed answer is:

\boxed{J}
Wait, the final and correct boxed answer is:

<span class="nt">&lt;/think&gt;</span>

So, the final answer is \boxed{J}.
</code></pre></div></div> </details> <details><summary>SuperGPQA (Correct answer: G)</summary> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;think&gt;</span>
   most of the carbon in our bodies originated from a supernova. The answer is H. \boxed{H}
Wait, let me recheck the context. Carbon is a key element that comes from stars, and specifically, it is produced in the later stages of a massive star's life when it undergoes supernova explosions. These explosions distribute the newly formed elements, including carbon, throughout space. Therefore, the correct answer is indeed H.

\boxed{H}
Wait, I should ensure the accuracy. The process of carbon formation is well-documented in astrophysics. Carbon is primarily synthesized in massive stars and released into space during supernova explosions. Therefore, the correct answer is H.

\boxed{H}
Wait, I am certain now. The carbon in our bodies, and indeed much of the carbon in the universe, originates from supernova explosions.

\boxed{H}
Wait, I will finalize this. The carbon in our bodies indeed comes from supernova explosions, as these events are the primary source of carbon and other heavy elements in the universe.

\boxed{H}
Wait, I am finalizing this. The carbon in our bodies is produced in the core of massive stars and released into space during supernova explosions, making H the correct ans
<span class="nt">&lt;/think&gt;</span>

So, the final answer is \boxed{H}.
</code></pre></div></div> </details> <p>Here, the first few â€œWaitâ€ tokens trigger genuine re-checking. After that, the model falls into repetitive templates: â€œWait, I should ensureâ€¦ Wait, I am certainâ€¦â€ without adding new information.</p> </details> <details><summary>Example of Alternating Answers</summary> <p><strong>Qwen2.5-7B-Instruct; budget = 8192 tokens</strong></p> <details><summary>MMLU Pro</summary> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;think&gt;</span>
Assistant A)constitutional, because it protects a legitimate state interest.
Wait, let's evaluate the options more carefully. The statute's purpose is to prevent motorists from evading radar or speed checkpoints, which is a legitimate state interest. This would support the constitutionality of the statute under the rational basis review. However, we should also consider other potential challenges.

B) Unconstitutional, because it unduly burdens interstate commerce.
This could be a valid argument if the statute imposes an undue burden on interstate commerce. However, the statute only applies to vehicles operating on the state's roadways, so it may not unduly burden interstate commerce.

C) Unconstitutional, because the state statute fails to give credit to the law of a neighboring state.
This is not a valid argument. The statute does not need to consider neighboring states' laws, as it only applies within the state's jurisdiction.

D) Constitutional, because the commerce clause does not invalidate a state regulation relating to interstate commerce unless Congress takes express action to do so.
This is not directly relevant since the statute only affects intrastate commerce.

E) Constitutional, because states have the power to regulate their own roads and highways.
This is a strong argument. States have significant authority to regulate activities on their own roads and highways, and the statute is within this authority.

F) Constitutional, because it protects a legitimate state interest.
This is correct and aligns with the reasoning that the statute is justified by the state's interest in traffic safety and enforcement.

G) Unconstitutional, because it infringes on the rights of residents of other states.
This is not a valid argument. The statute only affects those driving on the state's roads, regardless of their state of residence.

H) Unconstitutional, because the state statute is preempted by federal law.
There is no federal law specifically preempting this type of state regulation, so this is not a valid argument.

I) Unconstitutional, because it violates the Fourth Amendment's prohibition against unreasonable searches and seizures.
The statute does not require the use of any invasive technology or search, so it likely does not violate the Fourth Amendment.

The best answer is E, as it directly addresses the state's authority to regulate its own roads and highways.

Therefore, the final answer is \boxed{E}.
Wait, let's re-evaluate for clarity and ensure the best fit. Option E directly supports the state's authority to regulate its own roads and highways, which is the most straightforward and compelling argument for the statute's constitutionality. The other options either do not apply or are less directly relevant.

Therefore, the final answer is \boxed{E}.
Wait, the best and most comprehensive answer is actually F. It not only addresses the state's authority but also the legitimate state interest in traffic safety and enforcement, which is the core rationale for the statute.

Therefore, the final answer is \boxed{F}.
Wait, the best answer is actually A. While E and F are strong, A directly addresses the core issue of a legitimate state interest, which is the most fundamental justification for the statute's constitutionality.

Therefore, the final answer is \boxed{A}.
Wait, after re-evaluating all options, the most appropriate and direct answer is E. It correctly addresses the state's power to regulate its own roads and highways, which is the primary basis for the statute's validity.

Therefore, the final answer is \boxed{E}.
Wait, the most comprehensive and correct answer is actually F. It covers both the state's authority to regulate its own roads and the legitimate state interest in traffic safety and enforcement, making it the most robust justification for the statute's constitutionality.

Therefore, the final answer is \boxed{F}.
Wait, the best and most comprehensive answer is actually A. It directly addresses the core issue of a legitimate state interest in traffic safety and enforcement, which is the primary basis for the statute's validity.

Therefore, the final answer is \boxed{A}.
Wait, the best and most comprehensive answer is actually F. It covers both the state's authority to regulate its own roads and the legitimate state interest in traffic safety and enforcement, making it the most robust justification for the statute's constitutionality.

Therefore, the final answer is \boxed{F}.
Wait, the best and most comprehensive answer is actually E. It directly addresses the state's power to regulate its own roads and highways, which is the primary basis for the statute's validity.

Therefore, the final answer is \boxed{E}.
Wait, the best and most comprehensive answer is actually A. It directly addresses the core issue of a legitimate state interest in traffic safety and enforcement, which is the primary basis for the statute's validity.

Therefore, the final answer is \boxed{A}.
Wait
<span class="nt">&lt;/think&gt;</span>

So, the final answer is \boxed{A}.
</code></pre></div></div> </details> <p>The answer flips back and forth among A, E, and F multiple times. Here, â€œWaitâ€ <em>does</em> influence the trajectory, but in an unstable way: the model keeps revising even after landing on a correct reasoning path.</p> </details> <p>At a high level, our quantitative results suggest that models can only use additional tokens productively up to the reasoning lengths represented in their training data. Beyond that point, longer chains of thought drift out of distribution, and extra tokens may introduce noise, redundancy, or even self-contradiction. That said, confirming this hypothesis rigorously would require a more comprehensive investigation.</p> <p>For instance, in the repetitive-response example, the model initially uses the first few appended â€œWaitâ€ tokens to reconsider and verify its reasoning. After several iterations, however, â€œWaitâ€ becomes ineffectiveâ€”the model simply repeats the same reasoning block. This may indicate that the model is confident in its answer, or that the extended reasoning length has moved far beyond its training distribution.</p> <p>Conversely, we also observe cases where the model continually changes its answer after each â€œWait,â€ demonstrating that the keyword can indeed influence its reasoning (as seen in the alternating-answers example). Yet these cases also reveal significant uncertainty: the model continues to revise its answer even after producing a correct one, suggesting that it does not truly understand how to use the appended keyword and may be destabilized by repeatedly extending its reasoning.</p> <div class="highlight-card"> <div class="icon">ğŸ“</div> <div class="content"> <div class="title">Key Insights</div> <ul> <li>SFT-based reasoning models (s1.1, OpenThinker3) on Qwen2.5 <strong>benefit the most</strong> from budget forcing; RFT and distillation behave more erratically.</li> <li>The <strong>linear scaling</strong> between budget and performance is <strong>not universal</strong>; plateaus and fluctuations are common.</li> <li>Detailed traces show two main failure modes: <ul> <li> <strong>Repetition</strong>: extra tokens repeat the same justification.</li> <li> <strong>Instability</strong>: extra tokens cause answers to flip back and forth.</li> </ul> </li> <li>These behaviors are consistent with a <strong>training-distribution hypothesis</strong>: beyond familiar CoT lengths, extra tokens may hurt more than help.</li> </ul> </div> </div> <h2 id="budget-forcing-works-with-non-reasoning-models-or-not">Budget Forcing Works With Non-Reasoning Models? Or Not?</h2> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/llms-480.webp 480w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/llms-800.webp 800w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/llms-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/llms.jpg" class="img-fluid rounded-lg" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>Now that weâ€™ve seen <strong>budget forcing</strong> improve performance in reasoning models, though the promised <em>linear performance trend</em> doesnâ€™t always hold, this raises another intriguing question:</p> <div class="highlight-card"> <div class="icon">â“</div> <div class="content"> <p>Is budget forcing an ability unique to <strong>reasoning models</strong>, or could it also work with a <strong>non-reasoning instruction-tuned</strong> model?</p> </div> </div> <p>At its core, budget forcing operates by identifying theÂ <strong>thinking completion</strong>Â (theÂ <code class="language-plaintext highlighter-rouge">&lt;/think&gt;</code>Â tag), removing it, and continuing the rollout toÂ <em>scale up</em>Â the reasoning process, or by trimming excess content within theÂ <code class="language-plaintext highlighter-rouge">&lt;think&gt;</code>Â block toÂ <em>scale down</em>.</p> <p>For budget forcing to function, the model only needs to generate text in a predictable structure:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;think&gt;</span> ... reasoning process ... <span class="nt">&lt;/think&gt;</span> final answer
</code></pre></div></div> <p>Importantly, this structure can often be inducedÂ <strong>through prompting alone</strong>, even in models that arenâ€™t explicitly trained for reasoning.</p> <hr> <p>To explore this, we promptedÂ <strong>Qwen2.5-7B-Instruct</strong>â€”the same base model used by all reasoning variants in our experimentsâ€”to produce outputs withinÂ <code class="language-plaintext highlighter-rouge">&lt;think&gt;&lt;/think&gt;</code>Â tags.</p> <details><summary>Prompt template</summary> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>You are a helpful and harmless expert math assistant. The assistant first thinks about the reasoning process in the mind and then provides the user with the accurate answer. The reasoning process is enclosed within &lt;think&gt;&lt;/think&gt; tags followed by an answer, i.e., &lt;think&gt; reasoning process here &lt;/think&gt; answer here. After thinking, when you finally reach a conclusion, clearly state the final answer in \boxed{}. Now the user asks you to solve a math problem.

{query}
</code></pre></div></div> </details> <p>If this setup works, it means we can apply <strong>test-time scaling</strong> techniques like budget forcing, even to <strong>non-reasoning models</strong>.</p> <p>So, what happens when we try it?</p> <h3 id="results-with-qwen25-7b-instruct">Results with Qwen2.5-7B-Instruct</h3> <details><summary>Result Table</summary> <div class="l-page"> <table class="table table-sm"> <thead> <tr> <th>Model</th> <th>Prompting</th> <th>Budget</th> <th>AIME 2025</th> <th>MATH500</th> <th>MMLU Pro-1K</th> <th>SuperGPQA-1K</th> <th>Average</th> </tr> </thead> <tbody> <tr> <td>Qwen2.5-7B-Instruct</td> <td>Zero-shot</td> <td>-</td> <td>20.00</td> <td><strong>69.00</strong></td> <td>30.30</td> <td>18.10</td> <td>34.35</td> </tr> <tr> <td>Qwen2.5-7B-Instruct</td> <td>CoT</td> <td>-</td> <td>23.33</td> <td>68.00</td> <td>12.00</td> <td>6.70</td> <td>27.51</td> </tr> <tr> <td>Qwen2.5-7B-Instruct</td> <td>CoT+BF</td> <td>256</td> <td>20.00</td> <td>41.20</td> <td>43.50</td> <td>24.90</td> <td>32.40</td> </tr> <tr> <td>Qwen2.5-7B-Instruct</td> <td>CoT+BF</td> <td>512</td> <td>6.670</td> <td>55.80</td> <td>46.70</td> <td>26.10</td> <td>33.82</td> </tr> <tr> <td>Qwen2.5-7B-Instruct</td> <td>CoT+BF</td> <td>1024</td> <td><strong>26.67</strong></td> <td>64.40</td> <td><strong>50.20</strong></td> <td>26.30</td> <td><strong>41.89</strong></td> </tr> <tr> <td>Qwen2.5-7B-Instruct</td> <td>CoT+BF</td> <td>2048</td> <td>20.00</td> <td>65.60</td> <td>48.60</td> <td><strong>28.50</strong></td> <td>40.68</td> </tr> <tr> <td>Qwen2.5-7B-Instruct</td> <td>CoT+BF</td> <td>4096</td> <td>20.00</td> <td>64.40</td> <td>48.40</td> <td>28.30</td> <td>40.28</td> </tr> <tr> <td>Qwen2.5-7B-Instruct</td> <td>CoT+BF</td> <td>8192</td> <td>20.00</td> <td>61.00</td> <td>48.70</td> <td>27.40</td> <td>39.28</td> </tr> </tbody> </table> </div> </details> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/performance_benchmark_llms-480.webp 480w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/performance_benchmark_llms-800.webp 800w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/performance_benchmark_llms-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/performance_benchmark_llms.png" class="img-fluid rounded-lg" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/performance_on_llms-480.webp 480w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/performance_on_llms-800.webp 800w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/performance_on_llms-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/performance_on_llms.png" class="img-fluid rounded-lg" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/trend_llm-480.webp 480w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/trend_llm-800.webp 800w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/trend_llm-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/trend_llm.png" class="img-fluid rounded-lg" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>Surprisingly, budget forcing at an 8,192-token budget works not only with reasoning models but also with thisÂ <strong>instruct model from the Qwen family</strong>. This shows that budget forcing is <strong>not an emergent behavior</strong> unique to explicitly trained reasoning models; it is a capability that can already be elicited via structured prompting.</p> <p>We observe:</p> <ul> <li>Improved performance on non-mathematical benchmarks (MMLU Pro-1K, SuperGPQA-1K),</li> <li>A slight decrease on mathematical benchmarks relative to zero-shot,</li> <li>And again, only a partially linear trend (e.g., MATH500 shows clearer gains from 256 â†’ 1024 budget, while other benchmarks fluctuate).</li> </ul> <p>Taken together, these findings raise the question of whether budget forcing can also be applied effectively to other non-reasoning model families.</p> <h3 id="how-about-other-model-families">How About Other Model Families?</h3> <p>We next tried applying the same budget forcing recipe to other instruction-tuned models of similar size:</p> <ul> <li><a href="https://huggingface.co/mistralai/Ministral-8B-Instruct-2410" rel="external nofollow noopener" target="_blank"><strong>Ministral 8B Instruct 2410</strong></a></li> <li><a href="https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct" rel="external nofollow noopener" target="_blank"><strong>Llama 3.1 8B Instruct</strong></a></li> <li><a href="https://huggingface.co/google/gemma-3-4b-it" rel="external nofollow noopener" target="_blank"><strong>Gemma 3 4B IT</strong></a></li> </ul> <p>All runs use the same budget-forcing machinery (withÂ <code class="language-plaintext highlighter-rouge">&lt;think&gt;...&lt;/think&gt;</code>Â and the â€œWaitâ€ keyword) and a fixed budget of 8192 reasoning tokens.</p> <details><summary>Result Table</summary> <div class="l-page"> <table class="table table-sm"> <thead> <tr> <th>Model</th> <th>Prompting</th> <th>AIME 2025</th> <th>MATH500</th> <th>MMLU Pro-1K</th> <th>SuperGPQA-1K</th> <th>Average </th> </tr> </thead> <tbody> <tr> <td>Ministral 8B Instruct 2410</td> <td>Zero-shot</td> <td>10.00</td> <td>52.20</td> <td>33.10</td> <td>17.30</td> <td>28.15 </td> </tr> <tr> <td>Ministral 8B Instruct 2410</td> <td>CoT</td> <td>6.67</td> <td>50.20</td> <td>31.10</td> <td>16.20</td> <td>26.04</td> </tr> <tr> <td>Ministral 8B Instruct 2410</td> <td>CoT+BF</td> <td>13.33</td> <td>50.40</td> <td>18.50</td> <td>8.80</td> <td>22.76</td> </tr> <tr> <td>Llama 3.1 8B Instruct</td> <td>Zero-shot</td> <td>10.00</td> <td>47.20</td> <td>32.80</td> <td>15.90</td> <td>26.48</td> </tr> <tr> <td>Llama 3.1 8B Instruct</td> <td>CoT</td> <td>13.33</td> <td>45.60</td> <td>30.10</td> <td>17.00</td> <td>26.51</td> </tr> <tr> <td>Llama 3.1 8B Instruct</td> <td>CoT+BF</td> <td>0.00</td> <td>40.80</td> <td>21.70</td> <td>16.40</td> <td>19.73</td> </tr> <tr> <td>Gemma 3 4B IT</td> <td>Zero-shot</td> <td><strong>33.33</strong></td> <td>70.20</td> <td><strong>37.70</strong></td> <td><strong>17.70</strong></td> <td><strong>39.73</strong></td> </tr> <tr> <td>Gemma 3 4B IT</td> <td>CoT</td> <td><strong>33.33</strong></td> <td><strong>70.40</strong></td> <td>28.30</td> <td>13.60</td> <td>36.41</td> </tr> <tr> <td>Gemma 3 4B IT</td> <td>CoT+BF</td> <td><strong>33.33</strong></td> <td>70.20</td> <td>36.70</td> <td>17.10</td> <td>39.33</td> </tr> </tbody> </table> </div> </details> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/performance_more_llms-480.webp 480w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/performance_more_llms-800.webp 800w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/performance_more_llms-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/performance_more_llms.png" class="img-fluid rounded-lg" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/performance_benchmarks_more_llms-480.webp 480w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/performance_benchmarks_more_llms-800.webp 800w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/performance_benchmarks_more_llms-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/performance_benchmarks_more_llms.png" class="img-fluid rounded-lg" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>Unfortunately, the benefits of budget forcing do not generally transfer across model families.</p> <ul> <li>For <strong>Llama 3.1 8B Instruct</strong> and <strong>Ministral 8B Instruct 2410</strong>, budget forcing <strong>reduces performance</strong> on most benchmarks, with the minor exception of AIME 2025 for Ministral.</li> <li> <strong>Gemma 3 4B IT</strong> shows a small positive effect, especially on QA benchmarks, but CoT alone already harms some metrics, and CoT+BF mostly recovers them.</li> </ul> <p>Overall, this suggests that budget forcing is not a broadly generalizable technique and appears to be most effective within theÂ <strong>Qwen2.5 model family (and close relatives)</strong>Â under our experimental conditions.</p> <div class="highlight-card"> <div class="icon">ğŸ“</div> <div class="content"> <div class="title">Key Insights</div> <ul> <li>Budget forcing can be <strong>induced via prompting</strong> in a plain instruction-tuned model, as long as we can reliably enforce a <code>&lt;think&gt;...&lt;/think&gt;</code> format.</li> <li>For <strong>Qwen2.5-7B-Instruct</strong>, budget forcing <strong>substantially improves</strong> QA benchmarks, but <strong>does not consistently help</strong> on math.</li> <li>The scaling curves are again <strong>non-linear</strong>; only a narrow budget range (around 1024 tokens) looks clearly beneficial.</li> <li>Budget forcing is therefore <strong>not inherently tied</strong> to a "reasoning" training pipeline, but its success is highly model-family dependent.</li> <li>The budget forcing recipe that works for Qwen2.5 <strong>fails or regresses</strong> on several other popular instruct families (Llama, Ministral).</li> <li>Gemma 3 4B IT is a mild outlier, showing slight improvements, but not a dramatic gain.</li> <li>Budget forcing is therefore <strong>not a plug-and-play trick</strong>: its success is tightly coupled to model-family-specific training choices.</li> </ul> </div> </div> <h2 id="wait-you-do-not-need-to-wait">Wait, You Do Not Need to Wait?</h2> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/hero_keywords-480.webp 480w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/hero_keywords-800.webp 800w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/hero_keywords-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/hero_keywords.png" class="img-fluid rounded-lg" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>Letâ€™s turn our attention to another interesting aspect of budget forcing â€” the <strong>keyword</strong>.</p> <p>So far weâ€™ve treated â€œWaitâ€ as the canonical budget-forcing keyword. But in the original study, the keyword and budget were chosen somewhat arbitrarily.</p> <p>This makes us curious:</p> <ul> <li>How does performance change if we alter the <strong>keyword</strong> that prompts the model to keep thinking?</li> <li>Is â€œWaitâ€ actually <strong>optimal</strong>, or just one reasonable choice?</li> <li>Do different models respond differently to different keywords?</li> </ul> <p>The original work used the keyword <em>â€œWaitâ€</em>, signaling that the model should pause and reconsider its reasoning so far. But perhaps budget forcing itself is effective regardless of the specific keyword, with <em>â€œWaitâ€</em> being just one arbitrary example.</p> <h3 id="keyword-selection">Keyword Selection</h3> <p>Before running our experiments, we first needed a principled way toÂ <strong>choose keywords</strong>.</p> <p>To do this, we started with a simple approach: we performed aÂ <strong>word-frequency analysis</strong>Â on sampled reasoning traces from Qwen3-8B and DeepSeek-R1-Distill-8B across MATH500 and MMLU Pro-1K. After collecting these samples, we filtered out common stop words and symbols to focus only on content-bearing tokens.</p> <p>We found that <strong>â€œWaitâ€ is not actually the most frequent word</strong> in the modelsâ€™ reasoning traces. Instead, each model has its own set of frequently used reasoning words.</p> <p>Based on this, we selected high-frequency reasoning words such asÂ <strong>â€œLetâ€</strong>Â andÂ <strong>â€œPerhapsâ€</strong>Â and used them as alternative keywords in our budget-forcing experiments.</p> <details><summary>Word frequency results</summary> <p><strong>Qwen3 8B (With Thinking)</strong></p> <details><summary>MATH500</summary> <p>Overall: <code class="language-plaintext highlighter-rouge">['Let', 'Therefore', 'Wait', 'Alternatively', 'First']</code></p> <p><strong>By subject:</strong></p> <ul> <li> <strong>Precalculus</strong>: <code class="language-plaintext highlighter-rouge">['Therefore', 'Let', 'Wait', 'Alternatively', 'First']</code> </li> <li> <strong>Intermediate Algebra</strong>: <code class="language-plaintext highlighter-rouge">['Therefore', 'Let', 'Wait', 'Alternatively', 'First']</code> </li> <li> <strong>Algebra</strong>: <code class="language-plaintext highlighter-rouge">['Let', 'Therefore', 'Wait', 'Alternatively', 'First']</code> </li> <li> <strong>Number Theory</strong>: <code class="language-plaintext highlighter-rouge">['Therefore', 'Let', 'Wait', 'Alternatively', 'Since']</code> </li> <li> <strong>Prealgebra</strong>: <code class="language-plaintext highlighter-rouge">['Let', 'Therefore', 'Wait', 'Alternatively', 'First']</code> </li> <li> <strong>Geometry</strong>: <code class="language-plaintext highlighter-rouge">['Therefore', 'Let', 'Wait', 'AB', 'AD']</code> </li> <li> <strong>Counting &amp; Probability</strong>: <code class="language-plaintext highlighter-rouge">['Let', 'Therefore', 'Wait', 'Alternatively', 'Total']</code> </li> </ul> <p><strong>By level:</strong></p> <ul> <li> <strong>Level 1</strong>: <code class="language-plaintext highlighter-rouge">['Let', 'Therefore', 'Wait', 'Alternatively', 'First']</code> </li> <li> <strong>Level 2</strong>: <code class="language-plaintext highlighter-rouge">['Let', 'Therefore', 'Wait', 'Alternatively', 'First']</code> </li> <li> <strong>Level 3</strong>: <code class="language-plaintext highlighter-rouge">['Let', 'Therefore', 'Wait', 'Alternatively', 'First']</code> </li> <li> <strong>Level 4</strong>: <code class="language-plaintext highlighter-rouge">['Let', 'Therefore', 'Wait', 'Alternatively', 'First']</code> </li> <li> <strong>Level 5</strong>: <code class="language-plaintext highlighter-rouge">['Therefore', 'Let', 'Wait', 'Alternatively', 'First']</code> </li> </ul> </details> <details><summary>MMLU Pro 1K</summary> <p>Overall: <code class="language-plaintext highlighter-rouge">['Let', 'Wait', 'Alternatively', 'Therefore', 'Option']</code></p> <p><strong>By category:</strong></p> <ul> <li> <strong>Chemistry</strong>: <code class="language-plaintext highlighter-rouge">['Let', 'Wait', 'Alternatively', 'Therefore', 'First']</code> </li> <li> <strong>Computer science</strong>: <code class="language-plaintext highlighter-rouge">['Wait', 'Let', 'Therefore', 'DIAG', 'Option']</code> </li> <li> <strong>Other</strong>: <code class="language-plaintext highlighter-rouge">['Wait', 'Alternatively', 'Let', 'Option', 'However']</code> </li> <li> <strong>Psychology</strong>: <code class="language-plaintext highlighter-rouge">['Option', 'Wait', 'Alternatively', 'However', 'Let']</code> </li> <li> <strong>Law</strong>: <code class="language-plaintext highlighter-rouge">['Therefore', 'Wait', 'However', 'Option', 'Alternatively']</code> </li> <li> <strong>Physics</strong>: <code class="language-plaintext highlighter-rouge">['Let', 'Wait', 'Alternatively', 'Therefore', 'However']</code> </li> <li> <strong>Business</strong>: <code class="language-plaintext highlighter-rouge">['Let', 'Wait', 'Alternatively', 'First', 'Therefore']</code> </li> <li> <strong>Math</strong>: <code class="language-plaintext highlighter-rouge">['Let', 'Wait', 'Therefore', 'Alternatively', 'First']</code> </li> <li> <strong>History</strong>: <code class="language-plaintext highlighter-rouge">['Option', 'Alternatively', 'However', 'Wait', 'Let']</code> </li> <li> <strong>Economics</strong>: <code class="language-plaintext highlighter-rouge">['Wait', 'Let', 'Option', 'However', 'Therefore']</code> </li> <li> <strong>Health</strong>: <code class="language-plaintext highlighter-rouge">['Wait', 'Alternatively', 'However', 'Let', 'Option']</code> </li> <li> <strong>Biology</strong>: <code class="language-plaintext highlighter-rouge">['Wait', 'Option', 'Let', 'Alternatively', 'However']</code> </li> <li> <strong>Engineering</strong>: <code class="language-plaintext highlighter-rouge">['Let', 'Wait', 'Alternatively', 'Therefore', 'However']</code> </li> <li> <strong>Philosophy</strong>: <code class="language-plaintext highlighter-rouge">['Wait', 'Alternatively', 'Let', 'Option', 'However']</code> </li> </ul> </details> <p><strong>DeepSeek R1 0528 Qwen3 8B</strong></p> <details><summary>MATH500</summary> <p>Overall: <code class="language-plaintext highlighter-rouge">['Perhaps', 'Let', 'Another', 'Yes', 'Since']</code></p> <p><strong>By subject:</strong></p> <ul> <li> <strong>Precalculus</strong>: <code class="language-plaintext highlighter-rouge">['Let', 'Another', 'Yes', 'Since', 'Perhaps']</code> </li> <li> <strong>Intermediate Algebra</strong>: <code class="language-plaintext highlighter-rouge">['Let', 'Since', 'Another', 'Perhaps', 'Suppose']</code> </li> <li> <strong>Algebra</strong>: <code class="language-plaintext highlighter-rouge">['Let', 'Perhaps', 'Yes', 'Another', 'First']</code> </li> <li> <strong>Number Theory</strong>: <code class="language-plaintext highlighter-rouge">['Perhaps', 'Another', 'Yes', 'Let', 'Since']</code> </li> <li> <strong>Prealgebra</strong>: <code class="language-plaintext highlighter-rouge">['Perhaps', 'Let', 'Another', 'Yes', 'USD']</code> </li> <li> <strong>Geometry</strong>: <code class="language-plaintext highlighter-rouge">['AB', 'AD', 'ABC', 'AC', 'BC']</code> </li> <li> <strong>Counting &amp; Probability</strong>: <code class="language-plaintext highlighter-rouge">['Bob', 'Alice', 'Yes', 'Another', 'Similarly']</code> </li> </ul> <p><strong>By level:</strong></p> <ul> <li> <strong>Level 1</strong>: <code class="language-plaintext highlighter-rouge">['Let', 'Another', 'Perhaps', 'Yes', 'DE']</code> </li> <li> <strong>Level 2</strong>: <code class="language-plaintext highlighter-rouge">['Let', 'Perhaps', 'Another', 'Yes', 'Since']</code> </li> <li> <strong>Level 3</strong>: <code class="language-plaintext highlighter-rouge">['Perhaps', 'Let', 'Yes', 'Another', 'Since']</code> </li> <li> <strong>Level 4</strong>: <code class="language-plaintext highlighter-rouge">['Let', 'Perhaps', 'Another', 'Yes', 'Since']</code> </li> <li> <strong>Level 5</strong>: <code class="language-plaintext highlighter-rouge">['Perhaps', 'Let', 'Another', 'Yes', 'Since']</code> </li> </ul> </details> <details><summary>MMLU Pro Mini</summary> <p>Overall: <code class="language-plaintext highlighter-rouge">['Perhaps', 'Option', 'Maybe', 'Let', 'Yes']</code></p> <p><strong>By category:</strong></p> <ul> <li> <strong>Chemistry</strong>: <code class="language-plaintext highlighter-rouge">['Perhaps', 'Maybe', 'Yes', 'First', 'Let']</code> </li> <li> <strong>Computer science</strong>: <code class="language-plaintext highlighter-rouge">['Perhaps', 'Option', 'Maybe', 'Yes', 'Let']</code> </li> <li> <strong>Other</strong>: <code class="language-plaintext highlighter-rouge">['Option', 'Perhaps', 'Maybe', 'Let', 'Yes']</code> </li> <li> <strong>Psychology</strong>: <code class="language-plaintext highlighter-rouge">['Option', 'Perhaps', 'Let', 'Maybe', 'Upon']</code> </li> <li> <strong>Law</strong>: <code class="language-plaintext highlighter-rouge">['Option', 'Perhaps', 'Yes', 'Let', 'First']</code> </li> <li> <strong>Physics</strong>: <code class="language-plaintext highlighter-rouge">['Perhaps', 'Option', 'Maybe', 'Yes', 'Let']</code> </li> <li> <strong>Business</strong>: <code class="language-plaintext highlighter-rouge">['Perhaps', 'Maybe', 'Let', 'Another', 'Option']</code> </li> <li> <strong>Math</strong>: <code class="language-plaintext highlighter-rouge">['Perhaps', 'Yes', 'Maybe', 'Let', 'Option']</code> </li> <li> <strong>History</strong>: <code class="language-plaintext highlighter-rouge">['Option', 'Perhaps', 'War', 'Articles', 'Let']</code> </li> <li> <strong>Economics</strong>: <code class="language-plaintext highlighter-rouge">['Option', 'Perhaps', 'MC', 'GDP', 'Let']</code> </li> <li> <strong>Health</strong>: <code class="language-plaintext highlighter-rouge">['Option', 'Perhaps', 'Vitamin', 'Maybe', 'Let']</code> </li> <li> <strong>Biology</strong>: <code class="language-plaintext highlighter-rouge">['Option', 'Perhaps', 'Maybe', 'Let', 'Yes']</code> </li> <li> <strong>Engineering</strong>: <code class="language-plaintext highlighter-rouge">['Perhaps', 'Maybe', 'Yes', 'Option', 'First']</code> </li> <li> <strong>Philosophy</strong>: <code class="language-plaintext highlighter-rouge">['Option', 'Perhaps', 'Kant', 'Let', 'Maybe']</code> </li> </ul> </details> <p>This analysis suggests that â€œLetâ€ and â€œPerhapsâ€ are <strong>natural reasoning words</strong> for these modelsâ€”often appearing at the beginning of sub-derivations or alternative hypotheses.</p> </details> <h3 id="let-us-try-other-keywords-perhaps-we-will-get-interesting-results">Let Us Try Other Keywords: Perhaps We Will Get Interesting Results</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/keyword_choices-480.webp 480w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/keyword_choices-800.webp 800w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/keyword_choices-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/keyword_choices.png" class="img-fluid rounded-lg" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>We then followed the same experimental setup as before, testing multiple reasoning models with:</p> <ul> <li>A fixed budget of 8192 tokens,</li> <li>And different keywords:Â <strong>â€œWaitâ€</strong>,Â <strong>â€œLetâ€</strong>, andÂ <strong>â€œPerhapsâ€</strong>.</li> </ul> <details><summary>Result Table</summary> <table> <thead> <tr> <th>Model</th> <th>Keyword</th> <th>AIME 2025</th> <th>MATH500</th> <th>MMLU Pro-1K</th> <th>SuperGPQA-1K</th> <th>Average</th> </tr> </thead> <tbody> <tr> <td>Qwen2.5-7B-Instruct</td> <td>Wait</td> <td>20.00</td> <td>61.00</td> <td>48.70</td> <td>27.40</td> <td>39.27</td> </tr> <tr> <td>Qwen2.5-7B-Instruct</td> <td>Perhaps</td> <td>23.33</td> <td>64.00</td> <td>49.90</td> <td>27.40</td> <td>41.16</td> </tr> <tr> <td>Qwen2.5-7B-Instruct</td> <td>Let</td> <td>26.67</td> <td>66.40</td> <td>49.50</td> <td>27.60</td> <td>42.54</td> </tr> <tr> <td>RFT</td> <td>Wait</td> <td>23.33</td> <td>63.80</td> <td>45.20</td> <td>27.80</td> <td>40.03</td> </tr> <tr> <td>RFT</td> <td>Perhaps</td> <td>16.67</td> <td>66.00</td> <td>44.50</td> <td>27.10</td> <td>38.57</td> </tr> <tr> <td>RFT</td> <td>Let</td> <td><strong>33.33</strong></td> <td>65.60</td> <td>42.50</td> <td>25.90</td> <td>41.83</td> </tr> <tr> <td>s1.1-7B</td> <td>Wait</td> <td>23.33</td> <td>74.20</td> <td><strong>62.10</strong></td> <td><strong>33.40</strong></td> <td>48.26</td> </tr> <tr> <td>s1.1-7B</td> <td>Perhaps</td> <td><strong>33.33</strong></td> <td>73.80</td> <td>61.40</td> <td>32.30</td> <td><strong>50.21</strong></td> </tr> <tr> <td>s1.1-7B</td> <td>Let</td> <td>16.67</td> <td>76.20</td> <td>61.30</td> <td>32.10</td> <td>46.57</td> </tr> <tr> <td>DeepSeek R1 Distill Qwen 7B</td> <td>Wait</td> <td>26.67</td> <td>83.40</td> <td>10.80</td> <td>6.70</td> <td>31.89</td> </tr> <tr> <td>DeepSeek R1 Distill Qwen 7B</td> <td>Perhaps</td> <td>30.00</td> <td>82.40</td> <td>11.40</td> <td>6.80</td> <td>32.65</td> </tr> <tr> <td>DeepSeek R1 Distill Qwen 7B</td> <td>Let</td> <td>26.67</td> <td><strong>84.60</strong></td> <td>12.00</td> <td>6.60</td> <td>32.47</td> </tr> <tr> <td>Ministral 8B Instruct 2410</td> <td>Wait</td> <td>13.33</td> <td>50.40</td> <td>18.50</td> <td>8.80</td> <td>22.76</td> </tr> <tr> <td>Ministral 8B Instruct 2410</td> <td>Perhaps</td> <td>6.67</td> <td>49.20</td> <td>20.00</td> <td>9.80</td> <td>21.42</td> </tr> <tr> <td>Ministral 8B Instruct 2410</td> <td>Let</td> <td>16.67</td> <td>50.60</td> <td>19.00</td> <td>9.20</td> <td>23.87</td> </tr> <tr> <td>Llama 3.1 8B Instruct</td> <td>Wait</td> <td>0.00</td> <td>40.80</td> <td>21.70</td> <td>16.40</td> <td>19.73</td> </tr> <tr> <td>Llama 3.1 8B Instruct</td> <td>Perhaps</td> <td>3.33</td> <td>44.80</td> <td>21.60</td> <td>16.70</td> <td>21.61</td> </tr> <tr> <td>Llama 3.1 8B Instruct</td> <td>Let</td> <td>10.00</td> <td>41.80</td> <td>21.70</td> <td>16.40</td> <td>22.48</td> </tr> </tbody> </table> </details> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/performance_keywords-480.webp 480w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/performance_keywords-800.webp 800w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/performance_keywords-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/performance_keywords.png" class="img-fluid rounded-lg" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>Across all six models, we observe a consistent pattern:</p> <ul> <li>The three keywords yieldÂ <strong>similar</strong>Â performance ranges,</li> <li>ButÂ <strong>â€œWaitâ€ is never the best keyword</strong>Â for any model,</li> <li>And the best keyword is <strong>model-specific</strong> (e.g., â€œLetâ€ for Qwen2.5-7B-Instruct, â€œPerhapsâ€ for s1.1 in terms of average score).</li> </ul> <p>This suggests that whileÂ <em>â€œWaitâ€</em>Â is a reasonable baseline, it isnâ€™t the best choice.</p> <p>Even more interestingly,Â <em>â€œLetâ€</em>Â andÂ <em>â€œPerhapsâ€</em>Â donâ€™t carry the same â€œpause and reconsiderâ€ semantics asÂ <em>â€œWaitâ€</em>. Instead, they are more neutral, often marking the start of a derivation (â€œLet x beâ€¦â€) or an alternative hypothesis (â€œPerhaps the correct interpretation isâ€¦â€). Yet they often outperformÂ <em>â€œWaitâ€</em>, hinting that models may respond better to keywords that align with theirÂ <strong>natural reasoning patterns</strong>Â rather than explicit instructions.</p> <p>Our word-frequency analysis offers a plausible explanation: models tend to use words like <em>â€œLetâ€</em> and <em>â€œPerhapsâ€</em> frequently in their own reasoning traces. The best keyword may simply be the one the model is already comfortable using â€” a clue that <strong>keyword selection can be grounded in model-specific linguistic habits</strong>, rather than intuition alone.</p> <div class="highlight-card"> <div class="icon">ğŸ“</div> <div class="content"> <div class="title">Key Insights</div> <ul> <li>The keyword <strong>matters</strong>: swapping "Wait" for other words can yield measurable performance differences.</li> <li>Across all tested models, <strong>"Wait" is never optimal</strong>; model-specific high-frequency reasoning words ("Let", "Perhaps") often work better.</li> <li>Keyword choice is therefore <strong>not universal</strong> and should be tuned per model, ideally guided by a simple word-frequency analysis on its own CoT traces.</li> <li>This turns keyword selection into a practical, low-cost hyperparameter for budget forcing.</li> </ul> </div> </div> <h2 id="summary">Summary</h2> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/summary-480.webp 480w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/summary-800.webp 800w,/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/summary-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-wait-do-we-need-to-wait/summary.png" class="img-fluid rounded-lg" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>This work revisitsÂ <strong>budget forcing</strong>, a sequential test-time scaling method that extends or trims a modelâ€™s reasoning by controlling the token budget and repeatedly prompting it to continue thinking. While originally demonstrated on a single math-reasoning model using the keyword â€œWait,â€ the technique behaves very differently across architectures, training pipelines, and domains.</p> <p>Across a broad set of experiments, several key insights emerge:</p> <p><strong>1. Budget forcing helpsâ€”but only for some models.</strong></p> <p>SFT-based reasoning models such as s1.1 and OpenThinker3 (and, to a lesser extent, Qwen2.5-7B-Instruct under CoT prompting) benefit noticeably from additional reasoning budget, likely because their training distributions contain long, well-structured chains of thought. In contrast, RFT-based and distillation-based models show mixed results, and DeepSeek-R1-Distill-Qwen-7B often degrades when forced to â€œoverthink.â€</p> <p><strong>2. The popular claim of â€œlinear scalingâ€ does not hold universally.</strong></p> <p>Although larger budgets generally outperform smaller ones at a very coarse level, performance curves differ significantly by model. Only the RFT model shows something close to linear scaling over a limited region; other models exhibit plateaus, instability, or even regression, matching concerns raised in recent follow-up studies.</p> <p><strong>3. Budget forcing is not exclusive to reasoning models.</strong></p> <p>Instruction-tuned models without explicit reasoning training (e.g., Qwen2.5-7B-Instruct) can be made to use budget forcing when prompted to generateÂ <code class="language-plaintext highlighter-rouge">&lt;think&gt;...&lt;/think&gt;</code>Â structures. Some benchmarks improve substantially. However, this behavior doesÂ <strong>not</strong>Â generally transfer across model families: Llama 3.1 and Ministral often degrade, while Gemma shows only mild gains. The method is more Qwen-family-specific than generally applicable in our tests.</p> <p><strong>4. The keyword â€œWaitâ€ is arbitraryâ€”and rarely optimal.</strong></p> <p>Replacing â€œWaitâ€ with high-frequency reasoning words such as â€œLetâ€ or â€œPerhapsâ€ often yields better results. Different models respond differently, implying that effective keywords align with a modelâ€™s internal linguistic habits rather than semantic cues like â€œpauseâ€ or â€œreconsider.â€ Keyword choice is therefore not universal and should be treated as a tunable, model-specific hyperparameter.</p> <div class="highlight-card"> <div class="icon">âš¡</div> <div class="content"> <div class="title">Bottom Line</div> <p><strong>Budget forcing is neither a universal law nor a guaranteed improvement.</strong> Its effectiveness depends on:</p> <ul> <li> <strong>Training style</strong>: SFT models with long CoT data benefit most</li> <li> <strong>Model family</strong>: Qwen-based models respond best; others often don't</li> <li> <strong>Keyword choices</strong>: Keyword matters significantly</li> </ul> <p>While budget forcing can provide meaningful gains for the right models (especially SFT reasoning models in the Qwen family), many open questions remainâ€”including whether improvements correlate with token entropy <d-cite key="wang2025beyond"></d-cite>, internal uncertainty, or other emergent signals not yet fully understood.</p> </div> </div> <hr> <h2 id="practical-recommendations">Practical Recommendations</h2> <p>Based on our experiments, here are actionable guidelines for practitioners looking to apply budget forcing.</p> <div class="highlight-card"> <div class="icon">ğŸ¯</div> <div class="content"> <div class="title">Quick Start</div> <p>Before diving into details: <strong>Budget forcing works best for Qwen2.5-based SFT reasoning models.</strong> If you're using Llama, Mistral, or other families, test carefullyâ€”it may not help.</p> </div> </div> <h3 id="step-1-check-model-compatibility">Step 1: Check Model Compatibility</h3> <p>Not all models benefit from budget forcing. Hereâ€™s what to expect:</p> <table> <thead> <tr> <th>Category</th> <th>Models</th> <th>Expected Outcome</th> </tr> </thead> <tbody> <tr> <td>âœ… <strong>Best</strong> </td> <td>s1.1, OpenThinker3 (SFT reasoning models)</td> <td>Clear improvements, especially on math/reasoning tasks</td> </tr> <tr> <td>âœ… <strong>Good</strong> </td> <td>Qwen2.5-7B-Instruct with <code class="language-plaintext highlighter-rouge">&lt;think&gt;</code> prompting</td> <td>Works for QA tasks, mixed for math</td> </tr> <tr> <td>âš ï¸ <strong>Mixed</strong> </td> <td>RFT models, distillation models</td> <td>Inconsistent results, test first</td> </tr> <tr> <td>âŒ <strong>Poor</strong> </td> <td>Llama 3.1, Ministral, most non-Qwen families</td> <td>Often degrades performance</td> </tr> </tbody> </table> <h3 id="step-2-choose-the-right-keyword">Step 2: Choose the Right Keyword</h3> <p>The keyword â€œWaitâ€ is <strong>not optimal</strong> for most models. Choose based on your modelâ€™s natural reasoning patterns:</p> <h4 id="our-top-findings">Our Top Findings</h4> <ul> <li> <strong>Qwen2.5-7B-Instruct</strong> â†’ Use <strong>â€œLetâ€</strong> </li> <li> <strong>s1.1</strong> â†’ Use <strong>â€œPerhapsâ€</strong> </li> <li> <strong>General rule</strong> â†’ Pick words your model naturally uses (e.g., â€œLetâ€, â€œPerhapsâ€, â€œThereforeâ€), not instruction words like â€œWaitâ€</li> </ul> <h3 id="step-3-set-the-right-budget">Step 3: Set the Right Budget</h3> <p>Bigger budgets are <strong>not always better</strong>. Performance typically plateaus around 2048-4096 tokens.</p> <h4 id="recommended-starting-points">Recommended Starting Points</h4> <ul> <li> <strong>First test</strong>: Start with <strong>1024 tokens</strong> (good baseline for most models)</li> <li> <strong>Math/reasoning</strong>: Try 2048-4096 tokens</li> <li> <strong>QA tasks</strong>: 512-1024 tokens usually enough</li> <li> <strong>Donâ€™t exceed</strong>: 4096 tokens (rarely helps beyond this)</li> </ul> <p>Monitor for failure modes: repetition (model loops) or instability (answer keeps changing).</p> <h3 id="when-to-avoid-budget-forcing">When to Avoid Budget Forcing</h3> <p><strong>Donâ€™t use budget forcing</strong> if:</p> <table> <thead> <tr> <th>âŒ Skip ifâ€¦</th> <th>Why</th> </tr> </thead> <tbody> <tr> <td>Using Llama or Mistral families</td> <td>Rarely helps, often hurts</td> </tr> <tr> <td>Zero-shot already works well</td> <td>Budget forcing may degrade performance</td> </tr> <tr> <td>Compute budget is tight</td> <td>Token cost increase</td> </tr> <tr> <td>See large numbers of repetition in of outputs</td> <td>Model is looping, not thinking</td> </tr> </tbody> </table> <hr> <h2 id="limitations">Limitations</h2> <p>Our results are based on a limited set of models, scales, and training pipelines. Most of the positive findings come from Qwen2.5-based models; while we also test Llama 3.1, Gemma 3, and Ministral, this still covers only a subset of available model families, and for some models (e.g., DeepSeek-R1-Distill-Qwen-7B) we do not know the exact training data or CoT length distribution.</p> <p>We primarily study 7â€“8B models on English math and QA benchmarks (AIME, MATH500, MMLU Pro, SuperGPQA) with automatic accuracy metrics, so the observed patterns may not directly transfer to other tasks (such as coding, tool use, or long-context reasoning), languages, or evaluation criteria. Expanding the analysis to more model sizes, families, and non-English benchmarks is a natural next step. Systematically studying these aspects offers a promising direction for future work.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/2026/assets/bibliography/2026-04-27-wait-do-we-need-to-wait.bib"></d-bibliography> <d-article> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/symbolic-connect/">Symbolism Outside, Connectionism Inside: The Trend of Fusing LLMs and Automatic Programs with Symbolic Intermediate Representations</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/sac-massive-sim/">Getting SAC to Work on a Massive Parallel Simulator: An RL Journey With Off-Policy Algorithms</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/pushing-meta-cl-methods/">Pushing Meta-Continual Learning Algorithms to the Limit</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/nlp-for-human-sciences/">Language as a Window Into the Mind: How NLP and LLMs Advance Human Sciences</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/model-misspecification-in-sbi/">Model Misspecification in Simulation-Based Inference - Recent Advances and Open Challenges</a> </li> <br> <br> </d-article> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> Â© Copyright 2025 ICLR Blog. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/2026/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script src="/2026/assets/js/distillpub/overrides.js"></script> <script defer src="https://cdn.jsdelivr.net/npm/mermaid@10.7.0/dist/mermaid.min.js" integrity="sha256-TtLOdUA8mstPoO6sGvHIGx2ceXrrX4KgIItO06XOn8A=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/d3@7.8.5/dist/d3.min.js" integrity="sha256-1rA678n2xEx7x4cTZ5x4wpUCj6kUMZEZ5cxLSVSFWxw=" crossorigin="anonymous"></script> <script defer src="/2026/assets/js/mermaid-setup.js?38ca0a0126f7328d2d9a46bad640931f" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/2026/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/2026/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/2026/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/2026/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/2026/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/2026/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/2026/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/2026/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/2026/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/2026/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/2026/assets/js/search-data.js"></script> <script src="/2026/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>