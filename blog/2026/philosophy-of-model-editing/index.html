<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> A Philosophy of Model Editing - What Does It Mean to “Change Knowledge” in a Neural Network? | ICLR Blogposts 2026 </title> <meta name="author" content="ICLR Blog"> <meta name="description" content="This blogpost explores what it truly means to change knowledge inside a neural network. Unlike symbolic systems, large language models do not store facts in explicit locations; they implement them through distributed geometric transformations. Editing a model therefore reshapes regions of its activation space, alters relational structures, and sometimes shifts broader behavioral tendencies. We examine how local edits differ from global ones, why forgetting resembles suppression rather than deletion, and how repeated modifications can change a model’s identity. By framing model editing as a philosophical and structural question rather than a purely technical procedure, this piece highlights the need to evaluate edits not only for local correctness but also for their impact on coherence, ontology, and long-term behavior."> <meta name="keywords" content="machine-learning, ml, deep-learning, reinforcement-learning, icl# add your own keywords or leave empty"> <link rel="stylesheet" href="/2026/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/2026/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/2026/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/2026/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/2026/assets/img/iclr_favicon.ico?0a8a3afdb0dbe139723b24dba3052a4f"> <link rel="stylesheet" href="/2026/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://iclr-blogposts.github.io/2026/blog/2026/philosophy-of-model-editing/"> <script src="/2026/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/2026/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <script src="/2026/assets/js/distillpub/template.v2.js"></script> <script src="/2026/assets/js/distillpub/transforms.v2.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "A Philosophy of Model Editing - What Does It Mean to “Change Knowledge” in a Neural Network?",
            "description": "This blogpost explores what it truly means to change knowledge inside a neural network. Unlike symbolic systems, large language models do not store facts in explicit locations; they implement them through distributed geometric transformations. Editing a model therefore reshapes regions of its activation space, alters relational structures, and sometimes shifts broader behavioral tendencies. We examine how local edits differ from global ones, why forgetting resembles suppression rather than deletion, and how repeated modifications can change a model’s identity. By framing model editing as a philosophical and structural question rather than a purely technical procedure, this piece highlights the need to evaluate edits not only for local correctness but also for their impact on coherence, ontology, and long-term behavior.",
            "published": "April 27, 2026",
            "authors": [
              
              {
                "author": "Anonymous",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "ICLR 2026 Submission",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/2026/"> ICLR Blogposts 2026 </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/2026/">home </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/about/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/call/">call for blogposts </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/submitting/">submitting </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/reviewing/">reviewing </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">past iterations </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2026/"><strong>2026</strong></a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2025/">2025</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2024/">2024</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2023/">2023</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blog-track.github.io/home/" rel="external nofollow noopener" target="_blank">2022</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>A Philosophy of Model Editing - What Does It Mean to “Change Knowledge” in a Neural Network?</h1> <p>This blogpost explores what it truly means to change knowledge inside a neural network. Unlike symbolic systems, large language models do not store facts in explicit locations; they implement them through distributed geometric transformations. Editing a model therefore reshapes regions of its activation space, alters relational structures, and sometimes shifts broader behavioral tendencies. We examine how local edits differ from global ones, why forgetting resembles suppression rather than deletion, and how repeated modifications can change a model’s identity. By framing model editing as a philosophical and structural question rather than a purely technical procedure, this piece highlights the need to evaluate edits not only for local correctness but also for their impact on coherence, ontology, and long-term behavior.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#introduction">Introduction</a> </div> <div> <a href="#what-is-knowledge-inside-a-neural-network">What Is “Knowledge” Inside a Neural Network?</a> </div> <div> <a href="#what-actually-changes-during-a-model-edit">What Actually Changes During a Model Edit?</a> </div> <ul> <li> <a href="#local-micro-manifold-rewrites">Local Micro-Manifold Rewrites</a> </li> <li> <a href="#distributed-relational-shifts">Distributed Relational Shifts</a> </li> </ul> <div> <a href="#does-editing-introduce-inconsistency">Does Editing Introduce Inconsistency?</a> </div> <div> <a href="#can-a-neural-network-ever-truly-forget">Can a Neural Network Ever Truly “Forget”?</a> </div> <div> <a href="#the-ontology-of-edited-models-does-editing-change-identity">The Ontology of Edited Models - Does Editing Change Identity?</a> </div> <div> <a href="#why-this-matters-beyond-bug-fixes">Why This Matters - Beyond Bug-Fixes</a> </div> <ul> <li> <a href="#safety">Safety</a> </li> <li> <a href="#alignment">Alignment</a> </li> <li> <a href="#interpretability">Interpretability</a> </li> <li> <a href="#delegated-autonomy">Delegated Autonomy</a> </li> <li> <a href="#scientific-understanding">Scientific Understanding</a> </li> </ul> <div> <a href="#a-research-aware-conceptual-taxonomy-of-model-edits">A Research-Aware Conceptual Taxonomy of Model Edits</a> </div> <div> <a href="#conclusion-editing-knowledge-editing-memory">Conclusion — Editing Knowledge ≠ Editing Memory</a> </div> </nav> </d-contents> <h2 id="introduction">Introduction</h2> <p>Large language models can now be adjusted. They can be corrected after deployment, fixed for safety, or guided towards new behaviors without needing complete retraining. This raises a fundamental question that spans machine learning, knowledge theory, and philosophy: What does it mean to change knowledge within a neural network? Traditional software updates a record in a database. Humans change beliefs through reasoning, feelings, and contradictions. Neural networks do neither. They do not store symbols, explicit beliefs, or lookup tables. Instead, knowledge is spread out, intertwined, and geometric.</p> <p>So when we edit a model :</p> <ul> <li>Are we rewriting memory?</li> <li>Are we distorting the shape of meaning itself?</li> <li>Is a fact a localized change or a global guideline?</li> <li>Can a neural network truly forget?</li> <li>And if we reshape enough knowledge, does the model’s identity shift?</li> </ul> <p>This blog post provides a framework for these questions. It is based on the technical features of neural networks but also invites philosophical reflection.</p> <h2 id="what-is-knowledge-inside-a-neural-network">What Is “Knowledge” Inside a Neural Network?</h2> <p>Before exploring how knowledge changes, we need to understand what it is.</p> <p>In symbolic systems, knowledge exists as:</p> <ul> <li>entries</li> <li>axioms</li> <li>pointers</li> <li>definitions</li> </ul> <p>In a neural network, there is no specific spot for “The Eiffel Tower is in Paris.” Instead, knowledge arises from a transformation represented in <d-cite key="bengio2013representation"></d-cite>:</p> <ul> <li>embedding geometry</li> <li>attention pathways</li> <li>MLP activations</li> <li>token transition statistics</li> </ul> <p>A useful summary:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>A fact is not stored; it is enacted. A network knows something because its transformations consistently bring it about.
</code></pre></div></div> <p>To illustrate this, consider a straightforward example <d-cite key="geva2021transformerfeedforward"></d-cite> :</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>When a model states, “Rome is the capital of Italy,” the fact is not retrieved; it emerges from a path through activation space that consistently lands in the “Rome” area.
</code></pre></div></div> <p>Thus:</p> <ul> <li>A fact is a stable attractor.</li> <li>A belief is a directional bias in that space.</li> <li>A concept is a group of reachable states.</li> </ul> <p>This means editing is essentially a geometric process.</p> <h2 id="what-actually-changes-during-a-model-edit">What Actually Changes During a Model Edit?</h2> <p>Editing a model—whether through fine-tuning, ROME-style updates, MEMIT, soft prompts, or manual weight adjustments—changes the underlying geometry of these attractors.</p> <p>Two main types of changes typically occur:</p> <h3 id="local-micro-manifold-rewrites">Local Micro-Manifold Rewrites</h3> <p>Imagine a micro-manifold: a small area of activation space where similar prompts converge. For example, questions like:</p> <ul> <li>“What is the capital of Italy?”</li> <li>“Italy’s capital city is…”</li> <li>“The city that serves as Italy’s seat of government is…”</li> </ul> <p>All fall into a similar neighborhood.</p> <p>A local edit only alters this specific area:</p> <ul> <li>the boundary shifts,</li> <li>an attractor nudges,</li> <li>nearby semantic neighbors reorganize slightly.</li> </ul> <p>Methods like ROME and MEMIT aim to work here <d-cite key="meng2022rome"></d-cite> <d-cite key="meng2023memit"></d-cite>, making precise and minimally invasive modifications.</p> <h3 id="distributed-relational-shifts">Distributed Relational Shifts</h3> <p>Some relationships are globally structured.</p> <p>Editing a relation like (Italy, capital, X) can have broader impacts:</p> <ul> <li>“Italian government is located in…”</li> <li>“Italian culture in ___ city”</li> <li>analogies like “France ↔ Paris :: Italy ↔ ___”</li> </ul> <p>This constitutes a relational edit, rather than a local one. You reshape an entire conceptual subspace.</p> <p>This is similar to full relation editing or changing an embedding direction like “country→capital.”</p> <p>In summary:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Local rewrites fix a pocket of meaning. 
Distributed edits alter the semantic landscape.
</code></pre></div></div> <p>Both are important and can create contradictions.</p> <h2 id="does-editing-introduce-inconsistency">Does Editing Introduce Inconsistency?</h2> <p>Human beliefs can be modular and inconsistent, while neural networks are more globally connected.</p> <p>This creates a challenge:</p> <ul> <li>Overly local edits cause the model to revert to the old fact under rephrasing.</li> <li>Overly global edits distort unrelated knowledge (identity drift).</li> </ul> <p>For example:</p> <ul> <li>Correcting a wrong fact might unintentionally alter analogy patterns.</li> <li>Changing a persona (like making the assistant sarcastic) could affect unrelated topics.</li> </ul> <p>A helpful distinction:</p> <ul> <li>Epistemic content refers to what the model believes (facts).</li> <li>Ontological structure refers to the types of concepts and relationships the model recognizes.</li> </ul> <p>A good edit should change epistemic content without harming ontology.</p> <p>In simpler terms:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Edit the belief, not the overall worldview.
</code></pre></div></div> <p>Current methods often struggle to maintain this balance.</p> <h2 id="can-a-neural-network-ever-truly-forget">Can a Neural Network Ever Truly “Forget”?</h2> <p>For humans, forgetting can take various forms:</p> <ul> <li>deletion</li> <li>suppression</li> <li>reconsolidation</li> <li>interference</li> </ul> <p>In neural networks, forgetting is a strange idea.</p> <p>There is no slot to erase or pointer to zero out. Knowledge is redundantly encoded <d-cite key="frankle2019lottery"></d-cite> across many layers and modules.</p> <p>To forget the fact: “The Eiffel Tower is in Paris,” you would need to disrupt all the attractor pathways leading to “Paris.”</p> <p>But because:</p> <ul> <li>representations are redundant,</li> <li>associations are intertwined,</li> <li>learned structures are densely distributed,</li> </ul> <p>a single update rarely wipes out all paths.</p> <p>This explains why edited facts often come back <d-cite key="goodfellow2013empirical"></d-cite>:</p> <ul> <li>under rephrasing,</li> <li>in lengthy contexts,</li> <li>through analogy paths,</li> <li>under tricky prompts.</li> </ul> <p>So:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Forgetting in neural networks isn’t about destruction; it’s about reducing the chance of a belief coming back.
</code></pre></div></div> <p>Philosophically, this is more like suppression than deletion.</p> <h2 id="the-ontology-of-edited-models-does-editing-change-identity">The Ontology of Edited Models: Does Editing Change Identity?</h2> <p>Model identity isn’t defined by the dataset but by:</p> <ul> <li>behavior</li> <li>coherence</li> <li>decision tendencies</li> <li>inductive biases</li> </ul> <p>Editing can change these.</p> <p>Small edits (like a single factual relationship) usually do not alter identity. However, large or repeated edits such as changing tone, worldview, or moral views can create a distinctly different agent.</p> <p>Example:</p> <ul> <li>turning a friendly assistant into a sarcastic persona,</li> <li>shifting political leanings <d-cite key="olah2020circuits"></d-cite>,</li> <li>imposing a strict safety rule that leads to reasoning changes.</li> </ul> <p>This relates to the Ship of Theseus problem:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>After many edits, is it still the same model?
</code></pre></div></div> <p>From an engineering perspective:</p> <ul> <li>the model is “the same” if its functional behavior remains stable</li> <li>“different” if the relational structure or persona changes.</li> </ul> <p>From a philosophical perspective:</p> <ul> <li>identity ties to the model’s internal ontology.</li> <li>Changing high-level relational geometry equals changing identity.</li> </ul> <h2 id="why-this-matters-beyond-bug-fixes">Why This Matters: Beyond Bug-Fixes</h2> <p>A theory of editing matters because it relates to:</p> <h3 id="safety">Safety</h3> <p>Local edits may unintentionally create global contradictions.</p> <h3 id="alignment">Alignment</h3> <p>Changing epistemic content could distort ontological foundations, altering what the model values.</p> <h3 id="interpretability">Interpretability</h3> <p>Editing enables us to examine the model’s structure: we find out which relationships are fragile or deep.</p> <h3 id="delegated-autonomy">Delegated Autonomy</h3> <p>If a model is part of a workflow or agent system, shifts in identity can undermine trust.</p> <h3 id="scientific-understanding">Scientific Understanding</h3> <p>Editing provides insight into how neural networks represent meaning and change knowledge.</p> <h2 id="a-research-aware-conceptual-taxonomy-of-model-edits">A Research-Aware Conceptual Taxonomy of Model Edits</h2> <p>Here is an improved taxonomy, now enhanced with examples and basic connections to known methods:</p> <p><strong>Type-1. Local Semantic Rewrites</strong></p> <p>Small, targeted changes to micro-manifolds. This roughly corresponds to methods like ROME or MEMIT that aim for precise, fact-level edits.</p> <p><strong>Type-2. Distributed Relational Shifts</strong></p> <p>Edits that affect entire relational subspaces (for example, altering all country→capital pairs). These can be seen in behavior changes after broader fine-tuning or multi-example edits.</p> <p><strong>Type-3. Ontological Reorientations</strong></p> <p>Changes that affect how the model organizes concepts (for instance, safety-alignment fine-tunes that reshape moral or intentional concepts). These often occur as a side effect of broad, domain-specific training.</p> <p><strong>Type-4. Identity-Level Modifications</strong></p> <p>Edits that change persona, reasoning style, or core behavioral tendencies. Example: turning a neutral assistant into one that is consistently sarcastic. This is typical in instruction tuning, reinforcement learning from human feedback, or safety training.</p> <p>This taxonomy is conceptual, but it connects to real methods <d-cite key="hartford2024ke-survey"></d-cite>, grounding philosophy in current practice.</p> <h2 id="conclusion--editing-knowledge--editing-memory">Conclusion — Editing Knowledge ≠ Editing Memory</h2> <p>We circle back to the question:</p> <p>What does it mean to change knowledge in a neural network?</p> <p>The refined answer:</p> <ul> <li>Facts are not stored; they are acted upon as transformations.</li> <li>Editing involves changing geometry, not memory.</li> <li>Forgetting is about reducing probability, not deleting.</li> <li>Local changes can result in global contradictions.</li> <li>Edits can shift not only beliefs but also identity.</li> <li>Maintaining ontological stability is just as important as epistemic correctness.</li> </ul> <p>A practical implication is:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Evaluating model edits should assess not only factual accuracy but also identity shifts and ontological changes.
</code></pre></div></div> <p>Ultimately:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Model editing is not just a technical tool. It is a philosophical act involving decisions about how an artificial mind should evolve.
</code></pre></div></div> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/2026/assets/bibliography/2026-04-27-philosophy-of-model-editing.bib"></d-bibliography> <d-article> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/fairness-audits/">Fairness Audits as Theater: When Metrics Mask Structural Harm</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/fans/">FANS - Frequency-Adaptive Noise Shaping for Diffusion Models</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/why-vlms-waste-their-vision/">Why vlms waste their vision</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/wait-do-we-need-to-wait/">Wait, Do We Need to Wait? Revisiting Budget Forcing for Sequential Test-Time Scaling</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/visual-reversal-curse-from-general-domain-to-remote-sensing-images/">Visual Reversal Curse: From General Domain to Remote Sensing Images</a> </li> <br> <br> </d-article> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 ICLR Blog. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/2026/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script src="/2026/assets/js/distillpub/overrides.js"></script> <script defer src="https://cdn.jsdelivr.net/npm/mermaid@10.7.0/dist/mermaid.min.js" integrity="sha256-TtLOdUA8mstPoO6sGvHIGx2ceXrrX4KgIItO06XOn8A=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/d3@7.8.5/dist/d3.min.js" integrity="sha256-1rA678n2xEx7x4cTZ5x4wpUCj6kUMZEZ5cxLSVSFWxw=" crossorigin="anonymous"></script> <script defer src="/2026/assets/js/mermaid-setup.js?38ca0a0126f7328d2d9a46bad640931f" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/2026/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/2026/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/2026/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/2026/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/2026/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/2026/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/2026/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/2026/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/2026/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/2026/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/2026/assets/js/search-data.js"></script> <script src="/2026/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>