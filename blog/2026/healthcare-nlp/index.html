<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> When SOTA Meets Reality: Lessons from Deploying NLP at a Large Healthcare Organization | ICLR Blogposts 2026 </title> <meta name="author" content="ICLR Blog"> <meta name="description" content="In academia, we optimize for accuracy. In healthcare, we optimize for patient outcomes. This is the story of how a large healthcare organization reduced a multi-year backlog not by using the largest or newest model, but by using the right one."> <meta name="keywords" content="machine-learning, ml, deep-learning, reinforcement-learning, icl# add your own keywords or leave empty"> <link rel="stylesheet" href="/2026/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/2026/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/2026/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/2026/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/2026/assets/img/iclr_favicon.ico?0a8a3afdb0dbe139723b24dba3052a4f"> <link rel="stylesheet" href="/2026/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://iclr-blogposts.github.io/2026/blog/2026/healthcare-nlp/"> <script src="/2026/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/2026/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <script src="/2026/assets/js/distillpub/template.v2.js"></script> <script src="/2026/assets/js/distillpub/transforms.v2.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "When SOTA Meets Reality: Lessons from Deploying NLP at a Large Healthcare Organization",
            "description": "In academia, we optimize for accuracy. In healthcare, we optimize for patient outcomes. This is the story of how a large healthcare organization reduced a multi-year backlog not by using the largest or newest model, but by using the right one.",
            "published": "April 27, 2026",
            "authors": [
              
              {
                "author": "Anonymous",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/2026/"> ICLR Blogposts 2026 </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/2026/">home </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/about/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/call/">call for blogposts </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/submitting/">submitting </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/reviewing/">reviewing </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">past iterations </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2026/"><strong>2026</strong></a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2025/">2025</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2024/">2024</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2023/">2023</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blog-track.github.io/home/" rel="external nofollow noopener" target="_blank">2022</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>When SOTA Meets Reality: Lessons from Deploying NLP at a Large Healthcare Organization</h1> <p>In academia, we optimize for accuracy. In healthcare, we optimize for patient outcomes. This is the story of how a large healthcare organization reduced a multi-year backlog not by using the largest or newest model, but by using the right one.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#introduction">Introduction</a> </div> <div> <a href="#the-metric-trap">The Metric Trap</a> </div> <div> <a href="#do-not-use-a-cannon-to-kill-a-fly">Do Not Use a Cannon to Kill a Fly</a> </div> <div> <a href="#data-quality-is-everything">Data Quality is Everything</a> </div> <div> <a href="#error-handling-and-system-design">Error Handling and System Design</a> </div> <div> <a href="#privacy-as-an-architectural-constraint">Privacy as an Architectural Constraint</a> </div> <div> <a href="#co-design-and-ai-literacy">Co-Design and AI Literacy</a> </div> <div> <a href="#the-dare-framework">The DARE Framework</a> </div> <div> <a href="#conclusion">Conclusion</a> </div> </nav> </d-contents> <h2 id="introduction">Introduction</h2> <p>The gap between a Jupyter notebook and a hospital server is not just a matter of deployment engineering, it is a fundamental conflict of objectives.</p> <p>Machine learning researchers are trained to chase the upper bounds of performance metrics. We want the highest F1-score, the lowest perplexity, or the top spot on a leaderboard. But at the {Anonymous Healthcare Organization}, where our team processes millions of pathology reports to track cancer incidence and patient outcomes, we learned that a “perfect” model can still fail to solve the actual problem.</p> <p>Over the course of four years, we deployed various NLP models, from simple regex patterns to fine-tuned BERT-type <d-cite key="devlin2019bert"></d-cite> models and Large Language Models (LLMs), for tasks including tumor reportability classification, cancer relapse detection, anatomical site identification, automated staging, and report segmentation.</p> <p>This post shares the unvarnished reality of what worked, what didn’t, and why the gap between research innovation and real-world healthcare deployment is wider than most people think.</p> <h2 id="the-metric-trap">The Metric Trap</h2> <p>In standard machine learning tasks, we define success as maximizing a metric like accuracy, F1-score, or Area Under the Curve (AUC). However, in {Anonymous Healthcare Organization’s} production pipeline, the cost functions are asymmetric and tied to human labor rather than model statistics.</p> <p>Consider our task of <em>Reportable Tumor Identification</em>, which involves determining which pathology reports contain cancers that must be tracked and reported. In the academic view, the goal is simply to maximize the F1-score by balancing precision and recall. But the operational reality is far more complex. Every “Positive” prediction triggers a manual review by a highly trained tumor registrar to finalize the case, while every “Negative” is archived. This creates a high-stakes environment where false negatives result in missed cancer cases, but false positives flood registrars with irrelevant reports, leading to burnout.</p> <p>We discovered that the metric that actually mattered was <em>Time Saved Per Report</em>. When we analyzed the operational data, the results were counterintuitive. Using our older (purely rule-based) NLP system, for every 1000 true positives, we will get 400 false positives. Manual processing by registrars takes about one minute per report, leading to 1400 minutes of work. Using the updated system with language models, we were able to bring down the false positives to 100, leading to a total 1100 reports compared to 1400. If we had only focused on filtering, the savings would be modest. However, by designing the model to perform <em>sentence-level highlighting</em>, pinpointing the exact evidence for its decision, we reduced the human review time from 60 seconds to 30 seconds per report.</p> <p>The result was a total processing time of 550 minutes, a nearly 60% reduction in workload. This highlighted a critical reality: a model with lower theoretical accuracy that integrates effectively into the human workflow (via explainability features) is vastly more valuable than a “State of the Art” black box that achieves marginally higher accuracy but offers no assistive utility.</p> <blockquote> <p><strong>The Lesson:</strong> Don’t just optimize for accuracy; optimize for the bottleneck. While ML experts measure success by accuracy and ROC curves, organizations measure success by backlog reduction. A tool that aids interpretability often yields higher utility than a “black box” with marginally higher accuracy.</p> </blockquote> <h2 id="do-not-use-a-cannon-to-kill-a-fly">Do Not Use a Cannon to Kill a Fly</h2> <p>With the current hype surrounding Generative AI <d-cite key="leaver2023chatgpt"></d-cite>, there is enormous pressure to throw an LLM at every text processing problem. In our experience, this approach is often computationally wasteful, prone to hallucinations, and less robust than simpler methods. We advocate for a <em>Pragmatic Hybrid Architecture</em>, essentially a waterfall approach where data flows through progressively more sophisticated models only when necessary.</p> <pre><code class="language-mermaid">graph TD
    A[Pathology Report] --&gt; B{Text Analysis}
    
    B --&gt;|Structured Data&lt;br/&gt;dates, codes, staging| C[Layer 1: Regex]
    B --&gt;|Semantic Understanding&lt;br/&gt;classification tasks| D[Layer 2: BERT]
    B --&gt;|Complex/Ambiguous&lt;br/&gt;8-12% of cases| E[Layer 3: LLM]
    
    C --&gt;|High precision&lt;br/&gt;instant processing| F[Extracted Structured Data]
    D --&gt;|High accuracy&lt;br/&gt;fast processing| G[Classification Result]
    E --&gt;|High accuracy&lt;br/&gt;slow, complex reasoning| H[Nuanced Analysis]
    
    F --&gt; I[Final Output]
    G --&gt; I
    H --&gt; I
    
    style A fill:#e8f4f8,stroke:#333,stroke-width:2px
    style C fill:#aed6f1,stroke:#333,stroke-width:2px
    style D fill:#a9dfbf,stroke:#333,stroke-width:2px
    style E fill:#f9e79f,stroke:#333,stroke-width:2px
    style I fill:#f5b7b1,stroke:#333,stroke-width:2px
    
    classDef layer1 fill:#aed6f1,stroke:#333,stroke-width:2px
    classDef layer2 fill:#a9dfbf,stroke:#333,stroke-width:2px
    classDef layer3 fill:#f9e79f,stroke:#333,stroke-width:2px
</code></pre> <div class="caption"> Figure 1: Our pragmatic hybrid architecture processes reports through layers of increasing sophistication, reserving expensive models for genuinely difficult cases. </div> <p><br></p> <p>The first line of defense is what we call the <em>“Boring Layer”</em>: regular expressions. For structured data like dates, histology codes, or tumor staging notation (e.g., “T1N0M0”), regex provides 100% precision with zero hallucinations. It is fast, cheap, and explainable. Extracting “Grade 3” from a standardized field does not require a GPU.</p> <p>When semantic understanding is required, such as distinguishing between a patient’s history of cancer versus a current diagnosis, we escalate to the <em>“Efficient Layer”</em>. Here, fine-tuned BERT-type models (like Gatortron <d-cite key="yang2022gatortron"></d-cite> or ClinicalBERT <d-cite key="alsentzer2019publicly"></d-cite>) excel. These smaller, domain-specific models often outperform general-purpose LLMs on focused classification tasks while costing a fraction of the computational budget <d-cite key="gu2021domain"></d-cite>.</p> <p>We reserve the <em>“Smart Layer”</em>: Generative AI, for the 8-12% of cases that are genuinely ambiguous, require complex reasoning, or involve summarization. This represents a small fraction of our volume but handles the edge cases where simpler methods fail.</p> <p>Crucially, we found that <em>Report Segmentation</em> was an unsung hero. Pathology reports are filled with noisy headers, disclaimers, and legal text. Using a lightweight model to strip this noise and feed only the relevant diagnostic text to downstream models improved performance more than simply scaling up the model size. As is often the case, better preprocessing beats bigger parameters <d-cite key="smelyakov2020effectiveness"></d-cite>.</p> <blockquote> <p><strong>The Lesson:</strong> Model selection should be pragmatic, not trendy. Match the complexity of the method to the complexity of the problem. If a regex works, use it. Preprocessing (segmentation) often delivers higher ROI than increasing parameter count.</p> </blockquote> <h2 id="data-quality-is-everything">Data Quality is Everything</h2> <p>In academic datasets, labels are usually treated as ground truth. In healthcare, we learned that labels are often opinions. When we analyzed our initial training data, we found that label noise was a massive bottleneck; models trained on a single annotator’s data were essentially learning that specific person’s biases rather than the medical truth.</p> <p>To fix this, we recommend a <em>consensus-based approach</em>. Where we define a “Code Book”: a living document of annotation guidelines. We ran pilot studies where multiple experts labeled the same reports, and where they disagreed, we held discussions to refine the definitions. If human experts cannot agree on the label for a specific report, a model has no chance of learning it correctly.</p> <p>We also had to contend with the reality that medical data is not static. Terminology evolves, and reporting formats change. A model trained on 2019 pathology reports will inevitably struggle with 2024 reports using new classifications from the governing bodies (WHO, NHS, etc.).</p> <pre><code class="language-mermaid">graph LR
    A[Training Data&lt;br/&gt;2019-2020] --&gt; B[Model Training]
    B --&gt; C[High Accuracy&lt;br/&gt;95%]
    C --&gt; D[Deployment]
    D --&gt; E[2021 Data&lt;br/&gt;92% accuracy]
    E --&gt; F[2022 Data&lt;br/&gt;88% accuracy]
    F --&gt; G[2023 Data&lt;br/&gt;85% accuracy]
    
    style A fill:#90EE90
    style C fill:#90EE90
    style E fill:#FFD700
    style F fill:#FFA500
    style G fill:#FF6347
</code></pre> <div class="caption"> Figure 2: Without continuous monitoring, model performance degrades over time as medical terminology shifts. </div> <p><br></p> <p>This necessitated <em>Automated Drift Detection</em>. By monitoring prediction distributions, confidence scores, and with human-in-the-loop approach, we can detect when the model becomes less confident or when the data distribution shifts, signaling a need for retraining.</p> <blockquote> <p><strong>The Lesson:</strong> Data quality and representativeness matter more than model sophistication. Invest in a “Code Book” and consensus processes early. Expect your drift in your data, and build monitoring systems that alert you when it does.</p> </blockquote> <h2 id="error-handling-and-system-design">Error Handling and System Design</h2> <p>No model is perfect, and in healthcare, “hallucination” is not just a quirk, it’s a liability. We learned that the reliability of a system depends less on eliminating every error and more on how the system handles those errors when they inevitably occur.</p> <p>We implemented <em>Confidence-Based Routing</em> to manage this risk. High-confidence predictions are processed automatically, while low-confidence predictions are flagged for human review (human-in-the-loop). Furthermore, if a report looks drastically different from the training data (out-of-distribution), it defaults to the manual queue.</p> <pre><code class="language-mermaid">graph TD
    A[Incoming Report] --&gt; B{Confidence Score}
    B --&gt;|High Confidence| C[Automated Processing]
    B --&gt;|Low Confidence| D[Human Review Queue]
    C --&gt; E{Audit Sample}
    E --&gt;|Random Sample| F[Quality Check]
    E --&gt;|Pass Through| G[Production Database]
    F --&gt; H{Discrepancy?}
    H --&gt;|Yes| I[Flag for Investigation]
    H --&gt;|No| G
    D --&gt; J[Expert Review]
    J --&gt; G
</code></pre> <div class="caption"> Figure 3: Multi-layer error mitigation pipeline combining confidence-based routing, human-in-the-loop validation, and continuous auditing. </div> <p><br></p> <p>To ensure long-term safety, we adopted a <em>clinical-trial design approach to auditing</em>. Rather than ad-hoc spot checks, we established a rigorous sampling protocol to estimate error rates with statistical significance. Routinely, we conduct a structured audit to ensure the model hasn’t silently degraded. Trust in AI is not built on a single high accuracy score, but on the assurance that the system knows when it doesn’t know.</p> <blockquote> <p><strong>The Lesson:</strong> Accept that errors will happen and design your system to handle them gracefully. Confidence thresholds, human-in-the-loop validation, and statistically rigorous auditing are essential for reliable healthcare AI systems.</p> </blockquote> <h2 id="privacy-as-an-architectural-constraint">Privacy as an Architectural Constraint</h2> <p>When working with sensitive patient data, privacy cannot be an afterthought; it must be a fundamental architectural constraint. Large Language Models have a known propensity to memorize training data, which poses a catastrophic risk in a healthcare organization. If an adversary could query a model to reconstruct an individual’s data, we would have failed our patients.</p> <p>To mitigate this, we rely primarily on <em>local, open-weights models</em> (like Llama or Mistral) hosted entirely within our firewall. Sending patient data to a public API is simply not an option for us. Additionally, where possible, we integrated <em>Differential Privacy (DP)</em> <d-cite key="dwork2006differential"></d-cite> into our training pipeline. DP provides a mathematical guarantee that individual patient data cannot be reverse-engineered from the model weights, but it degrades utility. In scenarios where high utility is desired, in addition to locally hosted models, the models are only trained on fully anonymized data.</p> <blockquote> <p><strong>The Lesson:</strong> Privacy must be integrated into the development lifecycle, not added at the end. Prefer local, offline models for sensitive data, and evaluate the trade-off between Differential Privacy guarantees, model utility, and data anonymization.</p> </blockquote> <h2 id="co-design-and-ai-literacy">Co-Design and AI Literacy</h2> <p>We had a significant structural advantage, being a large healthcare organization, our team includes ML researchers, tumor registrars, other subject matter experts, and clinicians working side-by-side.</p> <p>This collaboration forced a critical pivot in our project. Initially, our goal was purely technical: “Create an NLP solution that is 99% accurate.” However, after sitting down with other stakeholders and understanding their daily struggles, we realized that accuracy wasn’t their primary pain point. Their problem was the <em>24-month backlog</em> due to them being inundated with data.</p> <p>We revised our goal to “Reduce the backlog by 50%,” which changed our entire technical roadmap. Instead of building a black-box classifier to replace humans, we built an assistive tool that highlights evidence to speed them up.</p> <pre><code class="language-mermaid">graph TB
    NLP[NLP System]
    
    subgraph End Users
        TR[Subject Matter Experts]
    end
    
    subgraph Clinical Experts
        ONC[Clinicians]
    end
    
    subgraph Technical Team
        ML[ML Researchers]
        IT[IT Infrastructure]
    end
    
    subgraph Governance
        PRIV[Privacy Officers]
        ADMIN[Administrators]
    end
    
    NLP --- TR
    NLP --- ONC
    NLP --- ML
    NLP --- IT
    NLP --- PRIV
    NLP --- ADMIN
    
    TR -.workflow needs.-&gt; ML
    ONC -.clinical validation.-&gt; ML
    ML -.technical specs.-&gt; IT
    IT -.infrastructure constraints.-&gt; ML
    PRIV -.compliance requirements.-&gt; ML
    ADMIN -.resource allocation.-&gt; ML
    
    style NLP fill:#e74c3c,stroke:#333,stroke-width:3px,color:#fff
    style TR fill:#3498db,stroke:#333,stroke-width:2px
    style ONC fill:#e67e22,stroke:#333,stroke-width:2px
    style ML fill:#2ecc71,stroke:#333,stroke-width:2px
    style IT fill:#2ecc71,stroke:#333,stroke-width:2px
    style PRIV fill:#f39c12,stroke:#333,stroke-width:2px
    style ADMIN fill:#f39c12,stroke:#333,stroke-width:2px
</code></pre> <div class="caption"> Figure 4: Successful deployment required alignment across multiple groups within the organization, each with different priorities and expertise. </div> <p><br></p> <p>This co-design process also required investing in <em>AI Literacy</em> <d-cite key="yi2021establishing"></d-cite>. We couldn’t just drop an AI tool on clinical staff and walk away; we had to teach them how the models worked, where they failed, and why they made certain predictions. When domain experts understand the “black box,” they trust it more and become better at catching its errors.</p> <blockquote> <p><strong>The Lesson:</strong> Involve end-users from Day 1. Co-designing the solution ensures you are solving the business problem (backlogs), not just a technical problem. Furthermore, educating your users about AI capabilities and limitations builds the trust required for adoption.</p> </blockquote> <h2 id="the-dare-framework">The DARE Framework</h2> <p>Many healthcare organizations lack in-house ML expertise and opt to buy off-the-shelf AI tools. This is often risky, as a vendor’s “99% accuracy” claim is usually based on their clean, curated dataset, not your messy real-world data.</p> <p>To help organizations navigate this “Build vs. Buy” decision, we propose the <strong>DARE framework</strong>:</p> <ul> <li> <strong>D - Demand Robust Validation:</strong> Do not accept whitepapers as proof. Demand validation on <em>your</em> local data distribution. Vendors should be willing to run their model on your data to prove it works in your specific context.</li> <li> <strong>A - Assess Flexibility:</strong> Can the tool handle your specific quirks, such as local report formatting or unique abbreviations? Can it be fine-tuned when standards change?</li> <li> <strong>R - Rigorous Internal Compatibility:</strong> Does the tool introduce fairness biases regarding your specific patient demographics? Does it integrate seamlessly with your existing IT infrastructure?</li> <li> <strong>E - Ease of Evaluation:</strong> Avoid black boxes. Can you audit the logs? Does it provide confidence scores? Can clinical staff override the AI when needed?</li> </ul> <blockquote> <p><strong>The Lesson:</strong> Be skeptical of “plug-and-play” AI. Use the DARE framework to validate vendor claims on <em>your</em> specific data before committing resources.</p> </blockquote> <h2 id="conclusion">Conclusion</h2> <p>The journey from academic machine learning to deployed healthcare AI requires rethinking many of our ingrained instincts. We learned that the solution saving the most time isn’t always the one with the highest accuracy on a held-out test set, and that “boring” tools like regex often outperform the latest LLMs on structured tasks.</p> <p>Most importantly, we learned that deployment cannot be an afterthought. It requires deep collaboration between researchers and domain experts to ensure we are solving the right problems. By prioritizing workflows over metrics, respecting data privacy as a hard constraint, and demanding rigorous validation, we can bridge the gap between research and production.</p> <p>In machine learning conferences, SOTA means topping the benchmark. In healthcare, true SOTA is a system that runs reliably, respects patient privacy, and clears the backlog so patients get treated faster.</p> <p><strong>The real SOTA is AI that works.</strong></p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/2026/assets/bibliography/2026-04-27-healthcare-nlp.bib"></d-bibliography> <d-article> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/fairness-audits/">Fairness Audits as Theater: When Metrics Mask Structural Harm</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/fans/">FANS - Frequency-Adaptive Noise Shaping for Diffusion Models</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/why-vlms-waste-their-vision/">Why vlms waste their vision</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/wait-do-we-need-to-wait/">Wait, Do We Need to Wait? Revisiting Budget Forcing for Sequential Test-Time Scaling</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/visual-reversal-curse-from-general-domain-to-remote-sensing-images/">Visual Reversal Curse: From General Domain to Remote Sensing Images</a> </li> <br> <br> </d-article> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 ICLR Blog. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/2026/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script src="/2026/assets/js/distillpub/overrides.js"></script> <script defer src="https://cdn.jsdelivr.net/npm/mermaid@10.7.0/dist/mermaid.min.js" integrity="sha256-TtLOdUA8mstPoO6sGvHIGx2ceXrrX4KgIItO06XOn8A=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/d3@7.8.5/dist/d3.min.js" integrity="sha256-1rA678n2xEx7x4cTZ5x4wpUCj6kUMZEZ5cxLSVSFWxw=" crossorigin="anonymous"></script> <script defer src="/2026/assets/js/mermaid-setup.js?38ca0a0126f7328d2d9a46bad640931f" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/2026/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/2026/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/2026/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/2026/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/2026/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/2026/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/2026/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/2026/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/2026/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/2026/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/2026/assets/js/search-data.js"></script> <script src="/2026/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>