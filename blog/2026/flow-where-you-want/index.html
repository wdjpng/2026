<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Flow Where You Want | ICLR Blogposts 2026 </title> <meta name="author" content="ICLR Blog"> <meta name="description" content="This tutorial demonstrates how to add inference-time controls to pretrained flow-based generative models. Using an unconditional MNIST flow model, we apply classifier guidance and inpainting by adding velocity corrections during sampling. We also explore PnP-Flow, which satisfies constraints through iterative projection rather than velocity correction."> <meta name="keywords" content="machine-learning, ml, deep-learning, reinforcement-learning, icl# add your own keywords or leave empty"> <link rel="stylesheet" href="/2026/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/2026/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/2026/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/2026/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/2026/assets/img/iclr_favicon.ico?0a8a3afdb0dbe139723b24dba3052a4f"> <link rel="stylesheet" href="/2026/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://iclr-blogposts.github.io/2026/blog/2026/flow-where-you-want/"> <script src="/2026/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/2026/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <script src="/2026/assets/js/distillpub/template.v2.js"></script> <script src="/2026/assets/js/distillpub/transforms.v2.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Flow Where You Want",
            "description": "This tutorial demonstrates how to add inference-time controls to pretrained flow-based generative models. Using an unconditional MNIST flow model, we apply classifier guidance and inpainting by adding velocity corrections during sampling. We also explore PnP-Flow, which satisfies constraints through iterative projection rather than velocity correction.",
            "published": "April 27, 2026",
            "authors": [
              
              {
                "author": "Anonymous Authors",
                "authorURL": "https://en.wikipedia.org",
                "affiliations": [
                  {
                    "name": "Anonymous Institution",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/2026/"> ICLR Blogposts 2026 </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/2026/">home </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/about/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/call/">call for blogposts </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/submitting/">submitting </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/reviewing/">reviewing </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">past iterations </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2026/"><strong>2026</strong></a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2025/">2025</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2024/">2024</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2023/">2023</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blog-track.github.io/home/" rel="external nofollow noopener" target="_blank">2022</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Flow Where You Want</h1> <p>This tutorial demonstrates how to add inference-time controls to pretrained flow-based generative models. Using an unconditional MNIST flow model, we apply classifier guidance and inpainting by adding velocity corrections during sampling. We also explore PnP-Flow, which satisfies constraints through iterative projection rather than velocity correction.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#introduction">Introduction</a> </div> <ul> <li> <a href="#the-latent-flow-matching-setup">The Latent Flow-Matching Setup</a> </li> <li> <a href="#projecting-and-correcting">Projecting and Correcting</a> </li> <li> <a href="#mathematical-details">Mathematical Details</a> </li> </ul> <div> <a href="#classifier-guidance">Classifier Guidance</a> </div> <ul> <li> <a href="#setup-the-models">Setup the Models</a> </li> <li> <a href="#train-a-latent-classifier">Train a Latent Classifier</a> </li> <li> <a href="#latents-only-guidance">Latents-Only Guidance</a> </li> </ul> <div> <a href="#inpainting">Inpainting</a> </div> <ul> <li> <a href="#pixel-space-inpainting">Pixel Space Inpainting</a> </li> <li> <a href="#latent-space-inpatining">Latent Space Inpatining</a> </li> <li> <a href="#pnp-flow-guidance-by-any-other-name">PnP-Flow: Guidance By Any Other Name</a> </li> </ul> <div> <a href="#summary">Summary</a> </div> </nav> </d-contents> <div style="text-align: center; margin: 0;"> Anonymized Colab Link: <a href="https://colab.research.google.com/drive/1QkU7NB3eqlPijv1b5GKuC97qdBUzzDVc?usp=sharing" target="_" rel="external nofollow noopener"> <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" style="display: inline-block;"></a> </div> <h1 id="introduction">Introduction</h1> <p>In this tutorial, we’ll explore inference-time “plugin” methods for flow matching and rectified flow generative models like FLUX or Stable Audio Open Small. Unlike classifier-free guidance (CFG) <d-cite key="cfg"></d-cite>, which requires training the model with your desired conditioning signal, these plugin guidance methods let you add controls at inference time—even for conditions the model never saw during training.</p> <p>This tutorial assumes familiarity with flow-based generative models, by which we mean “flow matching” <d-cite key="lipman2023flow"></d-cite> and/or “rectified flows” <d-cite key="rectified_flow"></d-cite>. See the blog post <a href="https://drscotthawley.github.io/blog/posts/FlowModels.html" rel="external nofollow noopener" target="_blank">“Flow With What You Know”</a> <d-cite key="hawley2025flowwithwhat"></d-cite> for an overview, and/or my IJCNN 2025 tutorial <d-cite key="hawley_practical"></d-cite> for further detail. The key insight is that flow models generate samples through iterative integration, and at each step we can add small velocity corrections to steer toward specific goals. This works for various objectives: generating specific classes, filling in missing regions, or satisfying other desired constraints.</p> <p>Our discussion will bring us up to date on guidance methods for latent-space rectified flow models. While there’s an extensive literature on guidance for diffusion models <d-cite key="daras2024survey"></d-cite><d-cite key="ye2024tfg"></d-cite> – see Sander Dieleman’s excellent blog post <d-cite key="dieleman2022guidance"></d-cite> for an overview — flow matching allows us to cast these in a more accessible and intuitive way. There’s some recent work unifying guidance for diffusion and flows <d-cite key="zander_greedy"></d-cite>, but in this tutorial we’ll focus on a simplified treatment for flows only.</p> <p>The paradigm of latent generative models is covered in another superb Dieleman post <d-cite key="dieleman2025latents"></d-cite>, and combining latent-space models with flow-based guidance gives us powerful, flexible tools for adding flexible controls to efficient generation.</p> <p>Let’s review the picture for flow-based generative modeling in latent space…</p> <p>Let’s review the picture for flow-based generative modeling in latent space…</p> <h2 id="the-latent-flow-matching-setup">The Latent Flow-Matching Setup</h2> <p>The following diagrams illustrate the three key concepts:</p> <p><strong>a)</strong> A VAE compresses pixel-space images into compact latent representations. “E” is for encoder and “D” is for decoder:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-flow-where-you-want/vae_flow_diag-VAE.svg" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-flow-where-you-want/vae_flow_diag-VAE.svg" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p><strong>b)</strong> The flow model operates in this latent space, transforming noise (“Source”, t=0) into structured data (“Target”, t=1) through iterative integration. The decoder then converts the final latents back to pixels.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-flow-where-you-want/vae_flow_diag-Generation.drawio.svg" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-flow-where-you-want/vae_flow_diag-Generation.drawio.svg" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p><strong>c)</strong> While general flows can follow curved trajectories, some of our methods will focus on flows with nearly straight trajectories which allows for estimating endpoints without many integration steps:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-flow-where-you-want/vae_flow_diag-FlowTypes.drawio.svg" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-flow-where-you-want/vae_flow_diag-FlowTypes.drawio.svg" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>These (nearly) straight trajectories can be obtained by “ReFlow” distillation of another model (covered in <d-cite key="rectified_flow"></d-cite><d-cite key="hawley2025flowwithwhat"></d-cite> or by insisting during training that the models yield paths agreeing with Optimal Transport such as the “minibatch OT” method of Tong et al <d-cite key="tong2024improving"></d-cite>. Even if the model’s trajectories aren’t super-straight, we’ll see that the guidance methods we use can be applied fairly generally anyway.</p> <h2 id="projecting-and-correcting">Projecting and Correcting</h2> <p>Intuitively, guidance amounts to “steering” during the integration of the flow model in order to end up at a desired end point. The <a href="https://bsky.app/profile/drscotthawley.bsky.social/post/3m3df2idqrc2g" rel="external nofollow noopener" target="_blank">following video</a> provides a useful metaphor:</p> <p>The analogy’s not quite right: you can’t just steer, you are going to have to paddle a little bit. In other words, you’re going to have to provide a bit of a <em>extra velocity</em> to correct the where the “current” flow is taking you.</p> <p>In flow matching, we go from a source data (distribution) at time \(t=0\) to target data at \(t=1\). Since this tutorial applies to latent space, we’ll use the letter \(z\) for position, such as \(z_t\) being the position at time \(t\).</p> <p>When you’re “looking ahead” to estimate where you’ll end up, you project linearly along the current velocity \(\vec{v_t}\) for a duration of the remaining time. Let’s call this estimate \(\widehat{z_1}\), your projected endpoint :</p> \[\widehat{z_1} = z_t + (1-t)\vec{v_t}\tag{1}\] <p>…but perhaps that’s not where you want to go. Where you want to go is a distance \(\Delta \widehat{z_1}\) from \(\widehat{z_1}\), and to get there you’ll have to make a”course correction” \(\Delta \hat{v}\), as shown in the following diagram:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-flow-where-you-want/guidance_vectors-480.webp 480w,/2026/assets/img/2026-04-27-flow-where-you-want/guidance_vectors-800.webp 800w,/2026/assets/img/2026-04-27-flow-where-you-want/guidance_vectors-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-flow-where-you-want/guidance_vectors.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>By similar triangles, \(\Delta \widehat{z_1} = (1-t)\Delta \vec{v}\), which means the course correction you want is</p> \[\Delta \vec{v} = { \Delta \widehat{z_1} \over 1-t }.\] <p>TODO: math callout</p> <h3 id="mathematical-details">Mathematical Details</h3> <p><em>Since you’re going to more math once you try to read the scholarly literature on these topics, let’s go a bit further into the math…</em></p> <p>So \(\Delta \widehat{z_1}\) is a measure of the <em>deviation</em> from the desired endpoint. Now, in practical application we won’t actually use the “distance” \(\Delta \widehat{z_1}\), but we’ll use something that functions <em>like</em> a distance, such as a K-L divergence or Mean Squared Error (MSE), which are familiar loss functions from neural network training.</p> <p>When doing inference, this deviation serves the same function as a “loss” does when training models something we will seek to minimize – via gradient descent! – except we’ll vary the flow positions \(z\) instead of the model weights. More specifically, we’ll consider the “likelihood” \(p( \widehat{z_1} | y )\) of getting a \(z_1\) that matches a given control \(y\), and we’ll seek to maximize that likelihood, or equivalently to <em>minimize the negative</em> log-likelihood.</p> <p>The expression \(-\nabla_{\widehat{z_1}} \log p( \widehat{z_1} | y )\) essentially answers the question, “in which direction should I adjust \(\widehat{z_1}\) so as to make \(p( \widehat{z_1} | y )\) more likely? Just like with gradient descent when training a network, this gives us a direction and a magnitude, which we then multiply by a “guidance strength” \(\eta\) (similar to a “learning rate” for gradient descent) to turn it into a step size.</p> <p>TODO: end callout</p> <p>Applying this gradient-based approach, our expression for $\Delta v$ will involve replacing $\Delta \widehat{z_1}$ in (2) with $- \eta \nabla_{\widehat{z_1}} \log p( \widehat{z_1} | y$:</p> \[\Delta \vec{v} = - \eta {1 \over 1-t } \nabla_{z_t} \log p( \widehat{z_1} | y ) \tag{3}\] <p>where we used the fact that $\nabla_{\widehat{z_1}} = \nabla_{z_t}$ (since $\widehat{z_1} \propto z_t$). The factor of $1/(1-t)$ means small corrections suffice early on, but later times require larger adjustments—though other time scalings are possible, as we’ll see.</p> <p>Now let’s apply this to a concrete example.</p> <h2 id="classifier-guidance">Classifier Guidance</h2> <p>If we want our model to generate a member of a particular class, we can use an external classifier to examine the generated samples. The constraint to minimize will be the difference between the desired class and the <code class="language-plaintext highlighter-rouge">argmax</code> of the classifier output (or some similar relationship that enforces the class compliance).</p> <p>For our flow model, we’ll use <a href="https://github.com/Ocrabit/dl_class_projects/blob/main/dl_experimentation/submissions/marco_submission.py" rel="external nofollow noopener" target="_blank">the winning submission</a> from the <a href="https://2025-dlaie-leaderboard.streamlit.app/" rel="external nofollow noopener" target="_blank">2025 DLAIE Leaderboard Contest</a> on unconditional latent flow matching of MNIST digits. For the classifier, we’ll use the <a href="https://github.com/DLAIE/2025-LeaderboardContest/blob/main/evaluate_submission.py" rel="external nofollow noopener" target="_blank">official evaluation classifier</a> from the same contest.</p> <h3 id="setup-the-flow-model-and-classifier">Setup the Flow Model and Classifier</h3> <p>Let’s generate and draw some sample images.</p> <details> <summary>Show Code</summary> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">torchvision.utils</span> <span class="kn">import</span> <span class="n">make_grid</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># generate some samples
</span><span class="n">n_samples</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">x1</span> <span class="o">=</span> <span class="n">sub</span><span class="p">.</span><span class="nf">generate_samples</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">n_samples</span><span class="p">)</span>
<span class="n">x1</span><span class="p">.</span><span class="n">shape</span>


<span class="k">def</span> <span class="nf">show_grid</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">x1</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span> <span class="n">x1</span> <span class="o">=</span> <span class="n">x1</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># add channels dim
</span>    <span class="n">grid</span> <span class="o">=</span> <span class="nf">make_grid</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">nrow</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="n">grid</span><span class="p">.</span><span class="nf">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">).</span><span class="nf">cpu</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">gray</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">axis</span><span class="p">(</span><span class="sh">'</span><span class="s">off</span><span class="sh">'</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">title</span><span class="p">:</span> <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="nf">show_grid</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="sh">"</span><span class="s">Sample generated images</span><span class="sh">"</span><span class="p">)</span></code></pre></figure> </details> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-flow-where-you-want/gen_image_row_1-480.webp 480w,/2026/assets/img/2026-04-27-flow-where-you-want/gen_image_row_1-800.webp 800w,/2026/assets/img/2026-04-27-flow-where-you-want/gen_image_row_1-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-flow-where-you-want/gen_image_row_1.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>Now we’ll setup the (pretrained) classifier we’ll use for the guidance: Let’s make a plot showing the classifier’s output probabilities (aka likelihoods) across all classes, for all 10 samples. The samples will be the rows, and the class-likelihoods outputs from the classifier will be the columns, where brightness is correlated with likelihood.</p> <details><summary>Show Code</summary> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">show_probs</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">show probs as colormap intensities via imshow.
    have each row be a sample and each column be a class probability</span><span class="sh">"""</span>
    <span class="n">ncols</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="bp">None</span> <span class="k">else</span> <span class="mi">2</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">ncols</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span> <span class="n">axs</span> <span class="o">=</span> <span class="p">[</span><span class="n">axs</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>  <span class="c1"># show a little version of the x image for each row
</span>        <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">imshow</span><span class="p">(</span><span class="nf">make_grid</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="nf">cpu</span><span class="p">(),</span> <span class="n">nrow</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="nf">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">).</span><span class="nf">cpu</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">gray</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">axis</span><span class="p">(</span><span class="sh">'</span><span class="s">off</span><span class="sh">'</span><span class="p">)</span>

    <span class="c1"># show probabilities as an intensity map
</span>    <span class="n">im</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="n">ncols</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="nf">imshow</span><span class="p">(</span><span class="n">probs</span><span class="p">.</span><span class="nf">cpu</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">gray</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">ncols</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Class</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">ncols</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Sample #</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="n">ncols</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>

<span class="nf">show_probs</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x1</span><span class="p">)</span></code></pre></figure> </details> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-flow-where-you-want/show_probs_1-480.webp 480w,/2026/assets/img/2026-04-27-flow-where-you-want/show_probs_1-800.webp 800w,/2026/assets/img/2026-04-27-flow-where-you-want/show_probs_1-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-flow-where-you-want/show_probs_1.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>From the “random” distribution of generated digits, we see that this is an unconditional generative model: there’s nothing determining the classes of the outputs – until we add guidance, below! ;-) In a short while, we’ll reproduce that diagram, but we’ll use guidance to get one class per sample, in order, along the diagonal.</p> <p>To do that, we’re going to have to “break open” the generate_samples routine and even the integrate_path routine to allow us to add a correction to the velocity generated by the flow model at time . That correction will be based on the classifier’s output using the projected estimate of the final data, which we’ll obtain via linear extrapolation.</p> <p>In our latent space model, we flow with latents which must be decoded using the VAE’s decoder:</p> <p>\(\widehat{z_1} = z_t + (1-t) v_t\) \(\widehat{x_1} = D(\widehat{z_1})\)</p> <p>The correction $\Delta v$ will generated from a constraint which in this case is just like regular “classifier loss” function in a supervised learning problem. The desired class label is the “target” and the classifier output of the projected estimate is the “prediction”.</p> <p>Our code will follow this general layout:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">CrossEntropyLoss</span><span class="p">()</span>

<span class="n">v_t</span> <span class="o">=</span> <span class="nf">flow_model</span><span class="p">(</span><span class="n">z_t</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
<span class="n">z1_hat</span> <span class="o">=</span> <span class="n">z_t</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">t</span><span class="p">)</span><span class="o">*</span><span class="n">v_t</span>               <span class="c1"># projected destination
</span><span class="n">x1_hat</span> <span class="o">=</span> <span class="n">sub</span><span class="p">.</span><span class="n">vae</span><span class="p">.</span><span class="nf">decoder</span><span class="p">(</span><span class="n">z1_hat</span><span class="p">)</span>       <span class="c1"># decode it to pixel space
</span><span class="n">probs</span> <span class="o">=</span> <span class="nf">classify</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">x1_hat</span><span class="p">)</span>   <span class="c1"># classifer operates in pixel space
</span><span class="n">loss</span> <span class="o">=</span> <span class="nf">loss_fn</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>          <span class="c1"># "supervised learning"
</span><span class="n">delta_v</span> <span class="o">=</span> <span class="nf">magic_function</span><span class="p">(</span><span class="n">loss</span><span class="p">,...</span><span class="err">???</span><span class="p">)</span>  <span class="c1"># &lt;--- here's the part we need to work out
</span><span class="n">v_t</span> <span class="o">=</span> <span class="n">v_t</span> <span class="o">+</span> <span class="n">delta_v</span> <span class="o">*</span> <span class="n">guidance_strength</span>  <span class="c1"># we can set the strength of the correction</span></code></pre></figure> <p>To convert that <code class="language-plaintext highlighter-rouge">loss</code> into a “velocity,” we can take its gradient. When training a model, one typically takes the gradient with respect to the model weights. For inference-time guidance, however, we will take the gradient with respect to the flow coordinates $z$ in the latent space, thereby generating a vector in the latent space.</p> <p>PyTorch lets us compute the gradient with respect to anything (in the autograd graph). We just need to tell it what we want. And we need to be careful to make sure that the VAE and flow models stay frozen, so the only thing that’s allowed to change are the latents $z$.</p> <p>The cleanest way to pull this off, code-wise, is to create a function called <code class="language-plaintext highlighter-rouge">compute_v()</code> which for starters will just call the flow model, but then we’ll add to it with guidance info:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># wherever we used to just call flow_model(), we'll now call compute_v() instead
</span><span class="nd">@torch.no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">compute_v</span><span class="p">(</span><span class="n">flow_model</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">guidance_dict</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">v_t</span> <span class="o">=</span> <span class="nf">flow_model</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">guidance_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">v_t</span> <span class="o">+=</span> <span class="nf">compute_dv</span><span class="p">(</span><span class="n">v_t</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">guidance_dict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">v_t</span>

<span class="nd">@torch.enable_grad</span><span class="p">()</span>  <span class="c1"># &lt;-- later, this will be a key for getting guidance
</span><span class="k">def</span> <span class="nf">compute_dv</span><span class="p">(</span><span class="n">v_t</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">g</span><span class="p">:</span><span class="nb">dict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sh">"</span><span class="s">placeholder for now, will add guidance math later</span><span class="sh">"</span>
    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">v_t</span><span class="p">).</span><span class="nf">detach</span><span class="p">()</span> <span class="c1"># no correction yet; no gradients returned</span></code></pre></figure> <p>We’ll to use some typical “boilerplate” flow integration code, except we’ll add “<code class="language-plaintext highlighter-rouge">**kwargs</code>” everywhere so we can pass controls “all the way in” to the <code class="language-plaintext highlighter-rouge">compute_dv()</code> guidance routine, and pair <code class="language-plaintext highlighter-rouge">flow_model()</code> as an arg to <code class="language-plaintext highlighter-rouge">compute_v()</code> via <code class="language-plaintext highlighter-rouge">functools.partial</code>.</p> <details><summary>Show Flow Integration Code</summary> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">functools</span> <span class="kn">import</span> <span class="n">partial</span>  <span class="c1"># use partial to package flow_model with compute_v
</span>
<span class="nd">@torch.no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">rk4_step</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>  <span class="c1"># regular rk4, + kwargs passthrough
</span>    <span class="c1"># f: callable (y, t) -&gt; dy/dt
</span>    <span class="n">k1</span> <span class="o">=</span> <span class="nf">f</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">k2</span> <span class="o">=</span> <span class="nf">f</span><span class="p">(</span><span class="n">y</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">dt</span> <span class="o">*</span> <span class="n">k1</span><span class="p">,</span> <span class="n">t</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">dt</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">k3</span> <span class="o">=</span> <span class="nf">f</span><span class="p">(</span><span class="n">y</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">dt</span> <span class="o">*</span> <span class="n">k2</span><span class="p">,</span> <span class="n">t</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">dt</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">k4</span> <span class="o">=</span> <span class="nf">f</span><span class="p">(</span><span class="n">y</span> <span class="o">+</span> <span class="n">dt</span> <span class="o">*</span> <span class="n">k3</span><span class="p">,</span> <span class="n">t</span> <span class="o">+</span> <span class="n">dt</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y</span> <span class="o">+</span> <span class="p">(</span><span class="n">dt</span> <span class="o">/</span> <span class="mi">6</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">k1</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">k2</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">k3</span> <span class="o">+</span> <span class="n">k4</span><span class="p">)</span>

<span class="nd">@torch.no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">warp_time</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">dt</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="p">.</span><span class="mi">5</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Parametric Time Warping: s = slope in the middle.
        s=1 is linear time, s &lt; 1 goes slower near the middle, s&gt;1 goes slower near the ends
        s = 1.5 gets very close to the </span><span class="sh">"</span><span class="s">cosine schedule</span><span class="sh">"</span><span class="s">, i.e. (1-cos(pi*t))/2, i.e. sin^2(pi/2*x)</span><span class="sh">"""</span>
    <span class="k">if</span> <span class="n">s</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">s</span> <span class="o">&gt;</span> <span class="mf">1.5</span><span class="p">:</span> <span class="k">raise</span> <span class="nc">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">s=</span><span class="si">{</span><span class="n">s</span><span class="si">}</span><span class="s"> is out of bounds.</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">tw</span> <span class="o">=</span> <span class="mi">4</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">s</span><span class="p">)</span> <span class="o">*</span> <span class="n">t</span> <span class="o">**</span> <span class="mi">3</span> <span class="o">+</span> <span class="mi">6</span> <span class="o">*</span> <span class="p">(</span><span class="n">s</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">t</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="mi">3</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">s</span><span class="p">)</span> <span class="o">*</span> <span class="n">t</span>
    <span class="k">if</span> <span class="n">dt</span><span class="p">:</span>  <span class="c1"># warped time-step requested; use derivative
</span>        <span class="k">return</span> <span class="n">tw</span><span class="p">,</span> <span class="n">dt</span> <span class="o">*</span> <span class="mi">12</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">s</span><span class="p">)</span> <span class="o">*</span> <span class="n">t</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">12</span> <span class="o">*</span> <span class="p">(</span><span class="n">s</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">t</span> <span class="o">+</span> <span class="p">(</span><span class="mi">3</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">s</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tw</span>


<span class="nd">@torch.no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">integrate_path</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">initial_points</span><span class="p">,</span> <span class="n">step_fn</span><span class="o">=</span><span class="n">rk4_step</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">warp_fn</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">latent_2d</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">prog_bar</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">t0</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nf">next</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">())</span>
    <span class="n">device</span><span class="p">,</span> <span class="n">model_dtype</span> <span class="o">=</span> <span class="n">p</span><span class="p">.</span><span class="n">device</span><span class="p">,</span> <span class="n">p</span><span class="p">.</span><span class="n">dtype</span>
    <span class="n">current_points</span> <span class="o">=</span> <span class="n">initial_points</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">model_dtype</span><span class="p">).</span><span class="nf">clone</span><span class="p">()</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
    <span class="n">ts</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="n">t0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">model_dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">warp_fn</span><span class="p">:</span> <span class="n">ts</span> <span class="o">=</span> <span class="nf">warp_fn</span><span class="p">(</span><span class="n">ts</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">latent_2d</span><span class="p">:</span> <span class="n">t_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">empty</span><span class="p">((</span><span class="n">current_points</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">model_dtype</span><span class="p">)</span>
    <span class="n">vel_model</span> <span class="o">=</span> <span class="nf">partial</span><span class="p">(</span><span class="n">compute_v</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>  <span class="c1"># here's the secret sauce
</span>    <span class="n">iterator</span> <span class="o">=</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">ts</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">prog_bar</span><span class="p">:</span> <span class="n">iterator</span> <span class="o">=</span> <span class="nf">tqdm</span><span class="p">(</span><span class="n">iterator</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sh">"</span><span class="s">Integrating Path</span><span class="sh">"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">iterator</span><span class="p">:</span>
        <span class="n">t</span><span class="p">,</span> <span class="n">dt</span> <span class="o">=</span> <span class="n">ts</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">ts</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">ts</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">latent_2d</span><span class="p">:</span> <span class="n">t</span> <span class="o">=</span> <span class="n">t_batch</span><span class="p">.</span><span class="nf">fill_</span><span class="p">(</span><span class="n">t</span><span class="p">.</span><span class="nf">item</span><span class="p">())</span>
        <span class="n">current_points</span> <span class="o">=</span> <span class="nf">step_fn</span><span class="p">(</span><span class="n">vel_model</span><span class="p">,</span> <span class="n">current_points</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">current_points</span>

<span class="k">def</span> <span class="nf">generate_samples</span><span class="p">(</span><span class="n">sub</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">z0</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">t0</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
    <span class="n">z0</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">([</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">sub</span><span class="p">.</span><span class="n">latent_dim</span><span class="p">]).</span><span class="nf">to</span><span class="p">(</span><span class="n">sub</span><span class="p">.</span><span class="n">device</span><span class="p">)</span> <span class="k">if</span> <span class="n">z0</span> <span class="ow">is</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">z0</span>
    <span class="n">z1</span> <span class="o">=</span> <span class="nf">integrate_path</span><span class="p">(</span><span class="n">sub</span><span class="p">.</span><span class="n">flow_model</span><span class="p">,</span> <span class="n">z0</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="n">n_steps</span><span class="p">,</span> <span class="n">step_fn</span><span class="o">=</span><span class="n">rk4_step</span><span class="p">,</span> <span class="n">t0</span><span class="o">=</span><span class="n">t0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">gen_xhat</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">sigmoid</span><span class="p">(</span><span class="n">sub</span><span class="p">.</span><span class="nf">decode</span><span class="p">(</span><span class="n">z1</span><span class="p">).</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">gen_xhat</span></code></pre></figure> </details> <p>Now that we know that works, let’s “supe up” <code class="language-plaintext highlighter-rouge">compute_dv()</code> to include the guidance correction. We’ll use the <code class="language-plaintext highlighter-rouge">torch.autograd.grad()</code> function to compute the gradient of the loss.<br> First we have the <code class="language-plaintext highlighter-rouge">guidance_dict</code> that we’ll use to pass through our intentions through the various layers of routines to get to <code class="language-plaintext highlighter-rouge">compute_dv()</code>:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">guidance_dict</span> <span class="o">=</span> \
    <span class="p">{</span><span class="sh">'</span><span class="s">classifier</span><span class="sh">'</span><span class="p">:</span> <span class="n">classifier</span><span class="p">,</span>     <span class="c1"># the classifier model to use
</span>    <span class="sh">'</span><span class="s">decode</span><span class="sh">'</span><span class="p">:</span> <span class="n">sub</span><span class="p">.</span><span class="n">decode</span><span class="p">,</span>         <span class="c1"># how to decode to pixel space for classifier
</span>    <span class="sh">'</span><span class="s">loss_fn</span><span class="sh">'</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="sh">'</span><span class="s">none</span><span class="sh">'</span><span class="p">),</span> <span class="c1"># don't sum over batch dim
</span>    <span class="sh">'</span><span class="s">target</span><span class="sh">'</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>  <span class="c1"># desired class outcomes
</span>    <span class="sh">'</span><span class="s">strength</span><span class="sh">'</span><span class="p">:</span> <span class="mf">5.0</span><span class="p">,</span>              <span class="c1"># "guidance strength", you may vary this
</span>    <span class="sh">'</span><span class="s">t_min</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span> <span class="sh">'</span><span class="s">t_max</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.99</span><span class="p">,</span> <span class="c1"># t range to apply guidance, may vary these
</span>    <span class="p">}</span></code></pre></figure> <p>Next we have the fully-equipped <code class="language-plaintext highlighter-rouge">compute_dv()</code>. This code is overly-commented to make it easy to follow each step. (We replaced <code class="language-plaintext highlighter-rouge">guidance_dict</code> with <code class="language-plaintext highlighter-rouge">g</code> locally for brevity.) No other changes to any preceding code are necessary. We’ll be ready to do guided inference after this definition!</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nd">@torch.enable_grad</span><span class="p">()</span>  <span class="c1"># &lt;-- Needed to compute gradients if calling code has @torch.no_grad()
</span><span class="k">def</span> <span class="nf">compute_dv</span><span class="p">(</span><span class="n">v_t</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">g</span><span class="p">:</span><span class="nb">dict</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">debug</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="sh">"</span><span class="s">Compute the guidance correction to the flow velocity</span><span class="sh">"</span>
    <span class="k">if</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="n">g</span><span class="p">[</span><span class="sh">'</span><span class="s">t_min</span><span class="sh">'</span><span class="p">]</span> <span class="ow">or</span> <span class="n">t</span> <span class="o">&gt;</span> <span class="n">g</span><span class="p">[</span><span class="sh">'</span><span class="s">t_max</span><span class="sh">'</span><span class="p">]:</span> <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">v_t</span><span class="p">).</span><span class="nf">detach</span><span class="p">()</span>
    <span class="n">z</span><span class="p">.</span><span class="nf">requires_grad_</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>                   <span class="c1"># need to enable gradient tracking for z
</span>    <span class="n">z1_hat</span> <span class="o">=</span> <span class="n">z</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span> <span class="o">*</span> <span class="n">v_t</span>               <span class="c1"># linear projection to estimated endpoint
</span>
    <span class="c1"># Decoding to pixel space (if decoder provided)
</span>    <span class="n">x1_hat</span> <span class="o">=</span> <span class="n">z1_hat</span> <span class="k">if</span> <span class="n">g</span><span class="p">[</span><span class="sh">'</span><span class="s">decode</span><span class="sh">'</span><span class="p">]</span> <span class="ow">is</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">F</span><span class="p">.</span><span class="nf">sigmoid</span><span class="p">(</span><span class="n">g</span><span class="p">[</span><span class="sh">'</span><span class="s">decode</span><span class="sh">'</span><span class="p">](</span><span class="n">z1_hat</span><span class="p">)).</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>

    <span class="n">logits</span><span class="p">,</span> <span class="n">probs</span> <span class="o">=</span> <span class="nf">classify</span><span class="p">(</span><span class="n">g</span><span class="p">[</span><span class="sh">'</span><span class="s">classifier</span><span class="sh">'</span><span class="p">],</span> <span class="n">x1_hat</span><span class="p">)</span>          <span class="c1"># run classifier
</span>    <span class="n">loss</span> <span class="o">=</span> <span class="n">g</span><span class="p">[</span><span class="sh">'</span><span class="s">loss_fn</span><span class="sh">'</span><span class="p">](</span><span class="n">logits</span><span class="p">,</span> <span class="n">g</span><span class="p">[</span><span class="sh">'</span><span class="s">target</span><span class="sh">'</span><span class="p">][:</span><span class="nf">len</span><span class="p">(</span><span class="n">logits</span><span class="p">)])</span>     <span class="c1"># loss &lt;-&gt; "negative log likelihood"
</span>
    <span class="c1"># Compute grad wrt z. "grad_outputs=": don't sum over over batch, keep unique to each datum
</span>    <span class="n">grad_z</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">autograd</span><span class="p">.</span><span class="nf">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">grad_outputs</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">ones_like</span><span class="p">(</span><span class="n">loss</span><span class="p">),</span> <span class="n">retain_graph</span><span class="o">=</span><span class="bp">False</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">dv</span> <span class="o">=</span> <span class="o">-</span><span class="n">grad_z</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">t</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span>   <span class="c1"># - minimizes, (1-t) makes it velocity, eps helps stability
</span>
    <span class="n">z</span><span class="p">.</span><span class="nf">requires_grad_</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>        <span class="c1"># cleanup (z is a tensor so local changes could propagate)
</span>    <span class="k">return</span> <span class="n">g</span><span class="p">[</span><span class="sh">'</span><span class="s">strength</span><span class="sh">'</span><span class="p">]</span> <span class="o">*</span> <span class="n">dv</span><span class="p">.</span><span class="nf">detach</span><span class="p">()</span>  <span class="c1"># detach so no gradients returned</span></code></pre></figure> <p>Let’s now generate using classifier guidance on the flow model, and visualize the results:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># for reproducibility as we change other things
</span><span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
   <span class="n">x1</span> <span class="o">=</span> <span class="nf">generate_samples</span><span class="p">(</span><span class="n">sub</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">guidance_dict</span><span class="o">=</span><span class="n">guidance_dict</span><span class="p">,</span> <span class="n">debug</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
   <span class="n">logits</span><span class="p">,</span> <span class="n">probs</span> <span class="o">=</span> <span class="nf">classify</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">x1</span><span class="p">)</span>
<span class="nf">show_probs</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x1</span><span class="p">)</span></code></pre></figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-flow-where-you-want/show_probs_2-480.webp 480w,/2026/assets/img/2026-04-27-flow-where-you-want/show_probs_2-800.webp 800w,/2026/assets/img/2026-04-27-flow-where-you-want/show_probs_2-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-flow-where-you-want/show_probs_2.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>Excellent! That was our desired goal: consecutive classes along the diagonal.</p> <p>To get a better survey of the guidance capabilities, let’s make a 10x10 grid of outputs with classes along each column:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">).</span><span class="nf">repeat</span><span class="p">(</span><span class="mi">10</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="c1">#  [0,1,2,..9, 0,1,2,..9, ...]
</span><span class="n">guidance_dict</span><span class="p">[</span><span class="sh">'</span><span class="s">target</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">target</span>
<span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>         <span class="c1"># (optional) for reproducibility
</span><span class="n">x1</span> <span class="o">=</span> <span class="nf">generate_samples</span><span class="p">(</span><span class="n">sub</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="nf">len</span><span class="p">(</span><span class="n">target</span><span class="p">),</span> <span class="n">guidance_dict</span><span class="o">=</span><span class="n">guidance_dict</span><span class="p">)</span>
<span class="nf">show_grid</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="sh">"</span><span class="s">Guided samples</span><span class="sh">"</span><span class="p">)</span></code></pre></figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-flow-where-you-want/class_guidance_grid-480.webp 480w,/2026/assets/img/2026-04-27-flow-where-you-want/class_guidance_grid-800.webp 800w,/2026/assets/img/2026-04-27-flow-where-you-want/class_guidance_grid-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-flow-where-you-want/class_guidance_grid.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>That worked fine, and on a GPU it’s pretty fast, but on systems with only a CPU, it’s <em>painfully</em> slow. So instead, let’s…</p> <h2 id="train-a-latent-classifier">Train a Latent Classifier</h2> <p>We’ll train a model <code class="language-plaintext highlighter-rouge">z_classifier</code> that looks only in latent space, so we can use it as a guidance signal. This can be a very simple model consisting of a few <code class="language-plaintext highlighter-rouge">Linear</code> layers:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">LatentClassNet</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">latent_dim</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">dims</span> <span class="o">=</span> <span class="p">[</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">ModuleList</span><span class="p">([</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">in_d</span><span class="p">,</span> <span class="n">out_d</span><span class="p">)</span> <span class="k">for</span> <span class="n">in_d</span><span class="p">,</span> <span class="n">out_d</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">dims</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dims</span><span class="p">[</span><span class="mi">1</span><span class="p">:])])</span>   
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="p">:</span> <span class="n">z</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">leaky_relu</span><span class="p">(</span><span class="nf">layer</span><span class="p">(</span><span class="n">z</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">z</span>

<span class="n">z_classifier</span> <span class="o">=</span> <span class="nc">LatentClassNet</span><span class="p">().</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span></code></pre></figure> <p>This classifier will operate on <em>latent</em> encodings of the MNIST dataset. So let’s save the encoded latents to disk and load them into memory. These will be our training and test data.</p> <details><summary>Show Code</summary> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1">#| code-fold: true
</span>
<span class="c1"># You can probably skip this code block. It just runs MNIST
# through the VAE's encoder and saves it to disk. 
</span>
<span class="kn">from</span> <span class="n">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TensorDataset</span><span class="p">,</span> <span class="n">Subset</span>
<span class="kn">from</span> <span class="n">torchvision.datasets</span> <span class="kn">import</span> <span class="n">MNIST</span>
<span class="kn">from</span> <span class="n">torchvision.transforms</span> <span class="kn">import</span> <span class="n">ToTensor</span>
<span class="kn">from</span> <span class="n">glob</span> <span class="kn">import</span> <span class="n">glob</span> 
<span class="kn">import</span> <span class="n">math</span> 

<span class="nd">@torch.no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">encode_dataset</span><span class="p">(</span><span class="n">vae</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">chunk_size</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">tag</span><span class="o">=</span><span class="sh">"</span><span class="s">train</span><span class="sh">"</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Encode dataset into VAE latents (z = mu), saving progress in temp chunk files.
    We use temp chunks in case execution gets interrupted, we can try again &amp; resume. 
    </span><span class="sh">"""</span>
    <span class="n">device</span> <span class="o">=</span> <span class="nf">next</span><span class="p">(</span><span class="n">vae</span><span class="p">.</span><span class="nf">parameters</span><span class="p">()).</span><span class="n">device</span>
    <span class="n">total_chunks</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="nf">ceil</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">/</span> <span class="n">chunk_size</span><span class="p">)</span> 
    <span class="c1"># check for existing chunk files 
</span>    <span class="n">basename</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">tmp_chunk_</span><span class="si">{</span><span class="n">tag</span><span class="si">}</span><span class="sh">"</span>
    <span class="n">chunk_files</span> <span class="o">=</span> <span class="nf">glob</span><span class="p">(</span><span class="n">basename</span><span class="o">+</span><span class="sh">'</span><span class="s">*.pt</span><span class="sh">'</span><span class="p">)</span> 
    <span class="n">existing_chunks</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">chunk_files</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">tag</span><span class="si">}</span><span class="s">: Found </span><span class="si">{</span><span class="n">existing_chunks</span><span class="si">}</span><span class="s"> of </span><span class="si">{</span><span class="n">total_chunks</span><span class="si">}</span><span class="s"> expected chunks. Generating remaining...</span><span class="sh">"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">existing_chunks</span><span class="p">,</span> <span class="n">total_chunks</span><span class="p">):</span> 
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">chunk </span><span class="si">{</span><span class="n">c</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">total_chunks</span><span class="si">}</span><span class="s">:</span><span class="sh">"</span><span class="p">,</span><span class="n">end</span><span class="o">=</span><span class="sh">""</span><span class="p">)</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">c</span><span class="o">*</span><span class="n">chunk_size</span><span class="p">,</span> <span class="p">(</span><span class="n">c</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">chunk_size</span> <span class="p">))</span>
        <span class="n">data_subset</span> <span class="o">=</span> <span class="nc">Subset</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>        
        <span class="n">loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">data_subset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="n">all_latents</span><span class="p">,</span> <span class="n">all_labels</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="n">must_flatten</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
                <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">=</span><span class="sh">"</span><span class="p">,</span><span class="n">end</span><span class="o">=</span><span class="sh">""</span><span class="p">)</span> <span class="c1"># dumb progress bar 
</span>                <span class="n">x</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="c1"># next bit is so it should work with linear layers or conv
</span>                <span class="k">if</span> <span class="n">must_flatten</span> <span class="ow">is</span> <span class="bp">None</span> <span class="ow">or</span> <span class="n">must_flatten</span><span class="o">==</span><span class="bp">False</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span> <span class="n">z</span><span class="p">,</span> <span class="n">must_flatten</span> <span class="o">=</span> <span class="n">vae</span><span class="p">.</span><span class="nf">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">False</span>
                    <span class="k">except</span> <span class="nb">RuntimeError</span><span class="p">:</span>
                        <span class="n">z</span> <span class="o">=</span> <span class="n">vae</span><span class="p">.</span><span class="nf">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
                        <span class="n">must_flatten</span> <span class="o">=</span> <span class="bp">True</span>
                <span class="k">else</span><span class="p">:</span> <span class="n">z</span> <span class="o">=</span> <span class="n">vae</span><span class="p">.</span><span class="nf">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
                <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="n">z</span>
                <span class="n">all_latents</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">mu</span><span class="p">.</span><span class="nf">cpu</span><span class="p">())</span>
                <span class="n">all_labels</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="n">chunk_latents</span><span class="p">,</span> <span class="n">chunk_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">(</span><span class="n">all_latents</span><span class="p">),</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">(</span><span class="n">all_labels</span><span class="p">)</span>
        <span class="n">tmp_filename</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">basename</span><span class="si">}</span><span class="s">_</span><span class="si">{</span><span class="n">c</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">.pt</span><span class="sh">"</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">|  Saving chunk to </span><span class="si">{</span><span class="n">tmp_filename</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        <span class="n">torch</span><span class="p">.</span><span class="nf">save</span><span class="p">({</span> <span class="sh">'</span><span class="s">latents</span><span class="sh">'</span><span class="p">:</span><span class="n">chunk_latents</span><span class="p">,</span> <span class="sh">'</span><span class="s">labels</span><span class="sh">'</span><span class="p">:</span><span class="n">chunk_labels</span> <span class="p">},</span> <span class="n">tmp_filename</span><span class="p">)</span>
    
    <span class="c1"># Assemble all the chunks from files and return tensors.
</span>    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Assembling</span><span class="sh">"</span><span class="p">,</span> <span class="n">basename</span><span class="o">+</span><span class="sh">'</span><span class="s">*.pt ...</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">all_latents</span><span class="p">,</span> <span class="n">all_labels</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">chunk_file</span> <span class="ow">in</span> <span class="nf">glob</span><span class="p">(</span><span class="n">basename</span><span class="o">+</span><span class="sh">'</span><span class="s">*.pt</span><span class="sh">'</span><span class="p">):</span> 
        <span class="n">chunk_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">chunk_file</span><span class="p">,</span> <span class="n">weights_only</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">all_latents</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">chunk_dict</span><span class="p">[</span><span class="sh">'</span><span class="s">latents</span><span class="sh">'</span><span class="p">])</span>
        <span class="n">all_labels</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">chunk_dict</span><span class="p">[</span><span class="sh">'</span><span class="s">labels</span><span class="sh">'</span><span class="p">])</span> 
    <span class="n">latents</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">(</span><span class="n">all_latents</span><span class="p">),</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">(</span><span class="n">all_labels</span><span class="p">)</span>
    <span class="c1">#for f in glob(tmp_file_base+'*.pt'): os.remove(f)   # clean up 
</span>    <span class="k">return</span> <span class="n">latents</span><span class="p">,</span> <span class="n">labels</span> 

<span class="k">def</span> <span class="nf">encode_mnist</span><span class="p">(</span><span class="n">vae</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">):</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Acquiring train &amp; test MNIST image datasets...</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">train_ds</span> <span class="o">=</span> <span class="nc">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="sh">'</span><span class="s">./data</span><span class="sh">'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>  <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="nc">ToTensor</span><span class="p">())</span>
    <span class="n">test_ds</span>  <span class="o">=</span> <span class="nc">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="sh">'</span><span class="s">./data</span><span class="sh">'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="nc">ToTensor</span><span class="p">())</span>
    
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="se">\n</span><span class="s">Encoding dataset to latents...</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">train_latents</span><span class="p">,</span> <span class="n">train_labels</span> <span class="o">=</span> <span class="nf">encode_dataset</span><span class="p">(</span><span class="n">vae</span><span class="p">,</span> <span class="n">train_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">tag</span><span class="o">=</span><span class="sh">'</span><span class="s">train</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">test_latents</span><span class="p">,</span> <span class="n">test_labels</span> <span class="o">=</span> <span class="nf">encode_dataset</span><span class="p">(</span><span class="n">vae</span><span class="p">,</span> <span class="n">test_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">tag</span><span class="o">=</span><span class="sh">'</span><span class="s">test</span><span class="sh">'</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="nf">glob</span><span class="p">(</span><span class="sh">'</span><span class="s">tmp_chunk_t*_c*.pt</span><span class="sh">'</span><span class="p">):</span> <span class="n">os</span><span class="p">.</span><span class="nf">remove</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>  <span class="c1"># clean up
</span>
    <span class="k">if</span> <span class="n">filename</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Saving to </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s"> ...</span><span class="sh">"</span><span class="p">)</span>
        <span class="n">torch</span><span class="p">.</span><span class="nf">save</span><span class="p">({</span> <span class="sh">'</span><span class="s">train_z</span><span class="sh">'</span><span class="p">:</span> <span class="n">train_latents</span><span class="p">,</span>     <span class="sh">'</span><span class="s">test_z</span><span class="sh">'</span><span class="p">:</span> <span class="n">test_latents</span><span class="p">,</span>
                     <span class="sh">'</span><span class="s">train_labels</span><span class="sh">'</span><span class="p">:</span> <span class="n">train_labels</span><span class="p">,</span> <span class="sh">'</span><span class="s">test_labels</span><span class="sh">'</span><span class="p">:</span> <span class="n">test_labels</span> <span class="p">},</span> <span class="n">filename</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">train_latents</span><span class="p">,</span> <span class="n">train_labels</span>


<span class="c1"># Encode the dataset
</span><span class="n">latent_data_filename</span> <span class="o">=</span> <span class="sh">'</span><span class="s">mnist_latents.pt</span><span class="sh">'</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">exists</span><span class="p">(</span><span class="n">latent_data_filename</span><span class="p">):</span>
    <span class="n">train_latents</span><span class="p">,</span> <span class="n">train_labels</span> <span class="o">=</span> <span class="nf">encode_mnist</span><span class="p">(</span><span class="n">sub</span><span class="p">.</span><span class="n">vae</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="n">latent_data_filename</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">load_data</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
    <span class="k">if</span> <span class="sh">'</span><span class="s">MyDrive</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">filename</span><span class="p">:</span>
        <span class="kn">from</span> <span class="n">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
        <span class="n">drive</span><span class="p">.</span><span class="nf">mount</span><span class="p">(</span><span class="sh">'</span><span class="s">/content/drive</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">data_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">weights_only</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">data_dict</span>

<span class="n">data_dict</span> <span class="o">=</span> <span class="nf">load_data</span><span class="p">(</span><span class="n">latent_data_filename</span><span class="p">)</span>
<span class="n">train_z</span><span class="p">,</span> <span class="n">test_z</span> <span class="o">=</span> <span class="n">data_dict</span><span class="p">[</span><span class="sh">'</span><span class="s">train_z</span><span class="sh">'</span><span class="p">],</span> <span class="n">data_dict</span><span class="p">[</span><span class="sh">'</span><span class="s">test_z</span><span class="sh">'</span><span class="p">]</span>
<span class="n">train_z</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">test_z</span><span class="p">.</span><span class="n">shape</span>

<span class="c1"># Create datasets from the latent tensors
</span><span class="n">train_latent_ds</span> <span class="o">=</span> <span class="nc">TensorDataset</span><span class="p">(</span><span class="n">train_z</span><span class="p">,</span> <span class="n">data_dict</span><span class="p">[</span><span class="sh">'</span><span class="s">train_labels</span><span class="sh">'</span><span class="p">][:</span><span class="n">train_z</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
<span class="n">test_latent_ds</span> <span class="o">=</span> <span class="nc">TensorDataset</span><span class="p">(</span><span class="n">test_z</span><span class="p">,</span> <span class="n">data_dict</span><span class="p">[</span><span class="sh">'</span><span class="s">test_labels</span><span class="sh">'</span><span class="p">])</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">train_latent_dl</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">train_latent_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">test_latent_dl</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">test_latent_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Train batches: </span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">train_latent_dl</span><span class="p">)</span><span class="si">}</span><span class="s">, Test batches: </span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">test_latent_dl</span><span class="p">)</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="c1"># print single latent size
</span><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Latent size: </span><span class="si">{</span><span class="n">train_latent_ds</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="n">shape</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span></code></pre></figure> </details> <p>Then we’ll run the training loop…</p> <details> <summary>Training Loop Code and Execution</summary> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Latent classifier training loop
</span><span class="n">optimizer</span>  <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">z_classifier</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>
<span class="n">criterion</span>  <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">8</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">z_classifier</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
    <span class="n">pbar</span> <span class="o">=</span> <span class="nf">tqdm</span><span class="p">(</span><span class="n">train_latent_dl</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="sh">"</span><span class="s">Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="sh">"</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">latents</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">:</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="nf">z_classifier</span><span class="p">(</span><span class="n">latents</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
        <span class="n">loss</span>   <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
        <span class="n">pbar</span><span class="p">.</span><span class="nf">set_postfix</span><span class="p">({</span><span class="sh">'</span><span class="s">train_loss</span><span class="sh">'</span><span class="p">:</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">})</span>
        <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
    
    <span class="c1"># Validation
</span>    <span class="n">z_classifier</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
    <span class="n">val_latents</span><span class="p">,</span> <span class="n">val_labels</span> <span class="o">=</span> <span class="nf">next</span><span class="p">(</span><span class="nf">iter</span><span class="p">(</span><span class="n">test_latent_dl</span><span class="p">))</span>
    <span class="n">val_logits</span> <span class="o">=</span> <span class="nf">z_classifier</span><span class="p">(</span><span class="n">val_latents</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
    <span class="n">val_loss</span>   <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">val_logits</span><span class="p">,</span> <span class="n">val_labels</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
    <span class="n">val_acc</span>    <span class="o">=</span> <span class="p">(</span><span class="n">val_logits</span><span class="p">.</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">val_labels</span><span class="p">).</span><span class="nf">float</span><span class="p">().</span><span class="nf">mean</span><span class="p">()</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s">: train_loss=</span><span class="si">{</span><span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">, val_loss=</span><span class="si">{</span><span class="n">val_loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">, val_acc=</span><span class="si">{</span><span class="n">val_acc</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span></code></pre></figure> ``` Epoch 1/8: train_loss=0.9673, val_loss=1.1017, val_acc=0.6211 Epoch 2/8: train_loss=0.1901, val_loss=0.1919, val_acc=0.9375 Epoch 3/8: train_loss=0.0512, val_loss=0.1205, val_acc=0.9570 Epoch 4/8: train_loss=0.1193, val_loss=0.1022, val_acc=0.9668 Epoch 5/8: train_loss=0.0810, val_loss=0.0948, val_acc=0.9648 Epoch 6/8: train_loss=0.1569, val_loss=0.0815, val_acc=0.9707 Epoch 7/8: train_loss=0.0504, val_loss=0.0841, val_acc=0.9629 Epoch 8/8: train_loss=0.0408, val_loss=0.0792, val_acc=0.9746 ``` </details> <p>Let’s test our newly-trained latent classifier, to make sure it works before trying to use it for guidance. We’ll pull up data samples with known ground-truth “target” labels, and compare these to the predictions from the classifier. If the targets and predictions match up, we’re good to go:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">z</span><span class="p">,</span> <span class="n">L</span> <span class="o">=</span> <span class="n">test_latent_ds</span><span class="p">[</span><span class="mi">20</span><span class="p">:</span><span class="mi">30</span><span class="p">]</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> 
<span class="nf">show_grid</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="nf">sigmoid</span><span class="p">(</span><span class="n">sub</span><span class="p">.</span><span class="nf">decode</span><span class="p">(</span><span class="n">z</span><span class="p">)).</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">))</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
    <span class="n">pred_class</span> <span class="o">=</span> <span class="nf">classify</span><span class="p">(</span><span class="n">z_classifier</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">use_argmax</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Target labels:   </span><span class="sh">"</span><span class="p">,</span><span class="n">L</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Predicted labels:</span><span class="sh">"</span><span class="p">,</span> <span class="n">pred_class</span><span class="p">.</span><span class="nf">cpu</span><span class="p">())</span></code></pre></figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-flow-where-you-want/gen_image_row_2-480.webp 480w,/2026/assets/img/2026-04-27-flow-where-you-want/gen_image_row_2-800.webp 800w,/2026/assets/img/2026-04-27-flow-where-you-want/gen_image_row_2-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-flow-where-you-want/gen_image_row_2.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Target labels:    tensor([9, 6, 6, 5, 4, 0, 7, 4, 0, 1])
Predicted labels: tensor([9, 6, 6, 5, 4, 0, 7, 4, 0, 1])
</code></pre></div></div> <p>Good! They match up. Let’s move on…</p> <h3 id="latents-only-guidance">Latents-Only Guidance</h3> <p>Now that we have a trained classifier that operates in latent space, we can run basically the same code as before, only it will execute wayyyyy faster…</p> <details><summary>Show Code</summary> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">guidance_dict</span> <span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">classifier</span><span class="sh">'</span><span class="p">:</span> <span class="n">z_classifier</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">decode</span><span class="sh">'</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span>    <span class="c1"># no decoding, latent space only
</span>                <span class="sh">'</span><span class="s">loss_fn</span><span class="sh">'</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="sh">'</span><span class="s">none</span><span class="sh">'</span><span class="p">),</span> <span class="c1"># don't sum across batch dim
</span>                <span class="sh">'</span><span class="s">target</span><span class="sh">'</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">).</span><span class="nf">repeat</span><span class="p">(</span><span class="mi">10</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
                <span class="sh">'</span><span class="s">strength</span><span class="sh">'</span><span class="p">:</span> <span class="mf">5.0</span><span class="p">,</span>   <span class="c1"># "guidance strength"
</span>                <span class="sh">'</span><span class="s">t_min</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span>  <span class="sh">'</span><span class="s">t_max</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.99</span><span class="p">,</span> <span class="p">}</span>

<span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span> <span class="c1"># remove for new samples each time
</span><span class="n">x1</span> <span class="o">=</span> <span class="nf">generate_samples</span><span class="p">(</span><span class="n">sub</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="nf">len</span><span class="p">(</span><span class="n">guidance_dict</span><span class="p">[</span><span class="sh">'</span><span class="s">target</span><span class="sh">'</span><span class="p">]),</span> <span class="n">guidance_dict</span><span class="o">=</span><span class="n">guidance_dict</span><span class="p">)</span>
<span class="nf">show_grid</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="sh">"</span><span class="s">Latent-Only Guidance</span><span class="sh">"</span><span class="p">)</span></code></pre></figure> </details> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-flow-where-you-want/latent_guidance_grid-480.webp 480w,/2026/assets/img/2026-04-27-flow-where-you-want/latent_guidance_grid-800.webp 800w,/2026/assets/img/2026-04-27-flow-where-you-want/latent_guidance_grid-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-flow-where-you-want/latent_guidance_grid.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>That executes very quickly, even on a CPU, and the results are just as good as before. Since we no longer have to propagate gradients through the much larger VAE decoder model and pixel-space classifer, we can get answers a lot faster via our small latents-only classifier.</p> <p>Let’s move on to another application of guidance, for which our guidance signal doesn’t depend on a separate trained (classifier) model at all: inpainting.</p> <h2 id="inpainting">Inpainting</h2> <p>When inpainting, we have some “mask” inside which some of the data have been removed, and we want to use the model to fill in the missing part in a way that matches with the surrounding pixels. Let’s take a look at an example from MNIST, where we show an original image, the mask and the masked-out image:</p> <details><summary>Show Code</summary> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">torchvision.datasets</span> <span class="kn">import</span> <span class="n">MNIST</span>
<span class="kn">from</span> <span class="n">torchvision.transforms</span> <span class="kn">import</span> <span class="n">ToTensor</span>

<span class="n">test_ds</span>  <span class="o">=</span> <span class="nc">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="sh">'</span><span class="s">./data</span><span class="sh">'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="nc">ToTensor</span><span class="p">())</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">test_ds</span><span class="p">[</span><span class="mi">7</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]</span>
<span class="n">M</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">([</span><span class="n">H</span><span class="p">,</span><span class="n">W</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="p">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>   <span class="c1"># 1 = keep pixels
</span><span class="n">M</span><span class="p">[</span><span class="n">H</span><span class="o">//</span><span class="mi">3</span><span class="p">:</span><span class="mi">2</span><span class="o">*</span><span class="n">H</span><span class="o">//</span><span class="mi">3</span><span class="p">,</span> <span class="n">W</span><span class="o">//</span><span class="mi">3</span><span class="p">:</span><span class="mi">2</span><span class="o">*</span><span class="n">W</span><span class="o">//</span><span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>                         <span class="c1"># 0 = mask out
</span><span class="n">x_masked</span> <span class="o">=</span> <span class="n">M</span><span class="o">*</span><span class="n">x</span>
<span class="nf">show_grid</span><span class="p">(</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">M</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">x_masked</span><span class="p">],</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span><span class="sh">"</span><span class="s">      Original      |      Mask      |  Masked Image</span><span class="sh">"</span> <span class="p">)</span></code></pre></figure> </details> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-flow-where-you-want/inp_mask_example-480.webp 480w,/2026/assets/img/2026-04-27-flow-where-you-want/inp_mask_example-800.webp 800w,/2026/assets/img/2026-04-27-flow-where-you-want/inp_mask_example-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-flow-where-you-want/inp_mask_example.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>Another example would be a picture of a face where you’ve blocked out the nose and you want the model to fill in a nose. Some of the “filling in” is obtained nearly “for free” because the model has only been exposed to data that satisfies the manifold or probability distribution of the training data – e.g. If it was trained on faces, then it only ever saw faces with noses and hence can only generate faces with noses – but the real trick is to do it “well” and have it be “good” in the end. ;-)</p> <p>There’s a wealth of information on guidance as it was originally applied to diffusion models. We recommend Sander Dieleman’s blog post, <a href="https://sander.ai/2022/05/26/guidance.html" rel="external nofollow noopener" target="_blank">“Guidance: a cheat code for diffusion models”</a>, for an extremly informative survey. Yet because of the stochastic/random nature of the diffusion path, there are several “complicating” aspects of diffusion guidance that we’re going to gloss over in this tutorial because in the case of deterministic, smooth flow-model trajectories, things become a lot more intuitive.</p> <p>We’ll follow a method outlined in the paper <a href="https://arxiv.org/abs/2310.04432" rel="external nofollow noopener" target="_blank">“Training-free Linear Image Inverses via Flows”</a> by Pokle et al, a methoda that applies to general linear inverse problems of which inpainting is a particular case, and we’ll simplify their method to adapt it for <em>just inpainting.</em></p> <p>The method involves generating an <em>entire</em> new image \(x_1\) that everywhere <em>outside the mask matches up</em> with the pixels in user-supplied (masked) image \(y4\). So the constraint will be, given a 2D mask \(M\) (where \(M\)=1 means there’s an original pixel there, and \(M\)=0 is the masked-out region), to require that our estimate image \(\widehat{x_1}\) (i.e. the decoded image version of the estimated latets \(\widehat{z_1}\) ) satisfies \(M*\widehat{x_1} = M* y\) <d-footnote>where "$*$" denotes the elementwise or Hadamard product</d-footnote>, or in a “residual form”, we’ll just compute the Mean Squared Error (MSE) of \(M*(\widehat{x_1}-y)\):</p> \[{\rm Constraint:} = M^2 * (\widehat{x_1}-y)^2\] <p>(and if we want, we can use the fact that \(M\) being a binary mask means \(M^2 = M\)).</p> <p>If we want to do latent-only inpainting (which will be the fastest), then the same constraint applies just with the simplification \(\widehat{x_1} = \widehat{z_1}\)</p> <p>The authors of the paper recommend only doing guidance from t equals 0.2 onward because prior to that, it’s hard to make any meaningful estimate.. In fact, they don’t even integrate before \(t = 0.2\). They just interpolate between the source and the target data to get their starting point at \(t = 0.2\).</p> <p>To use our constraint in the guidance equation (3) for computing \(\Delta v\,\), we’ll need to turn our constraint into a likelihood by raising it to an expontential power – so we get a Gaussian! But the guidance equation includes a logarithm that immediately <em>undoes</em> our exponentiation:</p> \[\Delta v = - {\eta \over 1-t} \nabla_{z_t}\ {\color{red}{\text{l̸o̸g̸}} \, \color{red}{\text{e̸x̸p̸}}} \left( M^2 * (\widehat{x_1}-y)^2 \right).\] <p>The gradient part is \(\nabla_{z_t} M^2 *(\widehat{x_1}-y)^2 = 2M^2*(\widehat{x_1}-y) {\partial \widehat{x_1} \over \partial z_t }\)</p> <p>If we’re inpainting in latent space and not using the decoder for the constraint, then \({\partial \widehat{x_1} / \partial z_t } = 1\). Otherwise that term will require evaluation via PyTorch’s <code class="language-plaintext highlighter-rouge">autograd</code> (=slow).</p> <p>Our earlier time scaling was \(\gamma_t = 1/(1-t)\); turns out that doesn’t work very well in practice when it comes to inpainting. Instead, we’ll use a different time scaling that delivers good (albeit not perfect) results: \(\gamma_t = (1-t)/t\).</p> <p>Thus our full equation for the velocity correction will be:</p> \[\Delta \vec{v} = -\eta\, \gamma_t\, M^2 *(\widehat{x_1} - y){\partial\widehat{x_1}\over\partial{z_t}}, \ \ \ \ \ \ \ \ \ \gamma_t = {1-t\over t}\] <p>where we absorbed the factor of 2 into \(\eta\), and the last partial derivitive term can be one if we do latent-only inpainting.</p> <p>Let’s implement this in code, using two different versions of the gradient calculation, depending on whether we can do it all in latent space or if we need to propagate gradients through the decoder:</p> <details><summary>Show Code</summary> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nd">@torch.no_grad</span><span class="p">()</span>  <span class="c1"># gradients computed analytically!
</span><span class="k">def</span> <span class="nf">ip_latents_grad</span><span class="p">(</span><span class="n">v_t</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">g</span><span class="p">:</span><span class="nb">dict</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sh">"</span><span class="s">gradients for latent-only inpainting, fast</span><span class="sh">"</span>
    <span class="n">z1_hat</span> <span class="o">=</span> <span class="n">z</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">t</span><span class="p">)</span><span class="o">*</span><span class="n">v_t</span>
    <span class="k">return</span> <span class="n">g</span><span class="p">[</span><span class="sh">'</span><span class="s">M_sq</span><span class="sh">'</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">z1_hat</span> <span class="o">-</span> <span class="n">g</span><span class="p">[</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">])</span>  <span class="c1">#  x1_hat = z1_hat, dz1_hat/dz_t=1
</span>
<span class="nd">@torch.enable_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">ip_pixels_grad</span><span class="p">(</span><span class="n">v_t</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">g</span><span class="p">:</span><span class="nb">dict</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sh">"</span><span class="s">gradients for pixel-space inpainting. need to use decoder &amp; track via autograd, = slow</span><span class="sh">"</span>
    <span class="n">z</span><span class="p">.</span><span class="nf">requires_grad_</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">z1_hat</span> <span class="o">=</span> <span class="n">z</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">t</span><span class="p">)</span><span class="o">*</span><span class="n">v_t</span>
    <span class="n">x1_hat</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">sigmoid</span><span class="p">(</span><span class="n">g</span><span class="p">[</span><span class="sh">'</span><span class="s">decode</span><span class="sh">'</span><span class="p">](</span><span class="n">z1_hat</span><span class="p">)).</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">)</span> <span class="c1"># TODO: un-hard-code img size
</span>    <span class="n">grad_x</span> <span class="o">=</span> <span class="n">g</span><span class="p">[</span><span class="sh">'</span><span class="s">M_sq</span><span class="sh">'</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">x1_hat</span> <span class="o">-</span> <span class="n">g</span><span class="p">[</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">])</span>
    <span class="n">grad_z</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">autograd</span><span class="p">.</span><span class="nf">grad</span><span class="p">(</span><span class="n">x1_hat</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">grad_outputs</span><span class="o">=</span><span class="n">grad_x</span><span class="p">,</span><span class="n">retain_graph</span><span class="o">=</span><span class="bp">False</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># mults grad_x by dx1_hat/dz1_hat
</span>    <span class="n">z</span><span class="p">.</span><span class="nf">requires_grad_</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">grad_z</span><span class="p">.</span><span class="nf">detach</span><span class="p">()</span>  <span class="c1"># don't send gradients onward
</span>
<span class="k">def</span> <span class="nf">t_timescale</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">timescale</span><span class="o">=</span><span class="sh">'</span><span class="s">mine</span><span class="sh">'</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sh">"</span><span class="s">our choice for adaptive time sacle</span><span class="sh">"</span>
    <span class="k">if</span> <span class="n">timescale</span> <span class="o">==</span><span class="sh">'</span><span class="s">simple</span><span class="sh">'</span><span class="p">:</span> <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">t</span><span class="p">)</span>                          <span class="c1"># our earlier scale; doesn't work
</span>    <span class="k">elif</span> <span class="n">timescale</span><span class="o">==</span><span class="sh">'</span><span class="s">pokle</span><span class="sh">'</span><span class="p">:</span> <span class="nf">return </span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">t</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">t</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">t</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>     <span class="c1"># from pokle et al; can't get it to work
</span>    <span class="k">elif</span> <span class="n">timescale</span><span class="o">==</span><span class="sh">'</span><span class="s">constant</span><span class="sh">'</span><span class="p">:</span> <span class="k">return</span> <span class="mi">4</span>  <span class="c1"># or any constant. The 4 is from Pokle et al
</span>    <span class="k">else</span><span class="p">:</span> <span class="nf">return </span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">t</span><span class="p">)</span><span class="o">/</span><span class="n">t</span>  <span class="c1"># This works pretty well! strong guidance at start -&gt; zero at end
</span>
<span class="k">def</span> <span class="nf">compute_dv_inpainting</span><span class="p">(</span><span class="n">v_t</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">g</span><span class="p">:</span><span class="nb">dict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sh">"</span><span class="s">wrapper to call appropriate gradient-computation routine</span><span class="sh">"</span>
    <span class="k">if</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="n">g</span><span class="p">[</span><span class="sh">'</span><span class="s">t_min</span><span class="sh">'</span><span class="p">]</span> <span class="ow">or</span> <span class="n">t</span> <span class="o">&gt;</span> <span class="n">g</span><span class="p">[</span><span class="sh">'</span><span class="s">t_max</span><span class="sh">'</span><span class="p">]:</span> <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">v_t</span><span class="p">)</span>
    <span class="n">grad_fn</span> <span class="o">=</span> <span class="n">ip_latents_grad</span> <span class="k">if</span> <span class="n">g</span><span class="p">[</span><span class="sh">'</span><span class="s">decode</span><span class="sh">'</span><span class="p">]</span> <span class="ow">is</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">ip_pixels_grad</span>
    <span class="n">grad</span> <span class="o">=</span> <span class="nf">grad_fn</span><span class="p">(</span><span class="n">v_t</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">dv</span> <span class="o">=</span> <span class="o">-</span><span class="n">g</span><span class="p">[</span><span class="sh">'</span><span class="s">strength</span><span class="sh">'</span><span class="p">]</span> <span class="o">*</span> <span class="nf">t_timescale</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad</span>
    <span class="k">return</span> <span class="n">dv</span><span class="p">.</span><span class="nf">detach</span><span class="p">()</span></code></pre></figure> </details> <h3 id="do-the-inpainting">Do the Inpainting</h3> <details><summary>Show Code</summary> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span><span class="n">test_ds</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">50</span><span class="p">)])</span>
<span class="nf">print</span><span class="p">(</span><span class="n">y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">M</span><span class="o">*</span><span class="n">y</span>
<span class="nf">show_grid</span><span class="p">(</span><span class="n">y</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(),</span> <span class="sh">"</span><span class="s">Masked Images</span><span class="sh">"</span><span class="p">)</span></code></pre></figure> </details> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-flow-where-you-want/inp_masked_images-480.webp 480w,/2026/assets/img/2026-04-27-flow-where-you-want/inp_masked_images-800.webp 800w,/2026/assets/img/2026-04-27-flow-where-you-want/inp_masked_images-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-flow-where-you-want/inp_masked_images.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>And now we run the inpainting code…</p> <details><summary>Show Code</summary> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">compute_dv</span> <span class="o">=</span> <span class="n">compute_dv_inpainting</span>  <span class="c1"># register our new guidance routine
</span>
<span class="n">inpainting_dict</span> <span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">decode</span><span class="sh">'</span><span class="p">:</span> <span class="n">sub</span><span class="p">.</span><span class="n">decode</span><span class="p">,</span>         <span class="c1"># how to decode to pixel space for classifier
</span>                <span class="sh">'</span><span class="s">M_sq</span><span class="sh">'</span><span class="p">:</span> <span class="p">(</span><span class="n">M</span><span class="o">**</span><span class="mi">2</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
                <span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">:</span> <span class="n">y</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
                <span class="sh">'</span><span class="s">strength</span><span class="sh">'</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>              <span class="c1"># "guidance strength", you may vary this
</span>                <span class="sh">'</span><span class="s">t_min</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="sh">'</span><span class="s">t_max</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.999</span><span class="p">}</span> <span class="c1"># t range to apply guidance, may vary these
</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
    <span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># for reproducibility as we change other things
</span>    <span class="n">t0</span> <span class="o">=</span> <span class="mf">0.2</span>             <span class="c1"># starting time as per Pokle et al
</span>    <span class="n">z0</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">([</span><span class="nf">len</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">sub</span><span class="p">.</span><span class="n">latent_dim</span><span class="p">]).</span><span class="nf">to</span><span class="p">(</span><span class="n">sub</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">zy</span> <span class="o">=</span> <span class="n">sub</span><span class="p">.</span><span class="nf">encode</span><span class="p">(</span><span class="n">y</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>   <span class="c1"># encoded version of masked image
</span>    <span class="n">z0</span> <span class="o">=</span> <span class="n">z0</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">t0</span><span class="p">)</span> <span class="o">+</span> <span class="n">zy</span> <span class="o">*</span> <span class="n">t0</span>      <span class="c1"># interpolation init
</span>    <span class="n">inpainting_dict</span><span class="p">[</span><span class="sh">'</span><span class="s">t_min</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">t0</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="nf">generate_samples</span><span class="p">(</span><span class="n">sub</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="nf">len</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">t0</span><span class="o">=</span><span class="n">t0</span><span class="p">,</span> <span class="n">z0</span><span class="o">=</span><span class="n">z0</span><span class="p">,</span> <span class="n">guidance_dict</span><span class="o">=</span><span class="n">inpainting_dict</span><span class="p">,</span> <span class="n">warp_fn</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">debug</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="nf">show_grid</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="sh">"</span><span class="s">Inpainted Images</span><span class="sh">"</span><span class="p">)</span> </code></pre></figure> </details> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-flow-where-you-want/inp_inpainted_images-480.webp 480w,/2026/assets/img/2026-04-27-flow-where-you-want/inp_inpainted_images-800.webp 800w,/2026/assets/img/2026-04-27-flow-where-you-want/inp_inpainted_images-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-flow-where-you-want/inp_inpainted_images.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>We see that the generated images generally look great, although in some cases, the in-painting code has changed pixels even where the mask is 1. We can disallow this by just resetting those values to the pixels in $y$.</p> <p>Turning up the guidance strength would also enforce our constraint better, but turning up too high causes the whole thing to diverge and we get garbage out.</p> <p>In order to experiment with other methods more easily, we should do inpainting only in latent space, and for that we will need a model that supports spatial latents….</p> <h3 id="latent-only-inpainting">Latent-Only Inpainting</h3> <p>To do inpainting in latent space, we’ll need to switch models to one where the latents preserve the spatial structure of the original images.</p> <details> <summary>Get the spatial-latents model</summary> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Get Spatial VAE &amp; FLow DiT Model
</span><span class="err">!</span><span class="n">wget</span> <span class="o">-</span><span class="n">q</span> <span class="o">--</span><span class="n">no</span><span class="o">-</span><span class="n">clobber</span><span class="o">=</span><span class="n">off</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">raw</span><span class="p">.</span><span class="n">githubusercontent</span><span class="p">.</span><span class="n">com</span><span class="o">/</span><span class="n">dlaieburner</span><span class="o">/</span><span class="mi">2025</span><span class="o">-</span><span class="n">leaderboard</span><span class="o">/</span><span class="n">refs</span><span class="o">/</span><span class="n">heads</span><span class="o">/</span><span class="n">main</span><span class="o">/</span><span class="n">sample_submission_dit</span><span class="p">.</span><span class="n">py</span>

<span class="k">try</span><span class="p">:</span>
    <span class="k">del</span> <span class="n">SubmissionInterface</span> <span class="c1"># remove Marco's from earlier; make it reload
</span><span class="k">except</span> <span class="nb">NameError</span><span class="p">:</span>
    <span class="k">pass</span>  <span class="c1"># nevermind
</span>
<span class="kn">from</span> <span class="n">sample_submission_dit</span> <span class="kn">import</span> <span class="n">SubmissionInterface</span>

<span class="n">sub</span> <span class="o">=</span> <span class="nc">SubmissionInterface</span><span class="p">().</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span></code></pre></figure> </details> <p>Let’s take a look at the images and their spatial-latent representations:</p> <details><summary>Show Code</summary> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1">#| code-fold: true
</span>
<span class="c1"># viz images and spatial latents
</span><span class="kn">from</span> <span class="n">torchvision.datasets</span> <span class="kn">import</span> <span class="n">MNIST</span>
<span class="n">test_ds</span>  <span class="o">=</span> <span class="nc">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="sh">'</span><span class="s">./data</span><span class="sh">'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="nc">ToTensor</span><span class="p">())</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span><span class="n">test_ds</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">6</span><span class="p">)])</span>
<span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">4</span><span class="p">:</span> <span class="n">x1</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="nf">show_grid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="sh">"</span><span class="s">Images</span><span class="sh">"</span><span class="p">)</span>
<span class="n">z1</span> <span class="o">=</span> <span class="n">sub</span><span class="p">.</span><span class="nf">encode</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nf">show_grid</span><span class="p">((</span><span class="n">z1</span><span class="o">-</span><span class="n">z1</span><span class="p">.</span><span class="nf">min</span><span class="p">())</span><span class="o">/</span><span class="p">(</span><span class="n">z1</span><span class="p">.</span><span class="nf">max</span><span class="p">()</span><span class="o">-</span><span class="n">z1</span><span class="p">.</span><span class="nf">min</span><span class="p">()),</span> <span class="sh">"</span><span class="s">Latents</span><span class="sh">"</span><span class="p">)</span></code></pre></figure> </details> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-flow-where-you-want/spatial_latents_viz1-480.webp 480w,/2026/assets/img/2026-04-27-flow-where-you-want/spatial_latents_viz1-800.webp 800w,/2026/assets/img/2026-04-27-flow-where-you-want/spatial_latents_viz1-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-flow-where-you-want/spatial_latents_viz1.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-flow-where-you-want/spatial_latents_viz2-480.webp 480w,/2026/assets/img/2026-04-27-flow-where-you-want/spatial_latents_viz2-800.webp 800w,/2026/assets/img/2026-04-27-flow-where-you-want/spatial_latents_viz2-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-flow-where-you-want/spatial_latents_viz2.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>Now we can run latent-only inpainting using the same code as before, only this time with the spatial-latent model and with <code class="language-plaintext highlighter-rouge">decode=None</code> in the guidance dictionary:</p> <details><summary>Show Code</summary> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">prepare_latent_mask</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">encoder</span><span class="p">):</span>
    <span class="n">z_y</span> <span class="o">=</span> <span class="nf">encoder</span><span class="p">(</span><span class="n">image</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
    <span class="n">M_z</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">interpolate</span><span class="p">(</span><span class="n">mask</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="n">z_y</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:],</span> <span class="n">mode</span><span class="o">=</span><span class="sh">'</span><span class="s">bilinear</span><span class="sh">'</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">M_z</span> <span class="o">=</span> <span class="p">(</span><span class="n">M_z</span> <span class="o">&gt;</span> <span class="mf">0.9</span><span class="p">).</span><span class="nf">float</span><span class="p">()</span>    <span class="c1"># binarize it
</span>    <span class="k">return</span> <span class="n">z_y</span> <span class="o">*</span> <span class="n">M_z</span><span class="p">,</span> <span class="n">M_z</span><span class="o">**</span><span class="mi">2</span>

<span class="nd">@torch.no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">latents_only_inpaint</span><span class="p">(</span><span class="n">sub</span><span class="p">,</span> <span class="n">inpainting_dict</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">t0</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">warp_fn</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="n">z_y</span><span class="p">,</span> <span class="n">M_sq</span> <span class="o">=</span> <span class="nf">prepare_latent_mask</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">sub</span><span class="p">.</span><span class="n">encode</span><span class="p">)</span>   
    <span class="n">inpainting_dict</span><span class="p">.</span><span class="nf">update</span><span class="p">({</span><span class="sh">'</span><span class="s">M_sq</span><span class="sh">'</span><span class="p">:</span> <span class="n">M_sq</span><span class="p">,</span> <span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">:</span> <span class="n">z_y</span><span class="p">,</span> <span class="sh">'</span><span class="s">t_min</span><span class="sh">'</span><span class="p">:</span> <span class="n">t0</span><span class="p">})</span>
    <span class="n">z0</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">z_y</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">t0</span><span class="p">)</span> <span class="o">+</span> <span class="n">z_y</span> <span class="o">*</span> <span class="n">t0</span>         <span class="c1"># Initialize via interpolation
</span>    <span class="k">return</span> <span class="nf">generate_samples</span><span class="p">(</span><span class="n">sub</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">t0</span><span class="o">=</span><span class="n">t0</span><span class="p">,</span> <span class="n">z0</span><span class="o">=</span><span class="n">z0</span><span class="p">,</span>  <span class="n">guidance_dict</span><span class="o">=</span><span class="n">inpainting_dict</span><span class="p">,</span> <span class="n">warp_fn</span><span class="o">=</span><span class="n">warp_fn</span><span class="p">)</span>

<span class="n">inpainting_dict</span> <span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">decode</span><span class="sh">'</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span>            <span class="c1"># now we're latents-only
</span>                <span class="sh">'</span><span class="s">strength</span><span class="sh">'</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>             <span class="c1"># "guidance strength", you may vary this
</span>                <span class="sh">'</span><span class="s">t_min</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="sh">'</span><span class="s">t_max</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.999</span><span class="p">}</span> <span class="c1"># t range to apply guidance, may vary these
</span>
<span class="nf">show_grid</span><span class="p">(</span><span class="n">y</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(),</span> <span class="sh">"</span><span class="s">pixel y</span><span class="sh">'</span><span class="s">s</span><span class="sh">"</span><span class="p">)</span>
<span class="n">x1</span> <span class="o">=</span> <span class="nf">latents_only_inpaint</span><span class="p">(</span><span class="n">sub</span><span class="p">,</span> <span class="n">inpainting_dict</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="nf">len</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">n_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="nf">print</span><span class="p">()</span>
<span class="nf">show_grid</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="sh">"</span><span class="s">inpainted images</span><span class="sh">"</span><span class="p">)</span></code></pre></figure> </details> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-flow-where-you-want/latents_only_pixel_ys-480.webp 480w,/2026/assets/img/2026-04-27-flow-where-you-want/latents_only_pixel_ys-800.webp 800w,/2026/assets/img/2026-04-27-flow-where-you-want/latents_only_pixel_ys-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-flow-where-you-want/latents_only_pixel_ys.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-flow-where-you-want/latents_only_inpainted_images-480.webp 480w,/2026/assets/img/2026-04-27-flow-where-you-want/latents_only_inpainted_images-800.webp 800w,/2026/assets/img/2026-04-27-flow-where-you-want/latents_only_inpainted_images-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-flow-where-you-want/latents_only_inpainted_images.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>As before, the latent-only execution is very fast, and the results are quite good. There are some limitations to what’s being produced. The problem is due to the low resolution of our latents. Inpainting algorithms typically assume higher resolution in order to work accurately. But this lesson was designed to run quickly on CPUs and thus there is a trade-off.</p> <p>Now, if we want to enforce the original pixels where the mask is one, we can do that at every stage of the integration process. We just need to modify the integration process to overwrite $z$ wherever <code class="language-plaintext highlighter-rouge">Mz</code> is 1.</p> <p>Let’s move on and try a different method that can achieve similar results, albiet differently…</p> <h1 id="pnp-flow-guidance-by-another-name">PnP-Flow: Guidance By Another Name</h1> <p>The term ‘guidance’ typically refers to velocity modifications, but PnP-Flow by Martin et al <d-cite key="pnp_flow"></d-cite> achieves similar results by adjusting latent positions $z$ directly.<d-footnote>The paper by Pokle et al we cited earlier also included a related method, however the PnP-Flow method isn't restricted to linear problems. Plus, Anne Gagneux provided [code](https://github.com/annegnx/PnP-Flow) for PnP-Flow! Gagneux's repo even provides code for the position-only (non-velocity) algorithm from Pokle et al aka "OT-ODE".</d-footnote>\(^,\)<d-footnote>Differences between our variables and those in the PnP-Flow paper: For us, $z$ are integrated flow latent variables between $z_0$ (source) and $z_1$ (target), whereas $x$ are the pixel-space representations via our VAE's decoder $D$ such that $D(z)=x$. In PnP-Flow, $x$ is the integrated flow variable, $z$ is used only for their interpolation/overwrite step, and $D$ is the "denoiser" aka their flow model.</d-footnote></p> <p>PnP-Flow assumes straight-line trajectories, making the forward projection trivial: $\widehat{z_1}$ is reached by simple linear extrapolation. Instead of incrementally moving $z$ from $t=0$ to $t=1$, PnP-Flow projects forward to $\widehat{z_1}$ and iterates on that estimate through a series of correction and projection steps. The first step applies our gradient correction:</p> \[{\rm Step\ 1.}\ \ \ \ \ \ \ \ \ \ \ \ z_1^* := \widehat{z_1} - \eta\,\gamma_t \nabla F(\widehat{z_1},y)\] <p>where $z_1^*$ (my notation) is our goal i.e. the endpoint of our projected course correction, and $F(\widehat{z_1},y)$ is our (log-exp probability) constraint. For the time scaling, the PnP-Flow authors recommend $\gamma_t = (1-t)^\alpha$ with $\alpha \in [0,1]$ is a hyperparameter chosen according to the task – e.g., they use $\alpha$’s as large as 0.8 for denoising tasks, 0.5 for box inpainting, and 0.01 for random inpainting. This choice of $\gamma_t$ is a bit different from our earlier one of $(1-t)/t$. Both go to zero as $t \rightarrow 1$, but approach it differently and have different asymptotics as $t\rightarrow 0$.</p> <p>In the graph below, we show our earlier choice of $(1 - t)/t$ in green and $(1 - t)^\alpha$ in purple for various choices of $\alpha$:</p> <center> <a href="https://www.desmos.com/calculator/bcp2wiyyid" rel="external nofollow noopener" target="_blank"> <iframe src="https://www.desmos.com/calculator/bcp2wiyyid?embed" frameborder="0" scrolling="no" height="300px" width="200px"></iframe> <br>Interactive Desmos Graph Link</a><br><br> </center> <p>…where for “box inpainting” as we did above, they use $\alpha$=0.5.</p> <p>But PnP-Flow doesn’t stop there! Two other key steps remain. We then project backward to <em>overwrite</em> $z_t$ with a corrected value:</p> \[{\rm Step\ 2.}\ \ \ \ \ \ \ \ \ \ \ \ z_t := (1-t)\,z_0 + t\, z_1^*\] <p>We then compute a new projected estimate, same as we have before:</p> \[{\rm Step\ 3.}\ \ \ \ \ \ \widehat{z_1} := z_t + (1-t)\,v_t(z,t)\] <p>….and loop over Steps 1 to 3 for each value of $t$ in our set of (discrete) integration steps, i.e. after Step 3, we let $t := t+\Delta\,t$ and go back to Step 1. Our final value of $\widehat{z_1}$ will be the output.</p> <p>This image from the PnP-Flow paper may prove instructive, showing 3 different instances of the 3 PNP steps:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-flow-where-you-want/pnp_flow_steps-480.webp 480w,/2026/assets/img/2026-04-27-flow-where-you-want/pnp_flow_steps-800.webp 800w,/2026/assets/img/2026-04-27-flow-where-you-want/pnp_flow_steps-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-flow-where-you-want/pnp_flow_steps.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>This has a superficial resemblance to the “<a href="https://github.com/Stability-AI/stable-audio-tools/blob/31932349d98c550c48711e7a5a40b24aa3d7c509/stable_audio_tools/inference/sampling.py#L221" rel="external nofollow noopener" target="_blank">ping-pong</a>” integration method used by the flow model Stable Audio Open Small (SAOS) <d-cite key="sao_small"></d-cite>, with a key distinction: the ping-pong integrator and updates the time-integrated latent variable $z$ (called “$x$” in SAOS), whereas for PnP-Flow it is the projection $\widehat{z_1}$ (called <a href="https://github.com/Stability-AI/stable-audio-tools/blob/31932349d98c550c48711e7a5a40b24aa3d7c509/stable_audio_tools/inference/sampling.py#L242" rel="external nofollow noopener" target="_blank">“denoised”</a> in SAOS) that is the primary variable that is maintained between steps. This is a subtle distinction but worth noting.<d-footnote>The near trivial nature of integration for near-OT paths of flow models means that one can implement a flow version of DITTO <d-cite key="ditto"></d-cite> that avoids the expensive back-integration needed for diffusion models. The result is also superficially similar to PnP-Flow, but with gradient steps applied to $z$ instead of $\widehat{z_1}$.</d-footnote></p> <p>To implement PnP-Flow in code, let’s replace our “integrator” with something specific to PnP-Flow:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nd">@torch.no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">sample_pnpflow</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">z0</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">n_avg</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">warp_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="n">guidance_dict</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="n">ts</span> <span class="o">=</span> <span class="nf">warp_fn</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">z0</span><span class="p">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">z0</span><span class="p">.</span><span class="n">dtype</span><span class="p">))</span>  
    <span class="n">z1_hat</span> <span class="o">=</span> <span class="n">z0</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">ts</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="n">guidance_dict</span><span class="p">[</span><span class="sh">'</span><span class="s">M_sq</span><span class="sh">'</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">z1_hat</span> <span class="o">-</span> <span class="n">guidance_dict</span><span class="p">[</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">])</span>
        <span class="n">gamma_t</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span> <span class="o">**</span> <span class="n">alpha</span>
        <span class="n">z1_star</span> <span class="o">=</span> <span class="n">z1_hat</span> <span class="o">-</span> <span class="n">guidance_dict</span><span class="p">[</span><span class="sh">'</span><span class="s">strength</span><span class="sh">'</span><span class="p">]</span> <span class="o">*</span> <span class="n">gamma_t</span> <span class="o">*</span> <span class="n">grad</span>        
        <span class="n">projections</span> <span class="o">=</span> <span class="p">[]</span>           <span class="c1"># Average multiple noisy projections
</span>        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_avg</span><span class="p">):</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">t</span> <span class="o">*</span> <span class="n">z1_star</span>  <span class="o">+</span>  <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">z1_star</span><span class="p">)</span> 
            <span class="n">projections</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">z</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span> <span class="o">*</span> <span class="nf">model</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">t</span><span class="p">))</span>
        <span class="n">z1_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">(</span><span class="n">projections</span><span class="p">).</span><span class="nf">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">z1_hat</span></code></pre></figure> <p>The model we used earlier for latents-only inpainting was trained to have straight trajectories, so we should be able to use it again here, just calling <code class="language-plaintext highlighter-rouge">sample_pnpflow</code> (instead of <code class="language-plaintext highlighter-rouge">integrate_path</code>). The results are as follows:</p> <details><summary>Show Code</summary> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1">#| code-fold: true
</span><span class="nd">@torch.no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">pnp_flow_inpaint</span><span class="p">(</span><span class="n">sub</span><span class="p">,</span> <span class="n">inpainting_dict</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">t0</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Inpaint using PnP-Flow method</span><span class="sh">"""</span>
    <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">z_y</span><span class="p">,</span> <span class="n">M_sq</span> <span class="o">=</span> <span class="nf">prepare_latent_mask</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">sub</span><span class="p">.</span><span class="n">encode</span><span class="p">)</span>
    <span class="n">inpainting_dict</span><span class="p">.</span><span class="nf">update</span><span class="p">({</span><span class="sh">'</span><span class="s">M_sq</span><span class="sh">'</span><span class="p">:</span> <span class="n">M_sq</span><span class="p">,</span> <span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">:</span> <span class="n">z_y</span><span class="p">,</span> <span class="sh">'</span><span class="s">t_min</span><span class="sh">'</span><span class="p">:</span> <span class="n">t0</span><span class="p">})</span>
    <span class="n">z0</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">z_y</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">t0</span><span class="p">)</span> <span class="o">+</span> <span class="n">z_y</span> <span class="o">*</span> <span class="n">t0</span>
    <span class="k">return</span> <span class="nf">sample_pnpflow</span><span class="p">(</span><span class="n">sub</span><span class="p">.</span><span class="n">flow_model</span><span class="p">,</span> <span class="n">z0</span><span class="p">,</span> <span class="n">guidance_dict</span><span class="o">=</span><span class="n">inpainting_dict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<span class="n">inpainting_dict</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">strength</span><span class="sh">'</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span> <span class="sh">'</span><span class="s">t_min</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> <span class="sh">'</span><span class="s">t_max</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.999</span><span class="p">}</span>

<span class="nf">show_grid</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="sh">"</span><span class="s">Masked pixel images (y)</span><span class="sh">"</span><span class="p">)</span>

<span class="n">z1</span> <span class="o">=</span> <span class="nf">pnp_flow_inpaint</span><span class="p">(</span><span class="n">sub</span><span class="p">,</span> <span class="n">inpainting_dict</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="nf">len</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">n_steps</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">x1</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">sigmoid</span><span class="p">(</span><span class="n">sub</span><span class="p">.</span><span class="nf">decode</span><span class="p">(</span><span class="n">z1</span><span class="p">)).</span><span class="nf">cpu</span><span class="p">()</span>   <span class="c1"># convert latents to pixels
</span><span class="nf">show_grid</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="sa">f</span><span class="sh">"</span><span class="s">Inpainted images (alpha=0.5, strength=</span><span class="si">{</span><span class="n">inpainting_dict</span><span class="p">[</span><span class="sh">'</span><span class="s">strength</span><span class="sh">'</span><span class="p">]</span><span class="si">}</span><span class="s">)</span><span class="sh">"</span><span class="p">)</span></code></pre></figure> </details> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-flow-where-you-want/pnpflow_masked_ys-480.webp 480w,/2026/assets/img/2026-04-27-flow-where-you-want/pnpflow_masked_ys-800.webp 800w,/2026/assets/img/2026-04-27-flow-where-you-want/pnpflow_masked_ys-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-flow-where-you-want/pnpflow_masked_ys.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-flow-where-you-want/pnpflow_inpainted_images-480.webp 480w,/2026/assets/img/2026-04-27-flow-where-you-want/pnpflow_inpainted_images-800.webp 800w,/2026/assets/img/2026-04-27-flow-where-you-want/pnpflow_inpainted_images-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-flow-where-you-want/pnpflow_inpainted_images.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>Thus we see that works, though it also seems to “take some liberties”: most of the letters in the second group look like “boldface” versions of the top ones. This could be because of the low spatial resolution of the latents, e.g. that they are encoding information about curvature or other aspects of the shape.</p> <p>The results are similar to the previous inpainting method of Pokle et al, just a different way of doing it that may prove worthwhile.</p> <p>PnP-Flow is a general guidance method not limited to inpainting or even “linear” image degradations. I recommend looking into it further for other tasks and datasets — and let me know what sort of results you find!</p> <h1 id="summary">Summary</h1> <p>Training generative models can be expensive—lots of data, electricity, compute time. So what if you could take a pretrained model and add controls at inference time instead? That’s what this tutorial explored. While similar ideas are emerging for steering autoregressive models <d-cite key="zhao2025steeringautoregressive"></d-cite>, here we focused on pretrained flow models.</p> <p>The key idea is simple: at each integration step, you project forward to estimate where you’ll end up ($\,\widehat{z_1}\,$) , check how far that is from where you want to be, and add a small velocity correction to steer toward your goal. We applied this to an unconditional MNIST flow model for two tasks: generating specific digit classes via classifier guidance, and filling in masked-out regions via inpainting.</p> <p>We looked at four approaches. First, standard classifier guidance in pixel space—it works but it’s slow because you’re propagating gradients through the VAE decoder. Second, we trained a simple latent-space classifier and did the same thing much faster. Third, we implemented the linear inpainting method from Pokle et al, which operates directly on latents. Fourth, we tried PnP-Flow, which achieves guidance not by correcting velocities but by iteratively projecting samples forward and backward in time.</p> <p>The math here is much simpler than for typical diffusion methods because flow trajectories are smooth and deterministic. We’ve glossed over a lot of detail compared to the research papers, but hopefully this gives you enough to experiment with your own controls. There are limits to the effectiveness of guidance: small models that don’t generalize well won’t suddenly work miracles if you try to push them too far outside their training distribution. Nevertheless, these plugin methods are worth exploring as accessible ways to steer generative flows where you want them to go.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/2026/assets/bibliography/2026-04-27-flow-where-you-want.bib"></d-bibliography> <d-article> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/fairness-audits/">Fairness Audits as Theater: When Metrics Mask Structural Harm</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/fans/">FANS - Frequency-Adaptive Noise Shaping for Diffusion Models</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/why-vlms-waste-their-vision/">Why vlms waste their vision</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/wait-do-we-need-to-wait/">Wait, Do We Need to Wait? Revisiting Budget Forcing for Sequential Test-Time Scaling</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/visual-reversal-curse-from-general-domain-to-remote-sensing-images/">Visual Reversal Curse: From General Domain to Remote Sensing Images</a> </li> <br> <br> </d-article> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 ICLR Blog. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/2026/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script src="/2026/assets/js/distillpub/overrides.js"></script> <script defer src="https://cdn.jsdelivr.net/npm/mermaid@10.7.0/dist/mermaid.min.js" integrity="sha256-TtLOdUA8mstPoO6sGvHIGx2ceXrrX4KgIItO06XOn8A=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/d3@7.8.5/dist/d3.min.js" integrity="sha256-1rA678n2xEx7x4cTZ5x4wpUCj6kUMZEZ5cxLSVSFWxw=" crossorigin="anonymous"></script> <script defer src="/2026/assets/js/mermaid-setup.js?38ca0a0126f7328d2d9a46bad640931f" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/2026/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/2026/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/2026/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/2026/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/2026/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/2026/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/2026/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/2026/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/2026/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/2026/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/2026/assets/js/search-data.js"></script> <script src="/2026/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>