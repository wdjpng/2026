<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Symbolism Outside, Connectionism Inside: The Trend of Fusing LLMs and Automatic Programs with Symbolic Intermediate Representations | ICLR Blogposts 2026 </title> <meta name="author" content="ICLR Blog"> <meta name="description" content="This blog introduces the trend of fusing Large Language Models (LLMs) with external symbolic programs as a new paradigm in modern and future artificial intelligence (AI). This paradigm regards LLM output as a symbolic intermediate representation (IR), which is interpreted and executed by external symbolic programs to achieve the desired behavior. We firstly review and summarize the diverse applications of this paradigm. Then we introduce the more possible usages of this paradigm, from synthesizing grounded training data to composing modular systems of specialized neural networks. Finally, we introduce the frontier of this approach: applying formal methods to automatically verify the LLM's internal reasoning processes and outputs."> <meta name="keywords" content="machine-learning, ml, deep-learning, reinforcement-learning, icl# add your own keywords or leave empty"> <link rel="stylesheet" href="/2026/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/2026/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/2026/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/2026/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/2026/assets/img/iclr_favicon.ico?0a8a3afdb0dbe139723b24dba3052a4f"> <link rel="stylesheet" href="/2026/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://iclr-blogposts.github.io/2026/blog/2026/symbolic-connect/"> <script src="/2026/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/2026/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <script src="/2026/assets/js/distillpub/template.v2.js"></script> <script src="/2026/assets/js/distillpub/transforms.v2.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Symbolism Outside, Connectionism Inside: The Trend of Fusing LLMs and Automatic Programs with Symbolic Intermediate Representations",
            "description": "This blog introduces the trend of fusing Large Language Models (LLMs) with external symbolic programs as a new paradigm in modern and future artificial intelligence (AI). This paradigm regards LLM output as a symbolic intermediate representation (IR), which is interpreted and executed by external symbolic programs to achieve the desired behavior. We firstly review and summarize the diverse applications of this paradigm. Then we introduce the more possible usages of this paradigm, from synthesizing grounded training data to composing modular systems of specialized neural networks. Finally, we introduce the frontier of this approach: applying formal methods to automatically verify the LLM's internal reasoning processes and outputs.",
            "published": "April 27, 2026",
            "authors": [
              
              {
                "author": "Anonymous",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/2026/"> ICLR Blogposts 2026 </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/2026/">home </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/about/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/call/">call for blogposts </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/submitting/">submitting </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/reviewing/">reviewing </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">past iterations </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2026/"><strong>2026</strong></a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2025/">2025</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2024/">2024</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2023/">2023</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blog-track.github.io/home/" rel="external nofollow noopener" target="_blank">2022</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Symbolism Outside, Connectionism Inside: The Trend of Fusing LLMs and Automatic Programs with Symbolic Intermediate Representations</h1> <p>This blog introduces the trend of fusing Large Language Models (LLMs) with external symbolic programs as a new paradigm in modern and future artificial intelligence (AI). This paradigm regards LLM output as a symbolic intermediate representation (IR), which is interpreted and executed by external symbolic programs to achieve the desired behavior. We firstly review and summarize the diverse applications of this paradigm. Then we introduce the more possible usages of this paradigm, from synthesizing grounded training data to composing modular systems of specialized neural networks. Finally, we introduce the frontier of this approach: applying formal methods to automatically verify the LLM's internal reasoning processes and outputs.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#the-connectionism-and-symbolism-in-artificial-intelligence">The connectionism and symbolism in Artificial Intelligence</a> </div> <div> <a href="#procedures-and-examples-of-fusing-llms-and-automatic-programs">Procedures and Examples of Fusing LLMs and Automatic Programs</a> </div> <ul> <li> <a href="#the-core-loop-user-input-translation-execution-and-grounding">The Core Loop: User Input, Translation, Execution, and Grounding</a> </li> <li> <a href="#applicationss-in-different-domains">Applicationss in Different Domains</a> </li> </ul> <div> <a href="#synthesizing-data-with-programs-for-agentic-training">Synthesizing Data with Programs for Agentic Training</a> </div> <div> <a href="#connecting-specialized-neural-networks-with-symbolic-irs">Connecting Specialized Neural Networks with Symbolic IRs</a> </div> <ul> <li> <a href="#neural-networks-as-specialized-agents">Neural Networks as Specialized Agents</a> </li> <li> <a href="#the-planner-executor-architecture">The Planner-Executor Architecture</a> </li> <li> <a href="#modularity-specialization-and-scalability">Modularity, Specialization, and Scalability</a> </li> </ul> <div> <a href="#towards-verifiable-reasoning-with-external-programs">Towards Verifiable Reasoning with External Programs</a> </div> <div> <a href="#conclusion">Conclusion</a> </div> </nav> </d-contents> <h2 id="the-connectionism-and-symbolism-in-artificial-intelligence">The connectionism and symbolism in Artificial Intelligence</h2> <p>The history of artificial intelligence (AI) has been defined by a schism between two paradigms: symbolic and connectionist, reflecting the philosophical debate between rationalism and empiricism<d-cite key="ciatto2024symbolic,goel2021looking,quan-etal-2024-verification, wang2025malot, Survey-LLM-Text-to-SQL, kim2024llm, xu2024symbol, Huang_Lipovetzky_Cohn_2025,toroghi-etal-2024-verifiable"></d-cite>. While today’s Large Language Models (LLMs) seem to represent a victory for the connectionist approach, recent trends in LLM-based agents show the significance of the hybrid systems with both paradigms.</p> <p><strong>Symbolic AI</strong> dominated the AI field from the 1950s to the 1990s <d-cite key="WikipediaSymbolicAI"></d-cite>. Rooted in rationalism, it operates on the hypothesis that intelligence arises from manipulating human-readable symbols according to explicit logical rules<d-cite key="bhuyan2024neuro"></d-cite>. The strength of this approach is its <em>transparency and verifiability</em>; its reasoning can be audited step-by-step, making it effective in domains with clear rules like mathematics or chess<d-cite key="WikipediaSymbolicAI,bhuyan2024neuro"></d-cite>. However, symbolic systems struggle with the ambiguity and noise of the real world,<d-cite key="bhuyan2024neuro"></d-cite> and the “knowledge acquisition bottleneck”—the tedious process of manually encoding rules—hinders their scalability <d-cite key="Pangakis_Wolken_2025,NEURIPS2024_bf236666"></d-cite>.</p> <p>In contrast, <strong>Connectionist AI</strong> is inspired by the brain’s structure and the empiricist school of thought<d-cite key="Shoup2023LLMsResurrect,Garson2018Connectionism"></d-cite>. It posits that intelligence emerges from a large network of simple, interconnected units (neurons) that learn patterns directly from vast amounts of data, rather than being explicitly programmed<d-cite key="BechtelAbrahamsenConnectionism, bhuyan2024neuro"></d-cite> .The strength of connectionism is its <em>flexibility and robustness</em>. Neural networks excel at pattern recognition in complex, unstructured data like images and natural language<d-cite key="ReworkSymbolicVsConnectionist"></d-cite>. Their major limitation, however, is the <strong>“black box” problem</strong> <d-cite key="singh2024rethinking"></d-cite>. The knowledge is distributed across millions of weighted connections, making their reasoning opaque. They are also data-hungry and can produce plausible but factually incorrect outputs, known as “hallucinations”<d-cite key="huang2025survey"></d-cite>.</p> <p><strong>Modern LLMs are capable to act as an adaptor between connectionist and symbolic AI.</strong><d-cite key="openai2023gpt4,IBMLLMs,WorkHubHowLLMsWork"></d-cite> LLMs are neural networks of unprecedented scale, trained on internet-sized datasets to perform a simple task: predicting the next word in a sequence<d-cite key="openai2023gpt4,WorkHubHowLLMsWork, WorkHubHowLLMsWork,Shoup2023LLMsResurrect,CloudflareLLMs"></d-cite>. Through this process, LLMs develop remarkable “emergent abilities,” allowing them to translate languages, write code, and even exhibit nascent reasoning<d-cite key="IBMLLMs,lee2025symba,pan2023logic,kazemi2023lambada,toroghi-etal-2024-verifiable,hu-etal-2025-os,WorkHubHowLLMsWork,LLMCognitionWorkshop2024"></d-cite>. This mastery of language and code syntax makes them an ideal bridge between the two AI worlds. While they are fundamentally connectionist, they can generate outputs that symbolic systems can execute. This combination of syntactic fluency without semantic grounding makes the LLM a perfect universal translator, converting fuzzy human intent into the precise, formal language required by deterministic, symbolic programs. Finally, a hybrid system composed of LLM and symbolic program is the most promising path toward building future AI systems that can help both connectionist and symbolic AI to reach their full potential.</p> <figure style="text-align: center;"> <img src="/2026/assets/img/2026-04-27-symbolic-connect/SymbolicExamples.png" width="200"> <figcaption style="font-size: 1em;">Figure 1: LLM functions as a translator, converting natural language user requests into machine-executable symbolic languages. The top example shows the LLM generating an SQL query to retrieve structured data from a database, while the bottom example demonstrates the LLM using a sequence of Linux commands to fulfill an user request. In both cases, the outputs from the external tools are returned to the LLM, which then synthesizes the information into a final, grounded response or a concrete plan.</figcaption> </figure> <p>Next, we begin by deconstructing the core procedures of fusing LLMs and automatic programs, and survey its diverse applications. Then, we extends this paradign to more usages, from synthesizing grounded training data to composing modular systems of specialized neural agents. Subsequently, we introduce the frontier of this paradigm: applying formal methods to verify the LLM’s internal reasoning process and outputs.</p> <h2 id="procedures-and-examples-of-fusing-llms-and-automatic-programs">Procedures and Examples of Fusing LLMs and Automatic Programs</h2> <p>The limitations of LLMs, include static knowledge, propensity for hallucination, and lack of access to the external world. The hybrid neural-symbolic systems can help to solve these problems by combining the flexibility of LLMs and the rigor and reliability of symbolic programs like using a web search engine, a database management system, a sandboxed code interpreter, or an API server <d-cite key="xu2024symbol,WikipediaNeuroSymbolicAI,de2025tool,schick2023toolformer,Yang2023LeanDojo"></d-cite>. This paradigm uses a powerful architectural pattern: the LLM acts as an intuitive natural language interface, while symbolic programs provide a structured, verifiable connection to the external world<d-cite key="xu2024symbol,mo2025livemcpbench,wang2025mcp"></d-cite>. The LLM’s primary role is to translate a user’s intent into a precise logically-interpretable symbolic Intermediate Representation (IR), such as json string, a line of code or an API call. This IR is then passed to a deterministic program for execution, creating a system that combines the LLM’s flexibility with the rigor and reliability of a symbolic engine.</p> <h3 id="the-core-loop-user-input-translation-execution-and-grounding">The Core Loop: User Input, Translation, Execution, and Grounding</h3> <p>The interaction within these hybrid systems follows a consistent, four-stage loop that forms the bedrock of their functionality:</p> <ol> <li> <strong>User Input:</strong> The process begins with a user expressing a goal in natural language. This input is inherently “fuzzy”, which may be incomplete, ambiguous, or context-dependent. For example, a user might ask, “How did our sales in Europe do last quarter?” or “Help me free up some space on my computer.”</li> <li> <strong>Translation:</strong> The LLM receives this natural language input. Leveraging its vast pre-trained knowledge of language, syntax, and the given tool pools or the executable program meta information, it acts like a natural-to-formal language compiler, translating the user’s intent into a formal, unambiguous symbolic IR. This IR can take many forms, such as a search query, a SQL statement, a Linux command, a snippet of Python code, or a structured JSON object for an API call.</li> <li> <strong>Execution:</strong> The generated IR is passed to an external, deterministic “automatic program.” This could be a web search engine, a database management system, a virtual machine, a sandboxed code interpreter, or an API server. Unlike the LLM, this program is a “glass box”—its behavior is predictable, its operations are verifiable, and its outputs are based on factual data or formal logic. It executes the instruction specified by the IR.</li> <li> <strong>Grounding:</strong> The output from the external program, could be a set of search results, a database table, or a computed value. This output is often fed back to the LLM, which then synthesizes it into a coherent, natural language response for the user. This final step is crucial as it “grounds” the LLM’s response in verifiable, externally sourced information, dramatically reducing the risk of hallucination and ensuring the answer is factually accurate and up-to-date <d-cite key="xu2024symbol,LabelStudioExternalKnowledge,Jones2025DeepResearch"></d-cite>.</li> </ol> <p>This loop creates a powerful symbiosis. The LLM provides a frictionless, intuitive interface for humans, while the symbolic program provides reliability, precision, and a connection to the real world. A critical feature of this architecture is that the symbolic IR serves as a “verifiability firewall.” The output of the untrusted, probabilistic LLM is not the final answer but a formal plan (the IR) that can be inspected, validated, logged, and even modified by a human or another system before it is executed by the trusted, deterministic program. This checkpoint introduces a layer of safety and control that is impossible to achieve with a purely connectionist model. Following are some examples of how this hybrid system is applied in different domains.</p> <figure style="text-align: center;"> <img src="/2026/assets/img/2026-04-27-symbolic-connect/ToolUse.png" width="200"> <figcaption style="font-size: 1em;">Figure 2: An LLM translates user requests into interpretable symbolic codes, such as JSON, XML, Python, Linux commands and others. The output is interpreted and executed by an interpreter, enabling the LLM to exploit a vast array of external tools and programs to automate complex, real-world tasks.</figcaption> </figure> <h3 id="applicationss-in-different-domains">Applicationss in Different Domains</h3> <p><strong>Information and Data Access</strong>:</p> <ul> <li> <strong>LLM + Web Search:</strong> To access real-time information, an LLM can translate a user’s question into a search query (the IR), send it to a search API, and use the results to synthesize a current, factually grounded answer<d-cite key="Jones2025DeepResearch,GoogleCloudGrounding"></d-cite> .This process, a form of Retrieval-Augmented Generation (RAG), mitigates outdatedness and the tendency to invent information<d-cite key="ning2025survey,LabelStudioExternalKnowledge,AWS_RAG"></d-cite>.</li> <li> <strong>LLM + Databases (Text-to-SQL):</strong> This fusion democratizes data access. A user’s plain-English question is translated by the LLM into a syntactically correct SQL query (the IR), which is then executed by the database<d-cite key="Survey-LLM-Text-to-SQL,hong2025next, Survey-LLM-Text-to-SQL"></d-cite>. This transforms the database into a conversational knowledge source for non-technical users<d-cite key="AWSTextToSQL"></d-cite>.</li> <li> <strong>LLM + APIs:</strong> By learning to use external “tools,” an LLM can interact with the digital world. When a request requires an action like checking the weather, the LLM identifies the appropriate tool and generates a structured API call (the IR) to invoke the corresponding endpoint, extending its capabilities infinitely<d-cite key="schick2023toolformer,ORQAPICases, hu-etal-2025-os,LMStudioToolUse,GoogleGeminiFunctionCalling"></d-cite>.</li> </ul> <p><strong>Computation and Automation</strong>:</p> <ul> <li> <strong>LLM + Code Interpreter:</strong> For tasks like analyzing a data file, the LLM writes a Python script (the IR) that is executed in a secure, sandboxed environment<d-cite key="OpenAICookbookCodeInterpreter,miranda2025veribench"></d-cite>. This leverages the LLM for high-level planning while delegating computation to a reliable, formal system<d-cite key="chen2025symbolic,Huang_Lipovetzky_Cohn_2025,kim2024llm,schick2023toolformer"></d-cite>.</li> <li> <strong>LLM + Command Line (Linux Terminal):</strong> An LLM can automate system administration by breaking down a high-level goal like “deploy my web server” into a sequence of shell commands (the IR) to be executed by the operating system’s terminal, often with human confirmation for safety<d-cite key="hu-etal-2025-os,ning2025survey,GithubBotAquarium,WarpAgentMode, NanonetsBashHelper"></d-cite>.</li> <li> <strong>LLM + GUI Automation:</strong> To control legacy software that lacks APIs, an LLM can perceive a screenshot of an application and generate a script of mouse clicks and keyboard inputs (the IR). An automation framework then executes this script to “drive” the application <d-cite key="chen2025symbolic,nguyen2024gui,ning2025survey,xu2024symbol,AssistGUI"></d-cite>.</li> </ul> <p><strong>Specialized and Formal Domains</strong>:</p> <ul> <li> <strong>LLM + Robotics:</strong> LLMs excel at translating high-level human goals, like “pick up the red block,” into a sequence of precise motor commands (the IR) for a robot’s control system to execute<d-cite key="xu2024symbol,ACROMERobotics,zeng2023large"></d-cite>. This enables more natural and flexible human-robot interaction<d-cite key="nguyen2024gui,xu2024symbol,Wang2023PromptWalk,zeng2023large"></d-cite>.</li> <li> <strong>LLM + Formal Theorem Provers:</strong> To ensure mathematical correctness, LLMs can be paired with theorem provers like Lean<d-cite key="lee2025symba,quan-etal-2024-verification,Yang2023LeanDojo,AmazonScienceLean,miranda2025veribench,wang2025malot"></d-cite>. The LLM suggests a proof strategy, formulating it as a formal tactic (the IR). The prover’s kernel only accepts the tactic if it is logically sound, thus combining the LLM’s intuitive assistance with a mathematical guarantee of correctness<d-cite key="wang2025malot,Yang2023LeanDojo,LeanDojoOrg"></d-cite>.</li> </ul> <p>The following table provides a systematic overview of these applications, highlighting the consistent architectural pattern across diverse domains.</p> <table> <thead> <tr> <th style="text-align: left">Domain</th> <th style="text-align: left">LLM Input (Natural Language Intent)</th> <th style="text-align: left">Symbolic Intermediate Representation (IR)</th> <th style="text-align: left">Automatic Program (Executor/Verifier)</th> <th style="text-align: left">Key Capability Unlocked</th> </tr> </thead> <tbody> <tr> <td style="text-align: left"><strong>Information Retrieval</strong></td> <td style="text-align: left">“What’s the latest on neuro-symbolic AI?”</td> <td style="text-align: left">Search Query (<code class="language-plaintext highlighter-rouge">"neuro-symbolic AI"</code>)</td> <td style="text-align: left">Web Search Engine (e.g., Google)</td> <td style="text-align: left">Grounding LLM output in verifiable, real-time information<d-cite key="Jones2025DeepResearch"></d-cite>.</td> </tr> <tr> <td style="text-align: left"><strong>Database Interaction</strong></td> <td style="text-align: left">“Show me last quarter’s top 5 sales reps.”</td> <td style="text-align: left">SQL Query (<code class="language-plaintext highlighter-rouge">SELECT... LIMIT 5</code>)</td> <td style="text-align: left">Database Management System</td> <td style="text-align: left">Providing a natural language interface to structured data<d-cite key="hong2025next"></d-cite>.</td> </tr> <tr> <td style="text-align: left"><strong>External Services</strong></td> <td style="text-align: left">“What is the weather like in Tokyo?”</td> <td style="text-align: left">API Call (JSON object)</td> <td style="text-align: left">Weather API Server</td> <td style="text-align: left">Accessing live, real-world data and executing digital actions<d-cite key="schick2023toolformer"></d-cite>.</td> </tr> <tr> <td style="text-align: left"><strong>Code &amp; Data Analysis</strong></td> <td style="text-align: left">“Plot the user distribution by country from this file.”</td> <td style="text-align: left">Python Code (<code class="language-plaintext highlighter-rouge">df.plot(...)</code>)</td> <td style="text-align: left">Code Interpreter (Jupyter/Docker)</td> <td style="text-align: left">Offloading complex computation and data manipulation tasks<d-cite key="OpenAICookbookCodeInterpreter"></d-cite>.</td> </tr> <tr> <td style="text-align: left"><strong>System Administration</strong></td> <td style="text-align: left">“Install the latest version of NodeJS on my server.”</td> <td style="text-align: left">Shell Command (<code class="language-plaintext highlighter-rouge">nvm install node</code>)</td> <td style="text-align: left">Linux Terminal / OS Shell</td> <td style="text-align: left">Automating complex system-level tasks via command-line interfaces<d-cite key="WarpAgentMode"></d-cite>.</td> </tr> <tr> <td style="text-align: left"><strong>Robotic Control</strong></td> <td style="text-align: left">“Pick up the red block and place it on the green one.”</td> <td style="text-align: left">Control Commands (<code class="language-plaintext highlighter-rouge">move_to(x,y)</code>, <code class="language-plaintext highlighter-rouge">grasp()</code>)</td> <td style="text-align: left">Robotic Operating System</td> <td style="text-align: left">Translating high-level goals into low-level physical actions<d-cite key="ACROMERobotics"></d-cite>.</td> </tr> <tr> <td style="text-align: left"><strong>Formal Reasoning</strong></td> <td style="text-align: left">“Prove that the square root of 2 is irrational.”</td> <td style="text-align: left">Lean Tactics (<code class="language-plaintext highlighter-rouge">rw</code>, <code class="language-plaintext highlighter-rouge">apply</code>)</td> <td style="text-align: left">Lean Theorem Prover</td> <td style="text-align: left">Interfacing with formally verified systems to ensure logical rigor<d-cite key="wang2025malot,Yang2023LeanDojo"></d-cite>.</td> </tr> </tbody> </table> <h2 id="synthesizing-data-with-programs-for-agentic-training">Synthesizing Data with Programs for Agentic Training</h2> <p>The potential of fusing LLMs with external programs extends to addressing a core bottleneck in AI development: the acquisition of high-quality training data. By using LLMs to control programmatic data generation, we can create vast, diverse, and grounded datasets for training future AI models. This approach reframes data synthesis from an act of mimicry to one of grounded simulation.</p> <p><strong>The Data Bottleneck in Modern AI.</strong> The performance of AI models is tied to the scale and quality of their training data. Collecting this data is expensive, labor-intensive, and raises significant ethical concerns<d-cite key="Nadas2025SyntheticData,su2025scaling"></d-cite>. While synthetic data is an alternative, simply prompting an LLM to generate text can result in repetitive, factually unmoored datasets that reinforce the model’s existing biases<d-cite key="Nadas2025SyntheticData,BerdanierSyntheticData"></d-cite>.</p> <p><strong>A New Paradigm: Program-Aided Data Synthesis.</strong> A more powerful approach repurposes the LLM-program architecture for data generation. Here, the LLM writes and executes programs that create synthetic data. It acts as a generative engine, using its reasoning capabilities to control tools like simulators, APIs, and code interpreters to produce rich and verifiably correct training examples<d-cite key="long-etal-2024-llms,Huang_Lipovetzky_Cohn_2025"></d-cite>.</p> <p>This “program-aided” method has broad applications:</p> <ul> <li> <strong>Generating High-Quality Fine-Tuning Data:</strong> To fine-tune a model for a specific domain, an LLM can generate thousands of prompt-response pairs<d-cite key="long-etal-2024-llms,SuperAnnotateFinetuning"></d-cite>. For example, it can formulate a user query about a software product. Then, instead of hallucinating a response, it can generate and execute code that calls the product’s actual API to obtain a factually correct answer, creating a perfect training pair.</li> <li> <strong>Creating Data for Vision and Robotics Models:</strong> An LLM can control a photorealistic simulator to generate a nearly infinite stream of perfectly labeled data for vision or robotics models<d-cite key="wang2024survey"></d-cite>. It can programmatically vary parameters like object positions and lighting to create millions of diverse training scenarios<d-cite key="chen2025symbolic"></d-cite>.</li> <li> <strong>Bootstrapping Reinforcement Learning (RL) Agents:</strong> An LLM equipped with tools can interact with a simulated environment to generate millions of (state, action, reward) trajectories. This vast dataset of experiences can then be used to efficiently bootstrap the training of a more specialized RL agent <d-cite key="zhou2025anyprefer"></d-cite>.</li> </ul> <p><strong>New Agentic Training Curricula.</strong> A new training paradigm is emerging to transform Large Language Models (LLMs) into sophisticated agentic systems. Standard post-training methods often fail because they create an optimization tension: the model is forced to simultaneously learn foundational agentic skills while also aligning with specific expert data. To resolve this, a new approach called Agentic Continual Pre-training (Agentic CPT) focuses on first building a robust agentic foundation model<d-cite key="su2025scaling"></d-cite>. This specialized training goes beyond simple instruction following. It immerses the model in complex scenarios where it must learn to handle multi-turn conversations to clarify goals, develop intricate reasoning chains, and master multi-turn tool use involving many different tools where the output of one action informs the next. Crucially, this process incorporates a reflector mechanism, allowing the agent to self-critique its performance, learn from mistakes<d-cite key="novikov2025alphaevolve"></d-cite>, and dynamically adjust its plan. By creating a model that already understands this “agentic way” of thinking and acting, subsequent fine-tuning becomes far more effective.</p> <p>Program-aided synthesis is grounded in an external system that embodies factual knowledge or rules, such as an API or a physics engine<d-cite key="WorkHubHowLLMsWork"></d-cite>. The resulting data is not merely plausible; it is verifiably correct. This means we are moving from generating synthetic text to generating synthetic, grounded experiences. This data is far more valuable for training robust and generalizable AI systems because it reflects the underlying causal structure of the domain.</p> <h2 id="connecting-specialized-neural-networks-with-symbolic-irs">Connecting Specialized Neural Networks with Symbolic IRs</h2> <p>The paradigm of Large Language Models (LLMs) using external programs is undergoing a significant evolution. The concept of a “tool” can be expanding beyond simple APIs to include other specialized AI models. In this architecture, a general LLM functions as a central planner, orchestrating a collection of specialized AI agents to solve complex problems as shown in Figure 3 <d-cite key="kim2024llm"></d-cite>. This compositional approach mirrors the microservices principle in software engineering, promoting modularity and specialization over monolithic system design <d-cite key="Blueprint"></d-cite>.</p> <figure style="text-align: center;"> <img src="/2026/assets/img/2026-04-27-symbolic-connect/ModelsAsTools.png" width="200"> <figcaption style="font-size: 1em;">Figure 3: A Planner-Executor architecture where a central "Planner LLM" orchestrates the workflow for complex tasks. The Planner generates a structured plan (e.g., JSON) that an interpreter uses to sequentially call upon a variety of specialized neural networks, each acting as a distinct tool to solve a specific part of the problem..</figcaption> </figure> <h3 id="neural-networks-as-specialized-agents">Neural Networks as Specialized Agents</h3> <p>The architectural pattern of an LLM calling an external function is generalizable. Any system that accepts a structured input and produces a predictable output can be treated as a tool. This abstraction allows us to consider highly specialized AI models as callable functions within a larger agentic system<d-cite key="WhiteLLMFunctionCalling,shen2024small,shen2023hugginggpt"></d-cite>. Instead of a single, monolithic model attempting to master every domain, this paradigm leverages a collection of expert models, each excelling at a specific task. Examples of such specialized AI “tools” include:</p> <ul> <li> <strong>Vision Model:</strong> A state-of-the-art convolutional neural network (CNN) or Vision Transformer (ViT) <d-cite key="he2016deep,dosovitskiy2020image"></d-cite> optimized for object detection, image segmentation, or optical character recognition (OCR).</li> <li> <strong>Biology Model:</strong> A model like AlphaFold, specialized in predicting protein structures from amino acid sequences <d-cite key="AlphaFold"></d-cite>.</li> <li> <strong>Writing LLMs:</strong> An LLM that has been extensively fine-tuned on a narrow corpus, such as legal case law, medical research papers, or financial reports, making it an expert in that specific domain<d-cite key="WhiteLLMFunctionCalling,shen2024small,shen2023hugginggpt"></d-cite>.</li> <li> <strong>Image Generative Model:</strong> A diffusion model like DALL-E or Stable Diffusion <d-cite key="ramesh2021zero,rombach2022high,ramesh2022hierarchical"></d-cite>, which takes a text description and generates a corresponding image.</li> <li> <strong>Speech-to-Text Model:</strong> A specialized audio processing model for high-accuracy transcription <d-cite key="radford2023robust,gulati2020conformer"></d-cite>.</li> </ul> <p>Each of these models can be wrapped in an API, presenting itself to a central LLM as a tool with a specific function signature and a natural language description of its capabilities<d-cite key="WhiteLLMFunctionCalling,shen2024small"></d-cite>.</p> <h3 id="the-planner-executor-architecture">The Planner-Executor Architecture</h3> <p>To implement such a system, there should be a powerful multi-agent architecture, often referred to as a Planner-Executor or Orchestrator-Worker model<d-cite key="kim2024llm,IBMAgentOrchestration,WijesingheLLMOrchestration"></d-cite>. In this framework, a highly capable, general LLM serves as the central <strong>Planner</strong> (or “brain”), while a suite of specialized models act as <strong>Executors</strong>. The workflow for solving a complex problem proceeds as follows:</p> <ol> <li> <strong>Task Decomposition:</strong> The system receives an user request that requires multiple steps and different modalities. For example: “Please review the attached quarterly earnings PDF, identify the main reasons for the revenue increase, create a bar chart visualizing the revenue by region, and write a draft of a press release summarizing these findings.”</li> <li> <strong>Planning and Tool Selection:</strong> The Planner LLM analyzes the request and breaks it down into a logical sequence of sub-tasks<d-cite key="Huang_Lipovetzky_Cohn_2025,kim2024llm,SaMSolutionsAgentic"></d-cite>. For each sub-task, it identifies the most appropriate specialized agent (tool or neural network model) from given resource pool. Its thought process might resemble: <ul> <li>“First, I need to extract the text from the PDF. I will use the <code class="language-plaintext highlighter-rouge">Document_OCR_Agent</code>.”</li> <li>“Next, I need to read the extracted text and identify the key drivers of revenue. The <code class="language-plaintext highlighter-rouge">Financial_Analysis_LLM</code> is best for this.”</li> <li>“Then, I need to extract the regional revenue data and create a visualization. I will ask the <code class="language-plaintext highlighter-rouge">Code_Generation_Agent</code> to write Python code for this and then send the code to the <code class="language-plaintext highlighter-rouge">Code_Interpreter</code> tool for execution.”</li> <li>“Finally, I need to combine the analysis and the chart into a press release. I will use my own general-purpose <code class="language-plaintext highlighter-rouge">Text_Generation</code> capability for this.”</li> </ul> </li> <li> <strong>Symbolic Invocation:</strong> The Planner LLM generates a series of symbolic IRs (e.g. structured API calls) to invoke each Executor agent in sequence. It passes the output of one agent as the input to the next, managing the flow of information through the system<d-cite key="kim2024llm,AnalyticsVidhyaFunctionCalling,xu2024symbol"></d-cite>.</li> <li> <strong>Synthesis:</strong> After all sub-tasks are completed, the Planner LLM receives the final outputs from all the Executor agents (the analysis text, the chart image, etc.) and synthesizes them into a single, coherent response for the user.</li> </ol> <h3 id="modularity-specialization-and-scalability">Modularity, Specialization, and Scalability</h3> <p>Regarding different neural networks provides a modular view to the hybrid system. Thus, the whole system could be scaled with increasing the number of different modules. This modular, multi-agent architecture offers significant advantages over a monolithic approach:</p> <ul> <li> <strong>Specialization and Performance:</strong> Each agent can be a best-in-class model for its specific function. A dedicated vision model will always outperform a general LLM on image tasks. This divide-andconquer strategy leads to higher quality and more reliable results for the overall system <d-cite key="WhiteLLMFunctionCalling,shen2023hugginggpt"></d-cite>.</li> <li> <strong>Modularity and Maintainability:</strong> The system is composed of independent, interchangeable components <d-cite key="KumarMultiAgent"></d-cite>. A single agent, like the vision model, can be updated, improved, or replaced without affecting the rest of the system. This makes the entire architecture easier to develop, test, and maintain.</li> <li> <strong>Efficiency and Cost-Effectiveness:</strong> Instead of using a massive, expensive model for every step, the system can use smaller, more efficient, and cheaper models for simpler tasks, reserving the most powerful Planner LLM for the high-level reasoning and coordination work.</li> <li> <strong>Scalability and Extensibility:</strong> New capabilities can be added to the system simply by developing a new specialized agent and registering it as a tool with the Planner. The Planner LLM can learn to use this new tool from its description, without needing to be retrained.</li> </ul> <p>This architectural pattern represents a powerful parallel to the microservices revolution in software engineering<d-cite key="Blueprint"></d-cite>. For years, software development moved away from large, monolithic applications toward a paradigm where complex applications are built by composing small, independent services that communicate via well-defined APIs. This approach proved to be more scalable, resilient, and adaptable. The Planner-Executor model for AI is the conceptual equivalent. Instead of pursuing a single, monolithic Artificial General Intelligence (AGI), this approach suggests that higher-level intelligence can be achieved by composing a network of specialized AI micro-intelligences. The Planner LLM acts as the orchestration layer, and the symbolic API calls are the communication protocol that binds them together. This compositional path to AGI may prove more practical and robust than the monolithic one, suggesting a future of AI development that is less about building bigger models and more about building smarter systems of models.</p> <h2 id="towards-verifiable-reasoning-with-external-programs">Towards Verifiable Reasoning with External Programs</h2> <p><strong>The Challenge of Unreliable Reasoning in LLMs.</strong> Integrating connectionist Large Language Models (LLMs) with symbolic programs has significantly enhanced their reliability. This is achieved by grounding models in external facts and delegating precise computations to specialized tools. However, a more ambitious frontier involves addressing the core weakness of LLMs: the inherent unreliability of their internal reasoning. While techniques like Chain-of-Thought (CoT) prompting make the model’s reasoning more transparent, they do not guarantee correctness. <d-cite key="sistla2025towards,miranda2025veribench,toroghi-etal-2024-verifiable,MoreFormalizingReasoning"></d-cite> An LLM’s elegantly articulated reasoning can still originate from a subtle logical fallacy, leading to a confidently incorrect conclusion. This level of unreliability is unacceptable for high-stakes applications in fields such as science, law, and medicine.</p> <p>The probabilistic nature of LLMs is the root of this issue. They generate text by predicting the most probable next word, which can produce outputs that appear plausible but are logically flawed or factually inaccurate. This well-documented problem is often called hallucination <d-cite key="huang2025survey,zhang2025siren"></d-cite>.</p> <p><strong>Formalizing LLM Reasoning with Logic。</strong> The next potential evolution in the neuro-symbolic paradigm is to automatically verify the LLM’s reasoning process and detecing outputs as shown in Figure 4. This requires translating the model’s natural language outputs, including its declarative statements and inferential steps, into a formal symbolic language like First-Order Logic (FOL) or the higher-order logics used by proof assistants. <d-cite key="Yang2023LeanDojo,lee2025symba,pan2023logic,kazemi2023lambada,Brunello2024TranslatingNL"></d-cite></p> <p>This concept is supported by a strong theoretical foundation from the work of logician Richard Montague. <d-cite key="quan-etal-2024-verification,WikipediaMontagueGrammar,SasagawaMontagueGrammar"></d-cite> His work on Montague Grammar established that natural languages could be described with the same mathematical precision as formal languages, showing how syntactic structures can be mapped to formal semantic representations. <d-cite key="Janssen2017MontagueSemantics"></d-cite> While a complete implementation of Montague’s program for modern LLMs is a long-term goal, it establishes the theoretical plausibility of this approach. Recent advancements, such as the development of models like LogicLLaMA <d-cite key="yang-etal-2024-harnessing"></d-cite>, have already shown promise in translating natural language into well-formed logical expressions.</p> <figure style="text-align: center;"> <img src="/2026/assets/img/2026-04-27-symbolic-connect/AutoMatic.png" width="200"> <figcaption style="font-size: 1em;">Figure 4: A workflow for the automatic verification of a Large Language Model's reasoning. The LLM first generates a step-by-step reasoning chain, which an interpreter then translates into a formal language. This formal representation is subsequently passed to an automatic analyzer, like the Lean theorem prover, to mathematically validate the logical soundness of the entire argument.</figcaption> </figure> <p><strong>A Workflow for Automatically Verifiable LLM Outputs,</strong> The new workflow for creating verifiably correct LLM systems could be as follows.</p> <ol> <li> <strong>Generation with Rationale.</strong> An LLM is prompted to answer a complex question and provide its step-by-step reasoning in natural language, similar to a CoT approach.</li> <li> <strong>Formalization.</strong> The natural language output is then processed by a specialized “Formalizer” LLM. This model translates each sentence of the reasoning into a corresponding expression in a formal language, such as that used by the Lean theorem prover. <d-cite key="wang2025malot,quan-etal-2024-verification,toroghi-etal-2024-verifiable,Yang2023LeanDojo"></d-cite> The result is a sequence of formal claims representing the LLM’s argument.</li> <li> <strong>Formal Verification.</strong> This sequence of formal claims is then passed to an external, automated formal verifier, like a theorem prover or a model checker. <d-cite key="toroghi-etal-2024-verifiable,quan-etal-2024-verification,QuantumZeitgeistVerification,VeriPlan"></d-cite> This symbolic engine attempts to mathematically prove the validity of each step and the overall consistency of the argument.</li> <li> <strong>Feedback and Correction.</strong> If the verifier identifies a logical error, for example, a step that does not follow from previous ones or a conclusion that contradicts a known axiom, it provides specific, structured feedback. <d-cite key="MoreFormalizingReasoning,QuantumZeitgeistVerification,toroghi-etal-2024-verifiable"></d-cite> This feedback is sent back to the LLM, prompting it to correct its reasoning and generate a new, valid argument.</li> </ol> <p>This iterative loop transforms the LLM from an unreliable reasoner into a generator of conjectures. The creative and intuitive outputs of LLMs are rigorously evaluated by a logically sound symbolic partner. This methodology is also being explored for tasks like automated fact-checking, where LLM-generated claims are verified against structured knowledge bases <d-cite key="ou2025holmes,COLINGLOKI"></d-cite>.</p> <h2 id="conclusion">Conclusion</h2> <p>In conclusion, the fusion of Large Language Models with external symbolic programs constitutes a foundational architectural paradigm for advancing artificial intelligence. This neuro-symbolic integration progresses through increasingly sophisticated stages: from initially grounding outputs in factual data via tool use, to programmatically synthesizing verifiably correct training data, and composing modular systems of specialized neural agents. Throughout this evolution, the symbolic Intermediate Representation (IR) serves as the critical, verifiable bridge between the probabilistic reasoning of the LLM and the deterministic execution of external systems. The trend of this paradigm points towards the formal verification of the LLM’s internal reasoning processes themselves. By translating natural language rationales into formal logic for automated validation, this approach may pave the way for systems that are trustworthy and logically sound.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/2026/assets/bibliography/2026-04-27-symbolic-connect.bib"></d-bibliography> <d-article> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/wait-do-we-need-to-wait/">Wait, Do We Need to Wait? Revisiting Budget Forcing for Sequential Test-Time Scaling</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/sac-massive-sim/">Getting SAC to Work on a Massive Parallel Simulator: An RL Journey With Off-Policy Algorithms</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/nlp-for-human-sciences/">Language as a Window Into the Mind: How NLP and LLMs Advance Human Sciences</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/model-misspecification-in-sbi/">Model Misspecification in Simulation-Based Inference - Recent Advances and Open Challenges</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/mislead-lm/">Do Language Models Really Learn to Mislead Humans via RLHF?</a> </li> <br> <br> </d-article> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 ICLR Blog. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/2026/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script src="/2026/assets/js/distillpub/overrides.js"></script> <script defer src="https://cdn.jsdelivr.net/npm/mermaid@10.7.0/dist/mermaid.min.js" integrity="sha256-TtLOdUA8mstPoO6sGvHIGx2ceXrrX4KgIItO06XOn8A=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/d3@7.8.5/dist/d3.min.js" integrity="sha256-1rA678n2xEx7x4cTZ5x4wpUCj6kUMZEZ5cxLSVSFWxw=" crossorigin="anonymous"></script> <script defer src="/2026/assets/js/mermaid-setup.js?38ca0a0126f7328d2d9a46bad640931f" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/2026/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/2026/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/2026/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/2026/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/2026/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/2026/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/2026/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/2026/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/2026/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/2026/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/2026/assets/js/search-data.js"></script> <script src="/2026/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>