<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> In-context learning of representations can be explained by induction circuits | ICLR Blogposts 2026 </title> <meta name="author" content="ICLR Blog"> <meta name="description" content="Park et al., 2025 demonstrate that large language models can learn to trace random walks on graphs presented in context, and observe that token representations reorganize to reflect the underlying graph structure. This has been interpreted as evidence that models 'flexibly manipulate their representations' to reflect in-context semantics, and that this reorganization enables task performance. We offer a simpler mechanistic explanation. We first observe that task performance can be fully explained by induction circuits (Olsson et al., 2022), and show that ablating the attention heads that comprise these circuits substantially degrades performance. As for the geometric structure, we propose that it could result from previous token heads effectively mixing the representations of graph neighbors together. We show that a single round of such 'neighbor mixing' on random embeddings recreates the observed graph correspondence in PCA visualizations. These results suggest that apparent 'representation reorganization' may be a byproduct of the model's induction circuits, rather than a critical strategy useful for in-context learning."> <meta name="keywords" content="machine-learning, ml, deep-learning, reinforcement-learning, icl# add your own keywords or leave empty"> <link rel="stylesheet" href="/2026/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/2026/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/2026/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/2026/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/2026/assets/img/iclr_favicon.ico?0a8a3afdb0dbe139723b24dba3052a4f"> <link rel="stylesheet" href="/2026/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://iclr-blogposts.github.io/2026/blog/2026/iclr-induction/"> <script src="/2026/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/2026/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <script src="/2026/assets/js/distillpub/template.v2.js"></script> <script src="/2026/assets/js/distillpub/transforms.v2.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}.plot-container{position:relative;width:100%;margin-bottom:1rem}.plot-container.plot-standard{height:470px}.plot-container.plot-tall{height:570px}.plot-container.plot-grid{height:820px}.plot-container.plot-square{height:570px;max-width:570px;margin-left:auto;margin-right:auto}.plot-container.plot-medium{height:470px;max-width:670px;margin-left:auto;margin-right:auto}.plot-container iframe{display:none}.plot-container .plot-fallback{display:block;width:100%;height:auto;max-width:100%}.plot-container.plot-standard,.plot-container.plot-tall,.plot-container.plot-grid,.plot-container.plot-square,.plot-container.plot-medium{height:auto}.plot-row{display:flex;flex-wrap:wrap;gap:16px;margin-bottom:.5rem}.plot-row .plot-container{flex:1 1 400px;min-width:300px}.plot-row .plot-container.w-65{flex:65 1 300px}.plot-row .plot-container.w-60{flex:60 1 300px}.plot-row .plot-container.w-55{flex:55 1 300px}.plot-row .plot-container.w-50{flex:50 1 300px}.plot-row .plot-container.w-45{flex:45 1 300px}.plot-row .plot-container.w-40{flex:40 1 300px}.plot-row .plot-container.w-35{flex:35 1 300px}.plot-row-triple{display:flex;flex-wrap:wrap;gap:12px;margin-bottom:.5rem}.plot-row-triple .plot-container{flex:1 1 280px;min-width:250px}.plot-row-triple .plot-container .plot-fallback{width:100%;height:auto}.plot-frame-half{flex:1 1 300px;height:470px;border:0;display:block}.plot-frame-full{display:block;margin:0 auto 1rem auto;width:100%;max-width:900px;height:470px;border:0}@media(max-width:768px){.plot-frame-half,.plot-frame-full{display:none}}.attention-viewer{position:relative;width:100%;margin-bottom:1rem}.attention-viewer .viewer-interactive{display:none}.attention-viewer .viewer-gallery{display:none;width:100%;max-height:500px;overflow-y:auto;border:1px solid #e0e0e0;border-radius:8px;padding:10px;background:#fafafa}.attention-viewer .viewer-gallery .gallery-item{margin-bottom:20px;text-align:center}.attention-viewer .viewer-gallery .gallery-item img{max-width:100%;height:auto;border:1px solid #ddd;border-radius:4px}.attention-viewer .viewer-gallery .gallery-item .gallery-label{font-size:14px;font-weight:600;margin-bottom:8px;color:#333}.png-selector{display:block;width:100%;margin-bottom:1rem}.png-selector input[type="radio"]{display:none}.png-selector .selector-buttons{display:flex;flex-wrap:wrap;gap:4px;margin-bottom:15px}.png-selector label{padding:4px 8px;font-size:12px;border:1px solid #ccc;background:#f5f5f5;cursor:pointer;color:#333}.png-selector label:hover{background:#e0e0e0}.png-selector .selector-image{display:none;text-align:center}.png-selector .selector-image img{max-width:400px;width:100%;height:auto;border:1px solid #ddd}@media(prefers-color-scheme:dark){.png-selector label{background:#333;border-color:#555;color:#ddd}.png-selector label:hover{background:#444}.png-selector .selector-image img{border-color:#555}}.png-selector #ind1:checked ~ .selector-images .img-ind1,.png-selector #ind2:checked ~ .selector-images .img-ind2,.png-selector #ind3:checked ~ .selector-images .img-ind3,.png-selector #ind4:checked ~ .selector-images .img-ind4,.png-selector #ind5:checked ~ .selector-images .img-ind5,.png-selector #ind6:checked ~ .selector-images .img-ind6,.png-selector #ind7:checked ~ .selector-images .img-ind7,.png-selector #ind8:checked ~ .selector-images .img-ind8,.png-selector #ind9:checked ~ .selector-images .img-ind9,.png-selector #ind10:checked ~ .selector-images .img-ind10,.png-selector #ind11:checked ~ .selector-images .img-ind11,.png-selector #ind12:checked ~ .selector-images .img-ind12,.png-selector #ind13:checked ~ .selector-images .img-ind13,.png-selector #ind14:checked ~ .selector-images .img-ind14,.png-selector #ind15:checked ~ .selector-images .img-ind15,.png-selector #ind16:checked ~ .selector-images .img-ind16,.png-selector #ind17:checked ~ .selector-images .img-ind17,.png-selector #ind18:checked ~ .selector-images .img-ind18,.png-selector #ind19:checked ~ .selector-images .img-ind19,.png-selector #ind20:checked ~ .selector-images .img-ind20,.png-selector #ind21:checked ~ .selector-images .img-ind21,.png-selector #ind22:checked ~ .selector-images .img-ind22,.png-selector #ind23:checked ~ .selector-images .img-ind23,.png-selector #ind24:checked ~ .selector-images .img-ind24,.png-selector #ind25:checked ~ .selector-images .img-ind25,.png-selector #ind26:checked ~ .selector-images .img-ind26,.png-selector #ind27:checked ~ .selector-images .img-ind27,.png-selector #ind28:checked ~ .selector-images .img-ind28,.png-selector #ind29:checked ~ .selector-images .img-ind29,.png-selector #ind30:checked ~ .selector-images .img-ind30,.png-selector #ind31:checked ~ .selector-images .img-ind31,.png-selector #ind32:checked ~ .selector-images .img-ind32,.png-selector #prev1:checked ~ .selector-images .img-prev1,.png-selector #prev2:checked ~ .selector-images .img-prev2,.png-selector #prev3:checked ~ .selector-images .img-prev3,.png-selector #prev4:checked ~ .selector-images .img-prev4,.png-selector #prev5:checked ~ .selector-images .img-prev5,.png-selector #prev6:checked ~ .selector-images .img-prev6,.png-selector #prev7:checked ~ .selector-images .img-prev7,.png-selector #prev8:checked ~ .selector-images .img-prev8,.png-selector #prev9:checked ~ .selector-images .img-prev9,.png-selector #prev10:checked ~ .selector-images .img-prev10,.png-selector #prev11:checked ~ .selector-images .img-prev11,.png-selector #prev12:checked ~ .selector-images .img-prev12,.png-selector #prev13:checked ~ .selector-images .img-prev13,.png-selector #prev14:checked ~ .selector-images .img-prev14,.png-selector #prev15:checked ~ .selector-images .img-prev15,.png-selector #prev16:checked ~ .selector-images .img-prev16,.png-selector #prev17:checked ~ .selector-images .img-prev17,.png-selector #prev18:checked ~ .selector-images .img-prev18,.png-selector #prev19:checked ~ .selector-images .img-prev19,.png-selector #prev20:checked ~ .selector-images .img-prev20,.png-selector #prev21:checked ~ .selector-images .img-prev21,.png-selector #prev22:checked ~ .selector-images .img-prev22,.png-selector #prev23:checked ~ .selector-images .img-prev23,.png-selector #prev24:checked ~ .selector-images .img-prev24,.png-selector #prev25:checked ~ .selector-images .img-prev25,.png-selector #prev26:checked ~ .selector-images .img-prev26,.png-selector #prev27:checked ~ .selector-images .img-prev27,.png-selector #prev28:checked ~ .selector-images .img-prev28,.png-selector #prev29:checked ~ .selector-images .img-prev29,.png-selector #prev30:checked ~ .selector-images .img-prev30,.png-selector #prev31:checked ~ .selector-images .img-prev31,.png-selector #prev32:checked ~ .selector-images .img-prev32{display:block}
.png-selector #ind1:checked ~ .selector-buttons label[for="ind1"],.png-selector #ind2:checked ~ .selector-buttons label[for="ind2"],.png-selector #ind3:checked ~ .selector-buttons label[for="ind3"],.png-selector #ind4:checked ~ .selector-buttons label[for="ind4"],.png-selector #ind5:checked ~ .selector-buttons label[for="ind5"],.png-selector #ind6:checked ~ .selector-buttons label[for="ind6"],.png-selector #ind7:checked ~ .selector-buttons label[for="ind7"],.png-selector #ind8:checked ~ .selector-buttons label[for="ind8"],.png-selector #ind9:checked ~ .selector-buttons label[for="ind9"],.png-selector #ind10:checked ~ .selector-buttons label[for="ind10"],.png-selector #ind11:checked ~ .selector-buttons label[for="ind11"],.png-selector #ind12:checked ~ .selector-buttons label[for="ind12"],.png-selector #ind13:checked ~ .selector-buttons label[for="ind13"],.png-selector #ind14:checked ~ .selector-buttons label[for="ind14"],.png-selector #ind15:checked ~ .selector-buttons label[for="ind15"],.png-selector #ind16:checked ~ .selector-buttons label[for="ind16"],.png-selector #ind17:checked ~ .selector-buttons label[for="ind17"],.png-selector #ind18:checked ~ .selector-buttons label[for="ind18"],.png-selector #ind19:checked ~ .selector-buttons label[for="ind19"],.png-selector #ind20:checked ~ .selector-buttons label[for="ind20"],.png-selector #ind21:checked ~ .selector-buttons label[for="ind21"],.png-selector #ind22:checked ~ .selector-buttons label[for="ind22"],.png-selector #ind23:checked ~ .selector-buttons label[for="ind23"],.png-selector #ind24:checked ~ .selector-buttons label[for="ind24"],.png-selector #ind25:checked ~ .selector-buttons label[for="ind25"],.png-selector #ind26:checked ~ .selector-buttons label[for="ind26"],.png-selector #ind27:checked ~ .selector-buttons label[for="ind27"],.png-selector #ind28:checked ~ .selector-buttons label[for="ind28"],.png-selector #ind29:checked ~ .selector-buttons label[for="ind29"],.png-selector #ind30:checked ~ .selector-buttons label[for="ind30"],.png-selector #ind31:checked ~ .selector-buttons label[for="ind31"],.png-selector #ind32:checked ~ .selector-buttons label[for="ind32"],.png-selector #prev1:checked ~ .selector-buttons label[for="prev1"],.png-selector #prev2:checked ~ .selector-buttons label[for="prev2"],.png-selector #prev3:checked ~ .selector-buttons label[for="prev3"],.png-selector #prev4:checked ~ .selector-buttons label[for="prev4"],.png-selector #prev5:checked ~ .selector-buttons label[for="prev5"],.png-selector #prev6:checked ~ .selector-buttons label[for="prev6"],.png-selector #prev7:checked ~ .selector-buttons label[for="prev7"],.png-selector #prev8:checked ~ .selector-buttons label[for="prev8"],.png-selector #prev9:checked ~ .selector-buttons label[for="prev9"],.png-selector #prev10:checked ~ .selector-buttons label[for="prev10"],.png-selector #prev11:checked ~ .selector-buttons label[for="prev11"],.png-selector #prev12:checked ~ .selector-buttons label[for="prev12"],.png-selector #prev13:checked ~ .selector-buttons label[for="prev13"],.png-selector #prev14:checked ~ .selector-buttons label[for="prev14"],.png-selector #prev15:checked ~ .selector-buttons label[for="prev15"],.png-selector #prev16:checked ~ .selector-buttons label[for="prev16"],.png-selector #prev17:checked ~ .selector-buttons label[for="prev17"],.png-selector #prev18:checked ~ .selector-buttons label[for="prev18"],.png-selector #prev19:checked ~ .selector-buttons label[for="prev19"],.png-selector #prev20:checked ~ .selector-buttons label[for="prev20"],.png-selector #prev21:checked ~ .selector-buttons label[for="prev21"],.png-selector #prev22:checked ~ .selector-buttons label[for="prev22"],.png-selector #prev23:checked ~ .selector-buttons label[for="prev23"],.png-selector #prev24:checked ~ .selector-buttons label[for="prev24"],.png-selector #prev25:checked ~ .selector-buttons label[for="prev25"],.png-selector #prev26:checked ~ .selector-buttons label[for="prev26"],.png-selector #prev27:checked ~ .selector-buttons label[for="prev27"],.png-selector #prev28:checked ~ .selector-buttons label[for="prev28"],.png-selector #prev29:checked ~ .selector-buttons label[for="prev29"],.png-selector #prev30:checked ~ .selector-buttons label[for="prev30"],.png-selector #prev31:checked ~ .selector-buttons label[for="prev31"],.png-selector #prev32:checked ~ .selector-buttons label[for="prev32"]{background:#007bff;color:white;border-color:#007bff}</style> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "In-context learning of representations can be explained by induction circuits",
            "description": "Park et al., 2025 demonstrate that large language models can learn to trace random walks on graphs presented in context, and observe that token representations reorganize to reflect the underlying graph structure. This has been interpreted as evidence that models 'flexibly manipulate their representations' to reflect in-context semantics, and that this reorganization enables task performance. We offer a simpler mechanistic explanation. We first observe that task performance can be fully explained by induction circuits (Olsson et al., 2022), and show that ablating the attention heads that comprise these circuits substantially degrades performance. As for the geometric structure, we propose that it could result from previous token heads effectively mixing the representations of graph neighbors together. We show that a single round of such 'neighbor mixing' on random embeddings recreates the observed graph correspondence in PCA visualizations. These results suggest that apparent 'representation reorganization' may be a byproduct of the model's induction circuits, rather than a critical strategy useful for in-context learning.",
            "published": "April 27, 2026",
            "authors": [
              
              {
                "author": "Anonymous",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/2026/"> ICLR Blogposts 2026 </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/2026/">home </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/about/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/call/">call for blogposts </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/submitting/">submitting </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/reviewing/">reviewing </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">past iterations </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2026/"><strong>2026</strong></a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2025/">2025</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2024/">2024</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2023/">2023</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blog-track.github.io/home/" rel="external nofollow noopener" target="_blank">2022</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>In-context learning of representations can be explained by induction circuits</h1> <p>Park et al., 2025 demonstrate that large language models can learn to trace random walks on graphs presented in context, and observe that token representations reorganize to reflect the underlying graph structure. This has been interpreted as evidence that models 'flexibly manipulate their representations' to reflect in-context semantics, and that this reorganization enables task performance. We offer a simpler mechanistic explanation. We first observe that task performance can be fully explained by induction circuits (Olsson et al., 2022), and show that ablating the attention heads that comprise these circuits substantially degrades performance. As for the geometric structure, we propose that it could result from previous token heads effectively mixing the representations of graph neighbors together. We show that a single round of such 'neighbor mixing' on random embeddings recreates the observed graph correspondence in PCA visualizations. These results suggest that apparent 'representation reorganization' may be a byproduct of the model's induction circuits, rather than a critical strategy useful for in-context learning.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#recapitulation-and-reproduction-of-park-et-al-2025">Recapitulation and reproduction of Park et al., 2025</a> </div> <ul> <li> <a href="#the-grid-tracing-task">The grid tracing task</a> </li> <li> <a href="#replication-and-interpretation">Replication and interpretation</a> </li> </ul> <div> <a href="#a-simpler-explanation-induction-circuits">A simpler explanation: induction circuits</a> </div> <ul> <li> <a href="#testing-the-induction-hypothesis">Testing the induction hypothesis</a> </li> <li> <a href="#results">Results</a> </li> </ul> <div> <a href="#previous-token-mixing-can-account-for-representational-structure">Previous-token mixing can account for representational structure</a> </div> <ul> <li> <a href="#the-neighbor-mixing-hypothesis">The neighbor-mixing hypothesis</a> </li> <li> <a href="#a-toy-model-of-previous-token-mixing">A toy model of previous-token mixing</a> </li> <li> <a href="#evidence-of-neighbor-mixing-in-individual-model-activations">Evidence of neighbor mixing in individual model activations</a> </li> </ul> <div> <a href="#limitations-and-open-questions">Limitations and open questions</a> </div> <div> <a href="#conclusion">Conclusion</a> </div> </nav> </d-contents> <h2 id="recapitulation-and-reproduction-of-park-et-al-2025">Recapitulation and reproduction of Park et al., 2025</h2> <p>In this section, we provide a detailed description of Park et al. <d-cite key="park2025iclr"></d-cite>. We successfully reproduce their results on Llama-3.1-8B <d-cite key="grattafiori2024llama3"></d-cite>.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-iclr-induction/park_fig_1-480.webp 480w,/2026/assets/img/2026-04-27-iclr-induction/park_fig_1-800.webp 800w,/2026/assets/img/2026-04-27-iclr-induction/park_fig_1-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-iclr-induction/park_fig_1.png" class="" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <b>Figure 1.</b> <b>Overview of Park et al., 2025.</b> The grid tracing task uses a $4 {\times} 4$ grid of words. Models observe random walks on the grid (e.g., <code> apple</code><code> bird</code><code> milk</code><code> sand</code><code> sun</code><code> plane</code><code> opera</code><code> ...</code>) where consecutive words are always neighbors. As the sequence length grows, the model begins to predict valid next words based on the learned graph structure. More surprisingly, the geometry of the model's effective token representations mirrors that of the grid structure: the model learns (in context) to represent each node adjacent to its neighbor. <br> Figure reproduced from Park et al., 2025. </div> <h3 id="the-grid-tracing-task">The grid tracing task</h3> <p>Park et al. <d-cite key="park2025iclr"></d-cite> introduce the <em>in-context graph tracing</em> task. The task involves a predefined graph \(\mathcal{G} = (\mathcal{T}, E)\) where nodes \(\mathcal{T} = \{\tau_1, \tau_2, \ldots, \tau_n\}\) are referenced via tokens (e.g., <code> apple</code>, <code> bird</code>, <code> math</code>, etc.). The graph’s connectivity structure \(E\) is defined independently of any semantic relationships between the concepts. The model is provided with traces of random walks on this graph as context and must predict valid next nodes based on the learned connectivity structure. While <d-cite key="park2025iclr"></d-cite> study graph tracing on three different graph structures, we focus exclusively on their \(4{\times}4\) square grid setting (Figure 1). We provide details of the experimental setup below; our methodology always follows <d-cite key="park2025iclr"></d-cite> except when otherwise noted.</p> <p><strong>Grid structure.</strong> The task uses a \(4{\times}4\) grid of 16 distinct word tokens: <code> apple</code>, <code> bird</code>, <code> car</code>, <code> egg</code>, <code> house</code>, <code> milk</code>, <code> plane</code>, <code> opera</code>, <code> box</code>, <code> sand</code>, <code> sun</code>, <code> mango</code>, <code> rock</code>, <code> math</code>, <code> code</code>, <code> phone</code>.<d-footnote>All words tokenize to exactly one token when preceded by a space (e.g., <code> apple</code> is a single token). Sequences are tokenized with a leading space before the first word, ensuring single-token-per-word encoding.</d-footnote> Each word occupies a unique position in the grid. Two words are <em>neighbors</em> if they are horizontally or vertically adjacent (not diagonally). This defines an adjacency matrix \(A \in \{0,1\}^{16 \times 16}\) where \(A_{ij} = 1\) if and only if words \(i\) and \(j\) are neighbors.</p> <p><strong>Random walk generation.</strong> Training sequences are generated via random walks on this grid. Starting from a random position, at each step the walk moves to a uniformly random neighbor. This produces sequences like <code> apple</code><code> bird</code><code> milk</code><code> sand</code><code> sun</code><code> plane</code><code> opera</code><code> ...</code> where consecutive words are always grid neighbors. Following <d-cite key="park2025iclr"></d-cite>, we use sequence lengths of 1400 tokens.</p> <p><strong>Measuring accuracy.</strong> At timestep \(t\), the random walk is at node \(w_t\) with neighbor set \(\mathcal{N}(w_t)\). The model outputs a distribution \(p_{\theta}(\cdot \mid w_{1:t})\) over vocabulary tokens. “Rule following accuracy” is defined as the probability mass assigned to any valid next node:</p> \[\text{acc}_t \;=\; \sum_{w \in \mathcal{N}(w_t)} p_{\theta}(w \mid w_{1:t}).\] <p><strong>PCA visualization.</strong> To assess whether the model’s representations come to resemble the grid structure, activations are extracted from a late layer (layer 26) and projected onto their top principal components. For each of the 16 words, a class-mean activation is computed by averaging over all occurrences in the final 200 positions of the sequence. The first two principal components of these 16 class-mean vectors define a 2D subspace onto which the class means are projected for visualization. If the representational geometry reflects the grid, neighboring tokens should appear nearby in this projection.</p> <h3 id="replication-and-interpretation">Replication and interpretation</h3> <p>We replicate the results of Park et al. on Llama-3.1-8B. Figure 2 shows our reproduction: accuracy on the grid tracing task increases with context length, reaching \({\sim}0.90\) after \({\sim}10^3\) tokens, and PCA projections of late-layer activations reveal geometric structure mirroring the grid.</p> <div class="l-page"> <div class="plot-row"> <div class="plot-container plot-standard w-65"> <iframe src="/2026/assets/html/2026-04-27-iclr-induction/repro_paper/accuracy_curve.html"></iframe> <img class="plot-fallback" src="/2026/assets/html/2026-04-27-iclr-induction/repro_paper/accuracy_curve.png" alt="Accuracy curve showing model performance increasing with context length"> </div> <div class="plot-container plot-tall w-35"> <iframe src="/2026/assets/html/2026-04-27-iclr-induction/repro_paper/pca_visualization.html"></iframe> <img class="plot-fallback" src="/2026/assets/html/2026-04-27-iclr-induction/repro_paper/pca_visualization.png" alt="PCA visualization showing grid structure in token representations"> </div> </div> </div> <div class="caption"> <b>Figure 2.</b> <b>Reproduction of main results from Park et al., 2025.</b> <b>Left:</b> Model accuracy on the grid tracing task increases with context length, reaching ${\sim}0.90$ accuracy after ${\sim}10^3$ tokens. Shaded region shows $\pm 1$ standard deviation across 16 random sequences. <b>Right:</b> PCA projection of class-mean activations at layer 26 after seeing 1400 tokens. Gray dashed lines connect grid neighbors. The geometry of the effective representations resembles the grid structure underlying the data. </div> <p>Park et al. interpret these findings as evidence that the geometric reorganization plays a functional role in task performance: the model learns the graph structure in its representations, and this learned structure is what enables accurate next-node predictions.</p> <blockquote> <p>“We see once a critical amount of context is seen by the model, accuracy starts to rapidly improve. We find this point in fact closely matches when Dirichlet Energy<d-footnote>Dirichlet energy measures how much a signal varies across graph edges. Low energy means neighboring nodes have similar representations, so Park et al. use it to quantify how well the model's representations respect the graph structure.</d-footnote> reaches its minimum value: energy is minimized shortly before the rapid increase in in-context task accuracy, suggesting that the structure of the data is correctly learned before the model can make valid predictions. This leads us to the claim that as the amount of context is scaled, there is an <strong>emergent re-organization of representations that allows the model to perform well</strong> on our in-context graph tracing task.” <d-cite key="park2025iclr"></d-cite> (Section 4.1)</p> </blockquote> <p>We propose a simpler mechanistic account in the following sections.</p> <hr> <h2 id="a-simpler-explanation-induction-circuits">A simpler explanation: induction circuits</h2> <p>We propose that the grid navigation task can be solved by a much simpler mechanism than abstract spatial representation learning: <em>induction circuits</em> <d-cite key="elhage2021mathematical"></d-cite>, <d-cite key="olsson2022context"></d-cite>.</p> <p>An induction circuit consists of two types of attention heads working together. <em>Previous-token heads</em> attend from position \(t\) to position \(t{-}1\), copying information about the previous token into the current position’s residual stream. <em>Induction heads</em> then attend to positions that follow previous occurrences of the current token. Together, they implement in-context bigram recall: “if \(A\) followed \(B\) before, predict \(A\) when seeing \(B\) again.”<d-footnote>In the literature, the term "induction head" is sometimes used to refer to both the individual attention head and the full two-component circuit. We use "induction circuit" for the full mechanism and "induction head" for the specific head that attends to tokens following previous occurrences, to avoid ambiguity.</d-footnote></p> <p>In the grid task, if the model has seen the bigram <code> apple</code><code> bird</code> earlier in the sequence, then upon encountering <code> apple</code> again, the induction circuit can retrieve and predict <code> bird</code>. With enough context, the model will have observed multiple successors for each token, and can aggregate over these to assign probability mass to all valid neighbors.<d-footnote>For example, if the model has seen both <code> apple</code><code> bird</code> and <code> apple</code><code> house</code>, it can distribute probability across both <code> bird</code> and <code> house</code> when predicting the next token after <code> apple</code>.</d-footnote></p> <h3 id="testing-the-induction-hypothesis">Testing the induction hypothesis</h3> <p>If the model relies on induction heads to solve the task, then ablating these heads should substantially degrade task performance. We test this via <em>zero ablation</em>: setting targeted attention heads’ outputs to zero and measuring the causal impact on both task accuracy and in-context representations.</p> <p><strong>Head identification.</strong> Following <d-cite key="olsson2022incontext"></d-cite>, we identify induction heads and previous-token heads using attention pattern analysis on repeated sequences (see Appendix A for details). Induction heads attend to positions one token <em>after</em> where the current token previously appeared. Previous-token heads simply attend to the immediately preceding position. We rank all 1024 heads in Llama-3.1-8B by their induction and previous-token scores, yielding two ranked lists.</p> <p><strong>Ablation procedure.</strong> For each head type, we ablate the top-\(k\) heads for \(k \in \{1, 2, 4, 8, 16, 32\}\) and measure impact on task accuracy and PCA structure of representations. As a control, we ablate random heads sampled from all heads excluding the top 32 induction and top 32 previous-token heads.</p> <h3 id="results">Results</h3> <div class="l-page"> <div class="plot-row"> <div class="plot-container"> <iframe src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/ablation_induction.html"></iframe> <img class="plot-fallback" src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/ablation_induction.png" alt="Effect of ablating induction heads on accuracy"> </div> <div class="plot-container"> <iframe src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/ablation_prev_token.html"></iframe> <img class="plot-fallback" src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/ablation_prev_token.png" alt="Effect of ablating previous-token heads on accuracy"> </div> </div> </div> <div class="caption"> <b>Figure 3.</b> <b>Effect of head ablation on task accuracy.</b> <b>Left:</b> Ablating top induction heads progressively degrades accuracy, but the model still learns with context. <b>Right:</b> Ablating top previous-token heads causes accuracy to plateau, preventing learning even with more context. <span style="color: gray;">Gray line</span> shows ablating 32 random heads (excluding top induction and prev-token heads) as a control. </div> <p><strong>Both induction heads and previous-token heads are critical to task performance.</strong> Figure 3 shows task accuracy under head ablations. Ablating the top-4 induction heads causes accuracy to drop from \({\sim}0.90\) to \({\sim}0.70\), and ablating the top-32 drops accuracy all the way to \({\sim}0.40\). Ablating just the top-2 previous-token heads reduces accuracy \({&lt;}0.60\), and ablating the top-32 previous-token heads further drops accuracy to \({\sim}0.30\).</p> <p>In contrast, ablating \(k\) random heads causes only very small degradation to \({\sim}0.85\), suggesting that induction and previous-token heads are <em>particularly</em> important for task performance.<d-footnote>The random heads are sampled from the set of all heads <em>excluding</em> the top-32 induction heads and top-32 previous-token heads. We sample 4 different random sets of 32 heads and report the averaged results.</d-footnote></p> <p>While ablating induction heads significantly impairs task performance, accuracy continues to ascend as context length increases. In contrast, ablating previous token heads causes accuracy to plateau, even as context length grows.</p> <div class="l-page"> <div class="plot-row-triple"> <div class="plot-container"> <iframe src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/pca_ablation_baseline.html"></iframe> <img class="plot-fallback" src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/pca_ablation_baseline.png" alt="PCA baseline - grid structure visible"> </div> <div class="plot-container"> <iframe src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/pca_ablation_induction.html"></iframe> <img class="plot-fallback" src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/pca_ablation_induction.png" alt="PCA with induction heads ablated - grid structure preserved"> </div> <div class="plot-container"> <iframe src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/pca_ablation_prev_token.html"></iframe> <img class="plot-fallback" src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/pca_ablation_prev_token.png" alt="PCA with prev-token heads ablated - grid structure disrupted"> </div> </div> </div> <div class="caption"> <b>Figure 4.</b> <b>Effect of head ablation on representational geometry.</b> PCA projections of class-mean activations under different ablation conditions. <b>Left:</b> Baseline (no ablation) shows clear grid structure. <b>Center:</b> Ablating top-32 induction heads preserves the grid geometry. <b>Right:</b> Ablating top-32 previous-token heads disrupts the spatial organization. This suggests previous-token heads are necessary for the geometric structure, while induction heads are not. </div> <p><strong>Ablating previous-token heads disrupts representational organization.</strong> While both head types are important for accuracy, they seem to have different effects on learned representations. The figure below shows that ablating induction heads preserves the grid-like geometric structure in PCA visualizations, as the 2D projections still resemble the spatial grid. However, ablating previous-token heads disrupts this structure, causing representations to lose their apparent spatial organization.</p> <h2 id="previous-token-mixing-can-account-for-representational-structure">Previous-token mixing can account for representational structure</h2> <p>In the previous section, we studied <em>task performance</em> and argued that the model achieves high task accuracy by using induction circuits. We now study the <em>representational geometry</em>, and ask if we can give a simple explanation for the grid-like PCA plots. We will argue that it is plausible that the structures are byproducts of mixing performed by previous-token heads.</p> <h3 id="the-neighbor-mixing-hypothesis">The neighbor-mixing hypothesis</h3> <p>Figure 4 shows that ablating previous-token heads disrupts the grid structure, while ablating induction heads preserves it. This suggests that previous-token heads are somehow necessary for the geometric organization. But what mechanism could link previous-token heads to spatial structure?</p> <p>Previous-token heads mix information from position \(t-1\) into position \(t\). In a random walk, the token at \(t-1\) is always a grid neighbor of the token at \(t\). So each token’s representation gets mixed with a neighbor’s. When we compute the class mean for word \(c\), we average over all positions where \(c\) appears, each mixed with whichever neighbor preceded it. Over many occurrences, \(c\) is preceded by each of its neighbors roughly equally, so the class mean for \(c\) roughly encodes \(c\) plus an average of its neighbors.</p> <p>To test whether neighbor-mixing alone can create the observed geometry, we construct a minimal toy model.</p> <h3 id="a-toy-model-of-previous-token-mixing">A toy model of previous-token mixing</h3> <p>We work directly in a 16-token space indexed by the \(4{\times}4\) grid nodes. Each node \(i\) is assigned an initial random vector \(\mathbf{e}_i \in \mathbb{R}^{4096}\), sampled i.i.d. from \(\mathcal{N}(0,I)\). PCA of just the raw embeddings \(\{\mathbf{e}_i\}\) produces an essentially unstructured cloud: there is no visible trace of the grid.</p> <p>We then apply a single, “neighbor mixing” step:</p> \[\tilde{\mathbf{e}}_i \;=\; \mathbf{e}_i \;+\; \frac{1}{|\mathcal{N}(i)|} \sum_{j \in \mathcal{N}(i)} \mathbf{e}_j,\] <p>where \(\mathcal{N}(i)\) denotes the set of neighbors of node \(i\).</p> <p>After this one step, PCA of the 16 mixed vectors \(\{\tilde{\mathbf{e}}_i\}\) recovers a clear \(4{\times}4\) grid: neighbors are close in the 2D projection and non-neighbors are far (Figure 5).</p> <div class="l-page"> <div class="plot-row"> <div class="plot-container plot-tall"> <iframe src="/2026/assets/html/2026-04-27-iclr-induction/neighbor_mixing/mixing_random_baseline.html"></iframe> <img class="plot-fallback" src="/2026/assets/html/2026-04-27-iclr-induction/neighbor_mixing/mixing_random_baseline.png" alt="PCA of random embeddings without mixing - no structure visible"> </div> <div class="plot-container plot-tall"> <iframe src="/2026/assets/html/2026-04-27-iclr-induction/neighbor_mixing/mixing_random_mixed.html"></iframe> <img class="plot-fallback" src="/2026/assets/html/2026-04-27-iclr-induction/neighbor_mixing/mixing_random_mixed.png" alt="PCA after neighbor mixing - grid structure emerges"> </div> </div> </div> <div class="caption"> <b>Figure 5.</b> <b>One round of neighbor mixing creates grid structure from random embeddings.</b> <b>Left:</b> PCA projection of 16 random Gaussian vectors $\mathbf{e}_i \sim \mathcal{N}(0, I)$ shows no spatial structure. <b>Right:</b> After applying one neighbor-mixing step, the same embeddings exhibit clear grid organization in PCA space. Gray dashed lines connect grid neighbors. </div> <h3 id="evidence-of-neighbor-mixing-in-individual-model-activations">Evidence of neighbor mixing in individual model activations</h3> <p>We find additional evidence that the representational structure is a result of previous-token mixing.</p> <p>Instead of collapsing each word into a single class mean, we take the final 200 positions of a length-1400 random-walk sequence and project all 200 residual-stream vectors into the same 2D PCA space used for the class means. Each point now corresponds to a specific activation. For each point, we display bigram information: the center color indicates the current token \(w_t\) and the border color indicates the previous token \(w_{t-1}\).</p> <div class="l-page"> <div class="plot-container plot-square"> <iframe src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/bigram_pca_seed0.html"></iframe> <img class="plot-fallback" src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/bigram_pca_seed0.png" alt="Bigram PCA showing each point colored by current token (fill) and previous token (border)"> </div> </div> <div class="caption"> <b>Figure 6.</b> <b>Bigram-level PCA visualization.</b> Each point represents a single position's activation. Fill color indicates the current token; border color indicates the previous token. Points with the same current token but different previous tokens form distinct clusters, suggesting the representation encodes information about both. Star markers show token centroids. </div> <p>Figure 6 shows a consistent pattern. Points whose previous bigram is <code> plane</code><code> math</code> tend to lie between the <code> plane</code> and <code> math</code> centroids. Points with previous bigram <code> egg</code><code> math</code> tend to lie between <code> egg</code> and <code> math</code>. We see similar “in-between” behavior for all other bigrams. This is what one would expect if the representation of \(w_t\) contains something like a mixture of “self” and “previous token” rather than depending only on the current word.</p> <h2 id="limitations-and-open-questions">Limitations and open questions</h2> <p>Our experiments point towards a simple explanation: the model performs in-context graph tracing via induction circuits, and the grid-like PCA geometry is a byproduct of previous-token mixing. However, our understanding remains incomplete in important ways.</p> <p><strong>The toy model is a significant simplification.</strong> Our neighbor-mixing rule assumes that previous-token heads simply add the raw previous-token vector \(\mathbf{h}_{t-1}\) to the current position. In reality, attention heads apply value and output projections: they add \(W_O W_V \mathbf{h}_{t-1}\), where \(W_O W_V \in \mathbb{R}^{d_{\text{model}} \times d_{\text{model}}}\) is a low-rank matrix (rank \(\leq d_{\text{head}}\)). This projection could substantially transform the information being mixed, and notably cannot implement the identity mapping since it is low-rank. We also model everything as a single mixing step on static vectors, whereas the actual network has many attention heads, MLP blocks, and multiple layers that repeatedly transform the residual stream.</p> <p><strong>Why does the grid structure emerge late in the sequence?</strong> Previous-token heads are active from the start of the sequence, yet the grid-like PCA structure only becomes clearly visible after many tokens have been processed. If neighbor-mixing were the whole story, we might expect the geometric structure to appear earlier.</p> <p>These gaps mean our account should be understood as a <em>plausible mechanistic hypothesis</em> rather than a complete explanation. The key empirical findings stand: ablating induction heads degrades task performance while preserving PCA geometry, and ablating previous-token heads disrupts both performance and geometry.</p> <h2 id="conclusion">Conclusion</h2> <p>We have argued that the phenomena observed by Park et al. <d-cite key="park2025iclr"></d-cite> can be explained by well-known mechanisms in language models. Task performance on in-context graph tracing is well-explained by induction circuits, which recall previously-seen bigrams. The geometric organization visible in PCA plots appears to be a byproduct of previous-token mixing: because random walks traverse graph edges, previous-token heads mix each position’s representation with that of a graph neighbor, and this mixing alone is sufficient to produce grid-like structure from unstructured embeddings.</p> <p>These findings suggest that the “representation reorganization” observed by Park et al. may not reflect a sophisticated in-context learning strategy, but rather an artifact of previous-token head behavior.</p> <p>That said, our understanding has clear limits. Our toy model ignores the value and output projections of real attention heads, and we cannot yet explain why the geometric structure emerges only late in the sequence.</p> <hr> <h2 id="appendix-a-head-detection-methodology">Appendix A: Head Detection Methodology</h2> <p>We identify induction heads and previous-token heads using attention pattern analysis on synthetic repeated sequences, following the approach of Olsson et al. <d-cite key="olsson2022incontext"></d-cite>.</p> <h3 id="a1-test-sequence-construction">A.1 Test Sequence Construction</h3> <p>We construct a test sequence by repeating a random sequence of tokens:</p> \[[\text{tok}_1, \ldots, \text{tok}_{32}, \text{tok}_1, \ldots, \text{tok}_{32}]\] <p>where tokens are sampled uniformly from the lower half of the vocabulary. The full sequence has length \(T = 64\). We run the model on a batch of 32 such sequences and extract attention patterns from all heads.</p> <p>For layer \(\ell \in \{1, \ldots, 32\}\) and head \(h \in \{1, \ldots, 32\}\) (Llama-3.1-8B has 32 layers and 32 heads per layer), let \(P^{(\ell,h)} \in \mathbb{R}^{T \times T}\) denote the attention pattern, where \(P^{(\ell,h)}_{t,s}\) is the attention weight from position \(t\) (query) to position \(s\) (key).</p> <h3 id="a2-induction-score">A.2 Induction Score</h3> <p>Induction heads exhibit a characteristic pattern: for a repeated token at position \(i\) in the second half of the sequence, they attend not to its earlier occurrence at position \(i - 32\), but to the token <em>after</em> that earlier occurrence, i.e., position \(i - 31\).</p> <p>We compute the induction score as the average attention along this offset-31 diagonal:</p> \[s_{\text{ind}}^{(\ell,h)} = \frac{1}{32} \sum_{i=33}^{64} P^{(\ell,h)}_{i, i-31}\] <p>This measures how strongly the head attends to “the token that followed the previous occurrence of the current token.”</p> <h3 id="a3-previous-token-score">A.3 Previous-Token Score</h3> <p>Previous-token heads implement a simpler pattern: at each position, they attend primarily to the immediately preceding token.</p> <p>We compute the previous-token score as the average attention along the offset-1 diagonal:</p> \[s_{\text{prev}}^{(\ell,h)} = \frac{1}{T-1} \sum_{i=2}^{T} P^{(\ell,h)}_{i, i-1}\] <h3 id="a4-head-ranking">A.4 Head Ranking</h3> <p>We average scores across the batch of 32 sequences, then rank all 1024 heads (32 layers \(\times\) 32 heads) by their induction and previous-token scores separately. This yields two ranked lists. For ablation experiments, we ablate the top-\(k\) heads from each list for \(k \in \{1, 2, 4, 8, 16, 32\}\).</p> <hr> <h2 id="appendix-b-attention-pattern-gallery">Appendix B: Attention Pattern Gallery</h2> <p>This appendix provides detailed visualizations of the attention patterns for the top-ranked induction heads and previous-token heads identified in our analysis. Click the buttons to explore different heads, ranked by their induction or previous-token score.</p> <h3 id="b1-induction-head-attention-patterns">B.1 Induction Head Attention Patterns</h3> <p>Induction heads attend to positions where the current token previously appeared, specifically attending one position <em>after</em> the previous occurrence. In the visualization below, the induction diagonal (offset by half the sequence length) shows elevated attention weights.</p> <div class="l-page"> <div class="png-selector"> <input type="radio" name="ind-head" id="ind1" checked> <input type="radio" name="ind-head" id="ind2"> <input type="radio" name="ind-head" id="ind3"> <input type="radio" name="ind-head" id="ind4"> <input type="radio" name="ind-head" id="ind5"> <input type="radio" name="ind-head" id="ind6"> <input type="radio" name="ind-head" id="ind7"> <input type="radio" name="ind-head" id="ind8"> <input type="radio" name="ind-head" id="ind9"> <input type="radio" name="ind-head" id="ind10"> <input type="radio" name="ind-head" id="ind11"> <input type="radio" name="ind-head" id="ind12"> <input type="radio" name="ind-head" id="ind13"> <input type="radio" name="ind-head" id="ind14"> <input type="radio" name="ind-head" id="ind15"> <input type="radio" name="ind-head" id="ind16"> <input type="radio" name="ind-head" id="ind17"> <input type="radio" name="ind-head" id="ind18"> <input type="radio" name="ind-head" id="ind19"> <input type="radio" name="ind-head" id="ind20"> <input type="radio" name="ind-head" id="ind21"> <input type="radio" name="ind-head" id="ind22"> <input type="radio" name="ind-head" id="ind23"> <input type="radio" name="ind-head" id="ind24"> <input type="radio" name="ind-head" id="ind25"> <input type="radio" name="ind-head" id="ind26"> <input type="radio" name="ind-head" id="ind27"> <input type="radio" name="ind-head" id="ind28"> <input type="radio" name="ind-head" id="ind29"> <input type="radio" name="ind-head" id="ind30"> <input type="radio" name="ind-head" id="ind31"> <input type="radio" name="ind-head" id="ind32"> <div class="selector-buttons"> <label for="ind1">L15H30</label> <label for="ind2">L8H1</label> <label for="ind3">L16H20</label> <label for="ind4">L2H22</label> <label for="ind5">L10H14</label> <label for="ind6">L5H11</label> <label for="ind7">L15H1</label> <label for="ind8">L24H27</label> <label for="ind9">L20H14</label> <label for="ind10">L5H8</label> <label for="ind11">L20H1</label> <label for="ind12">L19H3</label> <label for="ind13">L2H20</label> <label for="ind14">L26H15</label> <label for="ind15">L2H12</label> <label for="ind16">L27H6</label> <label for="ind17">L26H13</label> <label for="ind18">L28H15</label> <label for="ind19">L2H25</label> <label for="ind20">L13H6</label> <label for="ind21">L16H1</label> <label for="ind22">L22H14</label> <label for="ind23">L27H5</label> <label for="ind24">L27H7</label> <label for="ind25">L27H4</label> <label for="ind26">L2H21</label> <label for="ind27">L10H13</label> <label for="ind28">L5H9</label> <label for="ind29">L16H23</label> <label for="ind30">L20H13</label> <label for="ind31">L27H20</label> <label for="ind32">L19H0</label> </div> <div class="selector-images"> <div class="selector-image img-ind1"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/induction_patterns/rank01_L15H30.png" alt="L15H30"></div> <div class="selector-image img-ind2"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/induction_patterns/rank02_L8H1.png" alt="L8H1"></div> <div class="selector-image img-ind3"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/induction_patterns/rank03_L16H20.png" alt="L16H20"></div> <div class="selector-image img-ind4"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/induction_patterns/rank04_L2H22.png" alt="L2H22"></div> <div class="selector-image img-ind5"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/induction_patterns/rank05_L10H14.png" alt="L10H14"></div> <div class="selector-image img-ind6"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/induction_patterns/rank06_L5H11.png" alt="L5H11"></div> <div class="selector-image img-ind7"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/induction_patterns/rank07_L15H1.png" alt="L15H1"></div> <div class="selector-image img-ind8"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/induction_patterns/rank08_L24H27.png" alt="L24H27"></div> <div class="selector-image img-ind9"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/induction_patterns/rank09_L20H14.png" alt="L20H14"></div> <div class="selector-image img-ind10"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/induction_patterns/rank10_L5H8.png" alt="L5H8"></div> <div class="selector-image img-ind11"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/induction_patterns/rank11_L20H1.png" alt="L20H1"></div> <div class="selector-image img-ind12"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/induction_patterns/rank12_L19H3.png" alt="L19H3"></div> <div class="selector-image img-ind13"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/induction_patterns/rank13_L2H20.png" alt="L2H20"></div> <div class="selector-image img-ind14"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/induction_patterns/rank14_L26H15.png" alt="L26H15"></div> <div class="selector-image img-ind15"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/induction_patterns/rank15_L2H12.png" alt="L2H12"></div> <div class="selector-image img-ind16"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/induction_patterns/rank16_L27H6.png" alt="L27H6"></div> <div class="selector-image img-ind17"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/induction_patterns/rank17_L26H13.png" alt="L26H13"></div> <div class="selector-image img-ind18"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/induction_patterns/rank18_L28H15.png" alt="L28H15"></div> <div class="selector-image img-ind19"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/induction_patterns/rank19_L2H25.png" alt="L2H25"></div> <div class="selector-image img-ind20"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/induction_patterns/rank20_L13H6.png" alt="L13H6"></div> <div class="selector-image img-ind21"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/induction_patterns/rank21_L16H1.png" alt="L16H1"></div> <div class="selector-image img-ind22"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/induction_patterns/rank22_L22H14.png" alt="L22H14"></div> <div class="selector-image img-ind23"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/induction_patterns/rank23_L27H5.png" alt="L27H5"></div> <div class="selector-image img-ind24"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/induction_patterns/rank24_L27H7.png" alt="L27H7"></div> <div class="selector-image img-ind25"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/induction_patterns/rank25_L27H4.png" alt="L27H4"></div> <div class="selector-image img-ind26"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/induction_patterns/rank26_L2H21.png" alt="L2H21"></div> <div class="selector-image img-ind27"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/induction_patterns/rank27_L10H13.png" alt="L10H13"></div> <div class="selector-image img-ind28"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/induction_patterns/rank28_L5H9.png" alt="L5H9"></div> <div class="selector-image img-ind29"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/induction_patterns/rank29_L16H23.png" alt="L16H23"></div> <div class="selector-image img-ind30"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/induction_patterns/rank30_L20H13.png" alt="L20H13"></div> <div class="selector-image img-ind31"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/induction_patterns/rank31_L27H20.png" alt="L27H20"></div> <div class="selector-image img-ind32"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/induction_patterns/rank32_L19H0.png" alt="L19H0"></div> </div> </div> </div> <div class="caption"> <b>Figure A1.</b> <b>Induction head attention patterns.</b> Each heatmap shows the attention pattern for one of the top induction heads. The x-axis is the key (source) position, and the y-axis is the query (destination) position. Brighter colors indicate higher attention weights. Click the buttons to switch between heads. </div> <h3 id="b2-previous-token-head-attention-patterns">B.2 Previous-Token Head Attention Patterns</h3> <p>Previous-token heads attend primarily to position \(t-1\), implementing a simple “look at what came before” operation. This creates a strong diagonal pattern one position below the main diagonal.</p> <div class="l-page"> <div class="png-selector"> <input type="radio" name="prev-head" id="prev1" checked> <input type="radio" name="prev-head" id="prev2"> <input type="radio" name="prev-head" id="prev3"> <input type="radio" name="prev-head" id="prev4"> <input type="radio" name="prev-head" id="prev5"> <input type="radio" name="prev-head" id="prev6"> <input type="radio" name="prev-head" id="prev7"> <input type="radio" name="prev-head" id="prev8"> <input type="radio" name="prev-head" id="prev9"> <input type="radio" name="prev-head" id="prev10"> <input type="radio" name="prev-head" id="prev11"> <input type="radio" name="prev-head" id="prev12"> <input type="radio" name="prev-head" id="prev13"> <input type="radio" name="prev-head" id="prev14"> <input type="radio" name="prev-head" id="prev15"> <input type="radio" name="prev-head" id="prev16"> <input type="radio" name="prev-head" id="prev17"> <input type="radio" name="prev-head" id="prev18"> <input type="radio" name="prev-head" id="prev19"> <input type="radio" name="prev-head" id="prev20"> <input type="radio" name="prev-head" id="prev21"> <input type="radio" name="prev-head" id="prev22"> <input type="radio" name="prev-head" id="prev23"> <input type="radio" name="prev-head" id="prev24"> <input type="radio" name="prev-head" id="prev25"> <input type="radio" name="prev-head" id="prev26"> <input type="radio" name="prev-head" id="prev27"> <input type="radio" name="prev-head" id="prev28"> <input type="radio" name="prev-head" id="prev29"> <input type="radio" name="prev-head" id="prev30"> <input type="radio" name="prev-head" id="prev31"> <input type="radio" name="prev-head" id="prev32"> <div class="selector-buttons"> <label for="prev1">L0H2</label> <label for="prev2">L14H26</label> <label for="prev3">L1H20</label> <label for="prev4">L1H18</label> <label for="prev5">L9H11</label> <label for="prev6">L1H16</label> <label for="prev7">L0H3</label> <label for="prev8">L7H2</label> <label for="prev9">L0H24</label> <label for="prev10">L14H8</label> <label for="prev11">L1H13</label> <label for="prev12">L0H26</label> <label for="prev13">L11H16</label> <label for="prev14">L21H7</label> <label for="prev15">L7H1</label> <label for="prev16">L0H6</label> <label for="prev17">L1H24</label> <label for="prev18">L1H4</label> <label for="prev19">L12H16</label> <label for="prev20">L1H26</label> <label for="prev21">L9H10</label> <label for="prev22">L6H8</label> <label for="prev23">L9H8</label> <label for="prev24">L25H20</label> <label for="prev25">L1H30</label> <label for="prev26">L16H29</label> <label for="prev27">L1H1</label> <label for="prev28">L0H29</label> <label for="prev29">L14H9</label> <label for="prev30">L18H26</label> <label for="prev31">L21H10</label> <label for="prev32">L9H9</label> </div> <div class="selector-images"> <div class="selector-image img-prev1"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/prev_token_patterns/rank01_L0H2.png" alt="L0H2"></div> <div class="selector-image img-prev2"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/prev_token_patterns/rank02_L14H26.png" alt="L14H26"></div> <div class="selector-image img-prev3"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/prev_token_patterns/rank03_L1H20.png" alt="L1H20"></div> <div class="selector-image img-prev4"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/prev_token_patterns/rank04_L1H18.png" alt="L1H18"></div> <div class="selector-image img-prev5"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/prev_token_patterns/rank05_L9H11.png" alt="L9H11"></div> <div class="selector-image img-prev6"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/prev_token_patterns/rank06_L1H16.png" alt="L1H16"></div> <div class="selector-image img-prev7"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/prev_token_patterns/rank07_L0H3.png" alt="L0H3"></div> <div class="selector-image img-prev8"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/prev_token_patterns/rank08_L7H2.png" alt="L7H2"></div> <div class="selector-image img-prev9"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/prev_token_patterns/rank09_L0H24.png" alt="L0H24"></div> <div class="selector-image img-prev10"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/prev_token_patterns/rank10_L14H8.png" alt="L14H8"></div> <div class="selector-image img-prev11"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/prev_token_patterns/rank11_L1H13.png" alt="L1H13"></div> <div class="selector-image img-prev12"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/prev_token_patterns/rank12_L0H26.png" alt="L0H26"></div> <div class="selector-image img-prev13"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/prev_token_patterns/rank13_L11H16.png" alt="L11H16"></div> <div class="selector-image img-prev14"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/prev_token_patterns/rank14_L21H7.png" alt="L21H7"></div> <div class="selector-image img-prev15"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/prev_token_patterns/rank15_L7H1.png" alt="L7H1"></div> <div class="selector-image img-prev16"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/prev_token_patterns/rank16_L0H6.png" alt="L0H6"></div> <div class="selector-image img-prev17"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/prev_token_patterns/rank17_L1H24.png" alt="L1H24"></div> <div class="selector-image img-prev18"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/prev_token_patterns/rank18_L1H4.png" alt="L1H4"></div> <div class="selector-image img-prev19"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/prev_token_patterns/rank19_L12H16.png" alt="L12H16"></div> <div class="selector-image img-prev20"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/prev_token_patterns/rank20_L1H26.png" alt="L1H26"></div> <div class="selector-image img-prev21"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/prev_token_patterns/rank21_L9H10.png" alt="L9H10"></div> <div class="selector-image img-prev22"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/prev_token_patterns/rank22_L6H8.png" alt="L6H8"></div> <div class="selector-image img-prev23"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/prev_token_patterns/rank23_L9H8.png" alt="L9H8"></div> <div class="selector-image img-prev24"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/prev_token_patterns/rank24_L25H20.png" alt="L25H20"></div> <div class="selector-image img-prev25"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/prev_token_patterns/rank25_L1H30.png" alt="L1H30"></div> <div class="selector-image img-prev26"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/prev_token_patterns/rank26_L16H29.png" alt="L16H29"></div> <div class="selector-image img-prev27"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/prev_token_patterns/rank27_L1H1.png" alt="L1H1"></div> <div class="selector-image img-prev28"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/prev_token_patterns/rank28_L0H29.png" alt="L0H29"></div> <div class="selector-image img-prev29"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/prev_token_patterns/rank29_L14H9.png" alt="L14H9"></div> <div class="selector-image img-prev30"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/prev_token_patterns/rank30_L18H26.png" alt="L18H26"></div> <div class="selector-image img-prev31"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/prev_token_patterns/rank31_L21H10.png" alt="L21H10"></div> <div class="selector-image img-prev32"><img src="/2026/assets/html/2026-04-27-iclr-induction/induction_analysis/prev_token_patterns/rank32_L9H9.png" alt="L9H9"></div> </div> </div> </div> <div class="caption"> <b>Figure A2.</b> <b>Previous-token head attention patterns.</b> Each heatmap shows the attention pattern for one of the top previous-token heads. The strong sub-diagonal pattern indicates attention to position $t-1$. Click the buttons to switch between heads. </div> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/2026/assets/bibliography/2026-04-27-iclr-induction.bib"></d-bibliography> <d-article> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/vis-llm-latent-geometry/">Visualizing LLM Latent Space Geometry Through Dimensionality Reduction</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/subject-invariant-eeg/">The Decoupling Hypothesis: Attempting Subject-Invariant EEG Representation Learning via Auxiliary Injection</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/style-representations/">Artistic Style and the Play of Neural Style Representations</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/spatial-awareness/">Where's the Chicken? Unpacking Spatial Awareness in Vision-Language Models</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/sparsity/">Don't Look Up (Every Token): Escaping Quadratic Complexity via Geometric Patterns and Algorithms</a> </li> <br> <br> </d-article> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 ICLR Blog. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/2026/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script src="/2026/assets/js/distillpub/overrides.js"></script> <script defer src="https://cdn.jsdelivr.net/npm/mermaid@10.7.0/dist/mermaid.min.js" integrity="sha256-TtLOdUA8mstPoO6sGvHIGx2ceXrrX4KgIItO06XOn8A=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/d3@7.8.5/dist/d3.min.js" integrity="sha256-1rA678n2xEx7x4cTZ5x4wpUCj6kUMZEZ5cxLSVSFWxw=" crossorigin="anonymous"></script> <script defer src="/2026/assets/js/mermaid-setup.js?38ca0a0126f7328d2d9a46bad640931f" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/2026/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/2026/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/2026/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/2026/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/2026/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/2026/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/2026/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/2026/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/2026/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/2026/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/2026/assets/js/search-data.js"></script> <script src="/2026/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>