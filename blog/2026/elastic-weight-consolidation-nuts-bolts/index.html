<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Elastic Weight Consolidation (EWC): Nuts and Bolts | ICLR Blogposts 2026 </title> <meta name="author" content="ICLR Blog"> <meta name="description" content="A theoretical deep-dive into the Elastic Weight Consolidation method for continual learning, explaining the mathematical foundations and intuitions behind this influential approach to preventing catastrophic forgetting."> <meta name="keywords" content="machine-learning, ml, deep-learning, reinforcement-learning, icl# add your own keywords or leave empty"> <link rel="stylesheet" href="/2026/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/2026/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/2026/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/2026/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/2026/assets/img/iclr_favicon.ico?0a8a3afdb0dbe139723b24dba3052a4f"> <link rel="stylesheet" href="/2026/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://iclr-blogposts.github.io/2026/blog/2026/elastic-weight-consolidation-nuts-bolts/"> <script src="/2026/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/2026/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <script src="/2026/assets/js/distillpub/template.v2.js"></script> <script src="/2026/assets/js/distillpub/transforms.v2.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Elastic Weight Consolidation (EWC): Nuts and Bolts",
            "description": "A theoretical deep-dive into the Elastic Weight Consolidation method for continual learning, explaining the mathematical foundations and intuitions behind this influential approach to preventing catastrophic forgetting.",
            "published": "April 27, 2026",
            "authors": [
              
              {
                "author": "Anonymous",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/2026/"> ICLR Blogposts 2026 </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/2026/">home </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/about/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/call/">call for blogposts </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/submitting/">submitting </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/reviewing/">reviewing </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">past iterations </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2026/"><strong>2026</strong></a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2025/">2025</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2024/">2024</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2023/">2023</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blog-track.github.io/home/" rel="external nofollow noopener" target="_blank">2022</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Elastic Weight Consolidation (EWC): Nuts and Bolts</h1> <p>A theoretical deep-dive into the Elastic Weight Consolidation method for continual learning, explaining the mathematical foundations and intuitions behind this influential approach to preventing catastrophic forgetting.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#abstract">Abstract</a> </div> <div> <a href="#introduction">Introduction</a> </div> <div> <a href="#elastic-weight-consolidation">Elastic Weight Consolidation</a> </div> <ul> <li> <a href="#intractability-of-posterior-of-mathcal-a-and-its-approximation">Intractability of posterior of $\mathcal{A}$ and its approximation</a> </li> </ul> <div> <a href="#conclusion">Conclusion</a> </div> </nav> </d-contents> <h2 id="abstract">Abstract</h2> <p>In this blogpost, we present a theoretical support of the continual learning method <strong>Elastic Weight Consolidation</strong>, introduced in the paper titled ‘Overcoming catastrophic forgetting in neural networks’ <d-cite key="kirkpatrick2017overcoming"></d-cite>. Being one of the most cited papers in regularized methods for continual learning, this blogpost disentangles the underlying concept of the proposed objective function. We assume that the reader is aware of the basic terminologies of continual learning.</p> <h2 id="introduction">Introduction</h2> <p>Following are the notations used throughout this blogpost. Vectors and matrices are denoted in bold lowercase and bold uppercase, respectively. Superscript $^{\top}$ denotes matrix transpose. \(\mathbb{E}[\cdot]\) denotes the expectation operator. An optimum value of a variable is denoted by adding a superscript $^{\star}$.</p> <p>Continual learning is a much desired attribute for neural networks. For example, if we train a model to distinguish between images of a cat and a dog (task 1), and subsequently train it again to distinguish between images of chair and table (task 2), the model should be able to retain its knowledge on task 1 even after learning task 2. In simple terms, our network model should be able to perform equally well on all seen tasks, even after learning new ones. Any degradation of performance on the previous tasks after learning new ones is fittingly termed as <em>catastrophic forgetting</em>. This sub-research area has seen an insurgence in works in recent times <d-cite key="kirkpatrick2017overcoming,zenke2017continual,li2017learning,aljundi2018memory"></d-cite>. Briefly, the continual learning scenarios can be categorized into following <d-cite key="van2019three"></d-cite>:</p> <ul> <li> <strong>Task-Incremental Learning</strong>: For the given set of tasks, the task identity is known during testing.</li> <li> <strong>Domain-Incremental Learning</strong>: For the given set of tasks, task identity is not provided during testing, but need not infer the same.</li> <li> <strong>Class-Incremental Learning</strong>: For the given set of tasks, task identity is not provided during testing, but has to infer the same.</li> </ul> <p>We highly recommend <d-cite key="van2019three,wiewel2019localizing"></d-cite> for a good overview of different methodologies to alleviate catastrophic forgetting as well as continual learning in general. The next Section describes the well studied regularization method of continual learning: Elastic Weight Consolidation. It presents a solution to the continual learning problem by making task-specific synaptic (<em>read</em> network parameters) consolidation. Based on the theory of plasticity of post-synaptic dendritic spines in the brain, this method presents a paradigm that marks how important is a network parameter to the previous tasks and penalizes any change made to it depending upon the importance, while learning new tasks.</p> <h2 id="elastic-weight-consolidation">Elastic Weight Consolidation</h2> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-elastic-weight-consolidation-nuts-bolts/fig1-480.webp 480w,/2026/assets/img/2026-04-27-elastic-weight-consolidation-nuts-bolts/fig1-800.webp 800w,/2026/assets/img/2026-04-27-elastic-weight-consolidation-nuts-bolts/fig1-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-elastic-weight-consolidation-nuts-bolts/fig1.png" class="img-fluid rounded z-depth-1" width="75%" height="auto" title="Possible configurations of θ*_A" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <strong>Possible configurations of</strong> $\boldsymbol{\theta}^\star_{\mathcal{A}}$. The shaded region represents a space of optimum $\boldsymbol{\theta}_{\mathcal{A}}$ with acceptable errors w.r.t. $\boldsymbol{\theta}^\star_{\mathcal{A}}$ for task $\mathcal{A}$. </div> <p>Denote parameters of layers of a deep neural network (DNN) with $\boldsymbol{\theta}$. Training DNNs generates a mapping between the input distribution space and target distribution space. This is done by finding out an optimum \(\boldsymbol{\theta} = \boldsymbol{\theta}^\star\) which results in the least error in the training objective. It has been shown in earlier works <d-cite key="sussmann1992uniqueness"></d-cite> that such a mapping can be obtained with many configurations of $\boldsymbol{\theta}^\star$, represented in the figure above. The term <em>many configurations</em> can be interpreted as a solution space around the most optimum $\boldsymbol{\theta}$ with acceptable error in the learned mapping. Note that in figures to follow, the shaded ellipses represent the solution of individual tasks where as the overlapping region of multiple ellipses, marked by diagonal lines, represents the common solution space for all tasks.</p> <p>Let’s begin with a simple case of two tasks, task $\mathcal{A}$ and task $\mathcal{B}$. To have a configuration of parameters that performs well for both $\mathcal{A}$ and $\mathcal{B}$, the network should be able to pick $\boldsymbol{\theta}$ from the overlapping region of the individual solution spaces (see Figure 2). This is with the assumption that there is always an overlapping region for the solution spaces of all tasks for the network to learn them sequentially. A case of four tasks has been illustrated in Figure 2. In the first instance, the network can learn any \(\boldsymbol{\theta} = \boldsymbol{\theta}_{\mathcal{A}}\) that performs well for task $\mathcal{A}$. But with the arrival of task $\mathcal{B}$, the network should pick up a \(\boldsymbol{\theta} = \boldsymbol{\theta}_{\mathcal{A}, \mathcal{B}}\).</p> <p>The next question that arrives is how can the network learn the a set of parameters that lies in this overlapping region. To this end, EWC presents a method of selective regularization of parameters $\boldsymbol{\theta}$. After learning $\mathcal{A}$, this regularization method identifies which parameters are important for $\mathcal{A}$, and then penalizes any change made to the network parameters according to their importance while learning $\mathcal{B}$.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-elastic-weight-consolidation-nuts-bolts/fig2-480.webp 480w,/2026/assets/img/2026-04-27-elastic-weight-consolidation-nuts-bolts/fig2-800.webp 800w,/2026/assets/img/2026-04-27-elastic-weight-consolidation-nuts-bolts/fig2-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-elastic-weight-consolidation-nuts-bolts/fig2.png" class="img-fluid rounded z-depth-1" width="75%" height="auto" title="Overlap of possible configurations of θ*" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <strong>Overlap of possible configurations of</strong> $\boldsymbol{\theta}^\star$. The overlapping space represents an optimum parameter region where the network performs without any catastrophic degradation on previous tasks. </div> <h3 id="intractability-of-posterior-of-mathcala-and-its-approximation">Intractability of posterior of $\mathcal{A}$ and its approximation</h3> <p>To formulate the objective, we start by taking a Bayesian approach needed to estimate the network parameters $\boldsymbol{\theta}$. More specifically given the data $\boldsymbol{\Sigma}$, we want to learn the posterior probability distribution function $p(\boldsymbol{\theta}\mid\boldsymbol{\Sigma})$. Following <d-cite key="lherranz2018rotating"></d-cite> and using Bayes rule, we can write</p> <p>\begin{equation} \underbrace{p(\boldsymbol{\theta}\mid\boldsymbol{\Sigma})}_{\text{posterior}} = \dfrac{\overbrace{p(\boldsymbol{\Sigma}\mid\boldsymbol{\theta})}^{\text{likelihood}}\overbrace{p(\boldsymbol{\theta})}^{\text{prior}}}{p(\boldsymbol{\Sigma})} \end{equation}</p> <p>Since maximizing a function is same as maximizing its logarithm, we take \(\log(\cdot)\) of the above equation as follows:</p> <p>\begin{equation} \log(p(\boldsymbol{\theta}\mid\boldsymbol{\Sigma})) = \log(p(\boldsymbol{\Sigma}\mid\boldsymbol{\theta})) +\log(p(\boldsymbol{\theta})) - \log(p(\boldsymbol{\Sigma})) \end{equation}</p> <p>To train the neural network on $\boldsymbol{\Sigma}$, the objective function to be optimized over the log-likelihood function:</p> <p>\begin{equation} \text{argmax}_{\boldsymbol{\theta}}{\ell(\boldsymbol{\theta}) = \log(p(\boldsymbol{\theta}\mid\boldsymbol{\Sigma}))} \end{equation}</p> <p>For the case of given two independent tasks such that \(\boldsymbol{\Sigma} = \{\mathcal{A}, \mathcal{B}\}\) (with $\mathcal{B}$ appearing in sequence after $\mathcal{A}$), the log-posterior can be written as:</p> <p>\begin{equation} \log(p(\boldsymbol{\theta}\mid\boldsymbol{\Sigma})) = \log(p(\mathcal{B}\mid\boldsymbol{\theta})) +\log(p(\boldsymbol{\theta}\mid\mathcal{A})) - \log(p(\mathcal{B})) \end{equation} where the independence of $\mathcal{A}$ and $\mathcal{B}$ is used. Following the Bayesian formulation, $p(\mathcal{B}\mid\boldsymbol{\theta})$ is the loss for current task $\mathcal{B}$, $p(\mathcal{B})$ is the likelihood for $\mathcal{B}$, and now posterior $p(\boldsymbol{\theta}\mid\mathcal{A})$ for $\mathcal{A}$ becomes prior for $\mathcal{B}$.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-elastic-weight-consolidation-nuts-bolts/fig3-480.webp 480w,/2026/assets/img/2026-04-27-elastic-weight-consolidation-nuts-bolts/fig3-800.webp 800w,/2026/assets/img/2026-04-27-elastic-weight-consolidation-nuts-bolts/fig3-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-elastic-weight-consolidation-nuts-bolts/fig3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Laplace approximation of true posterior pdf" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <strong>Laplace approximation of true posterior pdf.</strong> $\mathbb{I}_\mathcal{A}$ represents the Fisher Information matrix. </div> <p>Referring to the log-posterior equation, it can be observed that we have to deal with the function $p(\boldsymbol{\theta}\mid\mathcal{A})$. This is the posterior function for $\mathcal{A}$ which contains the information about the parameters that explain $\mathcal{A}$ using the given network. As discussed in <d-cite key="kirkpatrick2017overcoming"></d-cite>, this posterior function is said to be intractable. Basically, the intractability of $p(\boldsymbol{\theta}\mid\mathcal{A})$ can be interpreted as the function not existing in some interpretable form. Hence, it is difficult to estimate its quantiles. See <d-cite key="tokdar2013lecture"></d-cite> for an example.</p> <p>Next as the posterior is difficult to analyze in its present form, we aim to approximate it using Laplace approximation. In simple terms, Laplace approximation methodology is employed to find a normal distribution approximation to a continuous probability density distribution (see Figure 3). Assuming $p(\boldsymbol{\theta}\mid\mathcal{A})$ is smooth and majorly peaked around its point of maxima (i.e. $\boldsymbol{\theta}^\star_{\mathcal{A}}$), we can approximate it with a normal distribution with mean $\boldsymbol{\theta}^\star_{\mathcal{A}}$ and variance $[\mathbb{I}_{\mathcal{A}}]^{-1}$. This brings us to the question on how did we come to the conclusion on these particular values of mean and variance for the normal distribution.</p> <p>To begin with, compute the second order Taylor expansion of $\ell(\boldsymbol{\theta})$ around $\boldsymbol{\theta}^\star_{\mathcal{A}}$ as follows:</p> <p>\begin{equation} \ell(\boldsymbol{\theta})\approx \ell(\boldsymbol{\theta}^\star_{\mathcal{A}}) +( \dfrac{\partial\ell(\boldsymbol{\theta})}{\partial\boldsymbol{\theta}}\mid_{\boldsymbol{\theta}^\star_{\mathcal{A}}}) + \dfrac{1}{2}(\boldsymbol{\theta} -\boldsymbol{ \theta}^\star_{\mathcal{A}})^\top(\dfrac{\partial^2\ell(\boldsymbol{\theta})}{\partial^2\boldsymbol{\theta}}\mid_{\boldsymbol{\theta}^\star_{\mathcal{A}}})(\boldsymbol{\theta} -\boldsymbol{ \theta}^\star_{\mathcal{A}}) + \text{(higher order terms)} \end{equation}</p> <p>Neglecting higher order terms and noting that \(\dfrac{\partial\ell(\boldsymbol{\theta})}{\partial\boldsymbol{\theta}}\mid_{\boldsymbol{\theta}^\star_{\mathcal{A}}} = 0\) (slope of tangent at peak), we have:</p> \[\begin{align} \ell(\boldsymbol{\theta})\approx \ell(\boldsymbol{\theta}^\star_{\mathcal{A}}) + \dfrac{1}{2}(\boldsymbol{\theta} -\boldsymbol{ \theta}^\star_{\mathcal{A}})^\top\underbrace{(\dfrac{\partial^2\ell(\boldsymbol{\theta})}{\partial^2\boldsymbol{\theta}}\mid_{\boldsymbol{\theta}^\star_{\mathcal{A}}})}_{\text{Hessian}}(\boldsymbol{\theta} -\boldsymbol{\theta}^\star_{\mathcal{A}}) \end{align}\] <p>Using the log-posterior equation, we can write the above for task $\mathcal{A}$ as following:</p> <p>\begin{equation} \log(p(\boldsymbol{\theta}\mid\mathcal{A})) = \log(p(\boldsymbol{\theta}^\star_{\mathcal{A}}\mid\mathcal{A})) + \dfrac{1}{2}(\boldsymbol{\theta} -\boldsymbol{ \theta}^\star_{\mathcal{A}})^\top(\dfrac{\partial^2(\log(p(\boldsymbol{\theta}\mid\mathcal{A})))}{\partial^2\boldsymbol{\theta}}\mid_{\boldsymbol{\theta}^\star_{\mathcal{A}}})(\boldsymbol{\theta} -\boldsymbol{ \theta}^\star_{\mathcal{A}}) + \Delta \end{equation}</p> <p>where \(\Delta = \log(p(\boldsymbol{\theta}^\star_{\mathcal{A}}\mid\mathcal{A}))\). Next, write</p> <p>\begin{equation} (\dfrac{\partial^2(\log(p(\boldsymbol{\theta}\mid\mathcal{A})))}{\partial^2\boldsymbol{\theta}}\mid_{\boldsymbol{\theta}^\star_{\mathcal{A}}}) = -((-\dfrac{\partial^2(\log(p(\boldsymbol{\theta}\mid\mathcal{A})))}{\partial^2\boldsymbol{\theta}}\mid_{\boldsymbol{\theta}^\star_{\mathcal{A}}})^{-1})^{-1} \end{equation}</p> <p>and replace it back in the equation to express the same in the standard form of normal distribution function:</p> <p>\begin{equation} p(\boldsymbol{\theta}\mid\mathcal{A}) = \epsilon\exp(-\dfrac{1}{2}(\boldsymbol{\theta} -\boldsymbol{ \theta}^\star_{\mathcal{A}})^\top((-\dfrac{\partial^2(\log(p(\boldsymbol{\theta}\mid\mathcal{A})))}{\partial^2\boldsymbol{\theta}}\mid_{\boldsymbol{\theta}^\star_{\mathcal{A}}})^{-1})^{-1}(\boldsymbol{\theta} -\boldsymbol{ \theta}^\star_{\mathcal{A}})) \end{equation}</p> <p>where \(\epsilon = \exp(\Delta)\) is a constant. From this equation, it can be concluded that we have obtained the Laplace approximation of posterior pdf as:</p> <p>\begin{equation} p(\boldsymbol{\theta}\mid\mathcal{A})\sim\mathcal{N}(\boldsymbol{ \theta}^\star_{\mathcal{A}}, (-\dfrac{\partial^2(\log(p(\boldsymbol{\theta}\mid\mathcal{A})))}{\partial^2\boldsymbol{\theta}}\mid_{\boldsymbol{\theta}^\star_{\mathcal{A}}})^{-1}) \end{equation}</p> <p>Notice the variance of the estimated normal distribution of $p(\boldsymbol{\theta}\mid\mathcal{A})$. Given $\boldsymbol{ \theta}^\star_{\mathcal{A}}$, the term $\log(p(\boldsymbol{\theta}\mid\mathcal{A}))$ represents the log-likelihood of posterior pdf $p(\boldsymbol{\theta}\mid\mathcal{A})$. Clearly, the term represents the inverse of <strong>Fisher information matrix</strong> (FIM),</p> \[\begin{equation} \mathbb{I}_{\mathcal{A}} = \mathbb{E}[-\dfrac{\partial^2(\log(p(\boldsymbol{\theta}\mid\mathcal{A})))}{\partial^2\boldsymbol{\theta}}\mid_{\boldsymbol{\theta}^\star_{\mathcal{A}}}] \end{equation}\] <p>Note that we obtain $\mathbb{I}_{\mathcal{A}}$ by using the Bayesian equation and treating the prior $p(\boldsymbol{\theta})$ and $p(\mathcal{A})$ constant. This makes derivative of log of the Bayesian equation posterior and likelihood equal. More on this in <strong>Appendix A.2</strong> of <d-cite key="van2019three"></d-cite>. Finally, we get</p> <p>\begin{equation} p(\boldsymbol{\theta}\mid\mathcal{A})\sim\mathcal{N}(\boldsymbol{ \theta}^\star_{\mathcal{A}}, [\mathbb{I}_{\mathcal{A}}]^{-1}) \end{equation}</p> <p>Further, as FIM can also be computed from first order derivatives, we can avoid the Hessian computed in the Taylor expansion using the following property <d-cite key="kay1993fundamentals"></d-cite>:</p> \[\begin{equation} \mathbb{I}_{\mathcal{A}} = \mathbb{E}[-\dfrac{\partial^2(\log(p(\boldsymbol{\theta}\mid\mathcal{A})))}{\partial^2\boldsymbol{\theta}}\mid_{\boldsymbol{\theta}^\star_{\mathcal{A}}}] = \mathbb{E}[(\dfrac{\partial(\log(p(\boldsymbol{\theta}\mid\mathcal{A})))}{\partial\boldsymbol{\theta}})(\dfrac{\partial(\log(p(\boldsymbol{\theta}\mid\mathcal{A})))}{\partial\boldsymbol{\theta}})^\top\mid_{\boldsymbol{\theta}^\star_{\mathcal{A}}}] \end{equation}\] <p>Now, we can write the log-posterior equation as:</p> \[\begin{equation} \log(p(\boldsymbol{\theta}\mid\boldsymbol{\Sigma})) = \log(p(\mathcal{B}\mid\boldsymbol{\theta})) +\dfrac{\lambda}{2}(\boldsymbol{\theta} -\boldsymbol{ \theta}^\star_{\mathcal{A}})^\top(\dfrac{\partial^2(\log(p(\boldsymbol{\theta}\mid\mathcal{A})))}{\partial^2\boldsymbol{\theta}}\mid_{\boldsymbol{\theta}^\star_{\mathcal{A}}})(\boldsymbol{\theta} -\boldsymbol{ \theta}^\star_{\mathcal{A}}) + \epsilon' \end{equation}\] <p>where $\epsilon’$ accounts for all constants and $\lambda$ is a hyper-parameter introduced to have a trade off between learning $\mathcal{B}$ and not forgetting $\mathcal{A}$. Simplifying more, we have:</p> \[\begin{equation} \log(p(\boldsymbol{\theta}\mid\boldsymbol{\Sigma})) = \log(p(\mathcal{B}\mid\boldsymbol{\theta})) - \dfrac{\lambda}{2}(\boldsymbol{\theta} - \boldsymbol{ \theta}^\star_{\mathcal{A}})^\top \mathbb{I}_{\mathcal{A}} (\boldsymbol{\theta} - \boldsymbol{\theta}^\star_{\mathcal{A}}) + \epsilon' \end{equation}\] <p>This implies: \(\begin{equation} \underbrace{\ell(\boldsymbol{\theta})}_{\text{overall loss}} = \underbrace{\ell_\mathcal{B}(\boldsymbol{\theta})}_{\text{loss for \mathcal{B} }} - \underbrace{\dfrac{\lambda}{2}(\boldsymbol{\theta} -\boldsymbol{ \theta}^\star_{\mathcal{A}})^\top\mathbb{I}_{\mathcal{A}}(\boldsymbol{\theta} -\boldsymbol{ \theta}^\star_{\mathcal{A}})}_{\text{weight regularizer}} + \epsilon' \end{equation}\)</p> <p>Further simplification can be found in <d-cite key="van2019three"></d-cite>. Before we end this Section, let’s discuss how does the FIM indicates the <strong>importance</strong> of the parameters for the previous tasks.</p> <p>We say a network has learnt a task when its objective has reached a minimum in the loss surface. We know that the curvature of such surfaces represent the sensitivity of the network with respect to the optimum $\boldsymbol{\theta}^\star$. This sensitivity can be determined by looking at the direction along which $\boldsymbol{\theta}^\star$ changes. This implies the curvature is inversely proportional to change in $\boldsymbol{\theta}^\star$. Hence, if the more the curvature, a ‘$\delta$’ increment can result in large increase in the loss. Curvature of a curve is denoted by its Hessian and hence in our case, as the second derivative is of the log likelihood function of the posterior pdf, the FIM \(\mathbb{I}_{\mathcal{A}}\) comes into picture. Thus, \(\mathbb{I}_\mathcal{A}\) can tell us which parameter is important to the the previous task as its corresponding element in \(\mathbb{I}_\mathcal{A}\) will have a large value, indicating higher importance. See <d-cite key="maltoni2019continuous"></d-cite> for more.</p> <h2 id="conclusion">Conclusion</h2> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-elastic-weight-consolidation-nuts-bolts/fig4-480.webp 480w,/2026/assets/img/2026-04-27-elastic-weight-consolidation-nuts-bolts/fig4-800.webp 800w,/2026/assets/img/2026-04-27-elastic-weight-consolidation-nuts-bolts/fig4-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-elastic-weight-consolidation-nuts-bolts/fig4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Sequential training on task B after task A" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <strong>Sequential training on task</strong> $\mathcal{B}$ <strong>after task</strong> $\mathcal{A}$. Left: Train the network as it is: results in 'Forgetting', Middle: Make no change in the parameters of previous tasks, Right: Make changes in the parameters of the previous tasks depending on their importance. </div> <p>In this blogpost, we have presented a theoretical support of the EWC method. We have shown how the intractable posterior function can be approximated using Laplace approximation, and how the Fisher Information Matrix can be used to identify the importance of parameters for previous tasks. The EWC method provides a principled approach to continual learning by selectively regularizing parameters based on their importance to previously learned tasks.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/2026/assets/bibliography/2026-04-27-elastic-weight-consolidation-nuts-bolts.bib"></d-bibliography> <d-article> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/fairness-audits/">Fairness Audits as Theater: When Metrics Mask Structural Harm</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/fans/">FANS - Frequency-Adaptive Noise Shaping for Diffusion Models</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/general-agent-evaluation/">Ready For General Agents? Let's Test It.</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/why-vlms-waste-their-vision/">Why vlms waste their vision</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/wait-do-we-need-to-wait/">Wait, Do We Need to Wait? Revisiting Budget Forcing for Sequential Test-Time Scaling</a> </li> <br> <br> </d-article> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 ICLR Blog. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/2026/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script src="/2026/assets/js/distillpub/overrides.js"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/2026/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/2026/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/2026/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/2026/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/2026/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/2026/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/2026/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/2026/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/2026/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/2026/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/2026/assets/js/search-data.js"></script> <script src="/2026/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>